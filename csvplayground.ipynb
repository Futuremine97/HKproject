{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7edde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52,54,58,62,63,66,68,70,68,70,70,73,74,75,77,78,Mei\n",
      "65,68,66,68,71,74,74,76,72,74,74,75,76,77,80,80,조진호\n",
      "51,55,58,60,66,67,67,69,68,70,74,73,78,76,78,80,최주원\n"
     ]
    }
   ],
   "source": [
    "# 이 커밋은 자기 자신과 자기 자신의 데이터를 비교해서 정답률 1이 나오는 코드입니다",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "\n",
    "with open(\"mei.csv\", 'r', encoding=\"utf-8\") as read_: #read다음에_는 의미가 없다. read랑 헷갈리지말라고 쓴 것. a 라고 해도 무방.\n",
    "    text=read_.readlines()\n",
    "\n",
    "rows=[]\n",
    "for i in text[1:]:\n",
    "    rows.append(list(map(int,i.split(\",\")[:-1])))\n",
    "print(i)\n",
    "\n",
    "df=pd.DataFrame(rows)\n",
    "df.columns=[\"sensor%d\"%i for i in range(1,17)]\n",
    "\n",
    "with open(\"jo.csv\", 'r', encoding=\"utf-8\") as read_:\n",
    "    text2=read_.readlines()\n",
    "    \n",
    "\n",
    "rows2=[]\n",
    "for i in text2[1:]:\n",
    "    rows2.append(list(map(int,i.split(\",\")[:-1])))\n",
    "print(i)\n",
    "\n",
    "with open(\"joo.csv\", 'r', encoding=\"utf-8\") as read_:\n",
    "    text3=read_.readlines()\n",
    "    \n",
    "rows3=[]\n",
    "for i in text3[1:]:\n",
    "    rows3.append(list(map(int,i.split(\",\")[:-1])))\n",
    "print(i)\n",
    "\n",
    "df2=pd.DataFrame(rows2)\n",
    "df2.columns=[\"sensor%d\"%i for i in range(1,17)]\n",
    "\n",
    "\n",
    "df3=pd.DataFrame(rows3)\n",
    "df3.columns=[\"sensor%d\"%i for i in range(1,17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b8de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import seaborn;\n",
    "seaborn.set()\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "image1 = df.astype('float')\n",
    "image2 = df2.astype('float')\n",
    "\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "y2 = ['sensor1']\n",
    "y1 = ['sensor1','sensor2','sensor3','sensor4','sensor5','sensor6','sensor7','sensor8','sensor9','sensor10','sensor11','sensor12','sensor13','sensor14','sensor15','sensor16'] # define y variable, i.e., what we want to predict\n",
    "print(df.shape) # print the number of rows anc columns\n",
    "\n",
    "print(df.head())\n",
    "print(df2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0806de5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train\n",
      "[[91, 93, 85, 90, 95, 93, 86, 91, 87, 87, 87, 86, 88, 87, 90, 87], [70, 73, 69, 71, 76, 76, 77, 78, 74, 75, 76, 78, 79, 80, 78, 81], [65, 64, 68, 67, 72, 71, 74, 73, 73, 70, 72, 74, 77, 77, 78, 78], [13, 19, 24, 29, 35, 37, 41, 47, 44, 48, 51, 55, 58, 59, 59, 62], [102, 100, 102, 97, 99, 99, 97, 96, 92, 91, 89, 89, 91, 91, 90, 88], [76, 78, 76, 77, 79, 80, 81, 81, 79, 81, 80, 81, 81, 83, 82, 80], [70, 71, 72, 72, 76, 76, 77, 77, 74, 74, 71, 76, 81, 79, 80, 80], [167, 163, 157, 151, 149, 145, 139, 136, 130, 127, 122, 120, 120, 120, 115, 117], [36, 40, 44, 47, 50, 53, 58, 57, 57, 59, 61, 63, 67, 69, 71, 69], [50, 56, 55, 57, 62, 64, 64, 67, 64, 67, 68, 65, 71, 75, 73, 75], [50, 52, 52, 56, 62, 64, 65, 66, 65, 66, 69, 68, 73, 73, 73, 74], [43, 49, 50, 54, 57, 58, 61, 64, 61, 65, 67, 66, 69, 70, 71, 74], [79, 75, 73, 77, 80, 81, 76, 82, 80, 79, 81, 82, 85, 84, 84, 83], [79, 79, 79, 81, 82, 82, 83, 85, 81, 81, 81, 83, 86, 87, 87, 85]]\n",
      "------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------\n",
      "X_train\n",
      "[[91, 93, 85, 90, 95, 93, 86, 91, 87, 87, 87, 86, 88, 87, 90, 87], [70, 73, 69, 71, 76, 76, 77, 78, 74, 75, 76, 78, 79, 80, 78, 81], [65, 64, 68, 67, 72, 71, 74, 73, 73, 70, 72, 74, 77, 77, 78, 78], [13, 19, 24, 29, 35, 37, 41, 47, 44, 48, 51, 55, 58, 59, 59, 62], [102, 100, 102, 97, 99, 99, 97, 96, 92, 91, 89, 89, 91, 91, 90, 88], [76, 78, 76, 77, 79, 80, 81, 81, 79, 81, 80, 81, 81, 83, 82, 80], [70, 71, 72, 72, 76, 76, 77, 77, 74, 74, 71, 76, 81, 79, 80, 80], [167, 163, 157, 151, 149, 145, 139, 136, 130, 127, 122, 120, 120, 120, 115, 117], [36, 40, 44, 47, 50, 53, 58, 57, 57, 59, 61, 63, 67, 69, 71, 69], [50, 56, 55, 57, 62, 64, 64, 67, 64, 67, 68, 65, 71, 75, 73, 75], [50, 52, 52, 56, 62, 64, 65, 66, 65, 66, 69, 68, 73, 73, 73, 74], [43, 49, 50, 54, 57, 58, 61, 64, 61, 65, 67, 66, 69, 70, 71, 74], [79, 75, 73, 77, 80, 81, 76, 82, 80, 79, 81, 82, 85, 84, 84, 83], [79, 79, 79, 81, 82, 82, 83, 85, 81, 81, 81, 83, 86, 87, 87, 85]]\n",
      "-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/\n",
      "-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/\n",
      "xt\n",
      "[ 91  93  85  90  95  93  86  91  87  87  87  86  88  87  90  87  70  73\n",
      "  69  71  76  76  77  78  74  75  76  78  79  80  78  81  65  64  68  67\n",
      "  72  71  74  73  73  70  72  74  77  77  78  78  13  19  24  29  35  37\n",
      "  41  47  44  48  51  55  58  59  59  62 102 100 102  97  99  99  97  96\n",
      "  92  91  89  89  91  91  90  88  76  78  76  77  79  80  81  81  79  81\n",
      "  80  81  81  83  82  80  70  71  72  72  76  76  77  77  74  74  71  76\n",
      "  81  79  80  80 167 163 157 151 149 145 139 136 130 127 122 120 120 120\n",
      " 115 117  36  40  44  47  50  53  58  57  57  59  61  63  67  69  71  69\n",
      "  50  56  55  57  62  64  64  67  64  67  68  65  71  75  73  75  50  52\n",
      "  52  56  62  64  65  66  65  66  69  68  73  73  73  74  43  49  50  54\n",
      "  57  58  61  64  61  65  67  66  69  70  71  74  79  75  73  77  80  81\n",
      "  76  82  80  79  81  82  85  84  84  83  79  79  79  81  82  82  83  85\n",
      "  81  81  81  83  86  87  87  85]\n",
      "------------------------------------------------------------------------------------------\n",
      "yt\n",
      "[ 91  93  85  90  95  93  86  91  87  87  87  86  88  87  90  87  70  73\n",
      "  69  71  76  76  77  78  74  75  76  78  79  80  78  81  65  64  68  67\n",
      "  72  71  74  73  73  70  72  74  77  77  78  78  13  19  24  29  35  37\n",
      "  41  47  44  48  51  55  58  59  59  62 102 100 102  97  99  99  97  96\n",
      "  92  91  89  89  91  91  90  88  76  78  76  77  79  80  81  81  79  81\n",
      "  80  81  81  83  82  80  70  71  72  72  76  76  77  77  74  74  71  76\n",
      "  81  79  80  80 167 163 157 151 149 145 139 136 130 127 122 120 120 120\n",
      " 115 117  36  40  44  47  50  53  58  57  57  59  61  63  67  69  71  69\n",
      "  50  56  55  57  62  64  64  67  64  67  68  65  71  75  73  75  50  52\n",
      "  52  56  62  64  65  66  65  66  69  68  73  73  73  74  43  49  50  54\n",
      "  57  58  61  64  61  65  67  66  69  70  71  74  79  75  73  77  80  81\n",
      "  76  82  80  79  81  82  85  84  84  83  79  79  79  81  82  82  83  85\n",
      "  81  81  81  83  86  87  87  85]\n",
      "------------------------------------------------------------------------------------------\n",
      "xt\n",
      "[[ 91  93  85  90  95  93  86  91  87  87  87  86  88  87  90  87  70  73\n",
      "   69  71  76  76  77  78  74  75  76  78  79  80  78  81  65  64  68  67\n",
      "   72  71  74  73  73  70  72  74  77  77  78  78  13  19  24  29  35  37\n",
      "   41  47  44  48  51  55  58  59  59  62 102 100 102  97  99  99  97  96\n",
      "   92  91  89  89  91  91  90  88  76  78  76  77  79  80  81  81  79  81\n",
      "   80  81  81  83  82  80  70  71  72  72  76  76  77  77  74  74  71  76\n",
      "   81  79  80  80 167 163 157 151 149 145 139 136 130 127 122 120 120 120\n",
      "  115 117  36  40  44  47  50  53  58  57  57  59  61  63  67  69  71  69\n",
      "   50  56  55  57  62  64  64  67  64  67  68  65  71  75  73  75  50  52\n",
      "   52  56  62  64  65  66  65  66  69  68  73  73  73  74  43  49  50  54\n",
      "   57  58  61  64  61  65  67  66  69  70  71  74  79  75  73  77  80  81\n",
      "   76  82  80  79  81  82  85  84  84  83  79  79  79  81  82  82  83  85\n",
      "   81  81  81  83  86  87  87  85]]\n",
      "------------------------------------------------------------------------------------------\n",
      "yt\n",
      "[[ 91  93  85  90  95  93  86  91  87  87  87  86  88  87  90  87  70  73\n",
      "   69  71  76  76  77  78  74  75  76  78  79  80  78  81  65  64  68  67\n",
      "   72  71  74  73  73  70  72  74  77  77  78  78  13  19  24  29  35  37\n",
      "   41  47  44  48  51  55  58  59  59  62 102 100 102  97  99  99  97  96\n",
      "   92  91  89  89  91  91  90  88  76  78  76  77  79  80  81  81  79  81\n",
      "   80  81  81  83  82  80  70  71  72  72  76  76  77  77  74  74  71  76\n",
      "   81  79  80  80 167 163 157 151 149 145 139 136 130 127 122 120 120 120\n",
      "  115 117  36  40  44  47  50  53  58  57  57  59  61  63  67  69  71  69\n",
      "   50  56  55  57  62  64  64  67  64  67  68  65  71  75  73  75  50  52\n",
      "   52  56  62  64  65  66  65  66  69  68  73  73  73  74  43  49  50  54\n",
      "   57  58  61  64  61  65  67  66  69  70  71  74  79  75  73  77  80  81\n",
      "   76  82  80  79  81  82  85  84  84  83  79  79  79  81  82  82  83  85\n",
      "   81  81  81  83  86  87  87  85]]\n",
      "------------------------------------------------------------------------------------------\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "knn 예측치\n",
      "[[ 91  93  85  90  95  93  86  91  87  87  87  86  88  87  90  87  70  73\n",
      "   69  71  76  76  77  78  74  75  76  78  79  80  78  81  65  64  68  67\n",
      "   72  71  74  73  73  70  72  74  77  77  78  78  13  19  24  29  35  37\n",
      "   41  47  44  48  51  55  58  59  59  62 102 100 102  97  99  99  97  96\n",
      "   92  91  89  89  91  91  90  88  76  78  76  77  79  80  81  81  79  81\n",
      "   80  81  81  83  82  80  70  71  72  72  76  76  77  77  74  74  71  76\n",
      "   81  79  80  80 167 163 157 151 149 145 139 136 130 127 122 120 120 120\n",
      "  115 117  36  40  44  47  50  53  58  57  57  59  61  63  67  69  71  69\n",
      "   50  56  55  57  62  64  64  67  64  67  68  65  71  75  73  75  50  52\n",
      "   52  56  62  64  65  66  65  66  69  68  73  73  73  74  43  49  50  54\n",
      "   57  58  61  64  61  65  67  66  69  70  71  74  79  75  73  77  80  81\n",
      "   76  82  80  79  81  82  85  84  84  83  79  79  79  81  82  82  83  85\n",
      "   81  81  81  83  86  87  87  85]]\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "정답률= 1.0\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "------------------------------------------------------------------------------------------\n",
      "[[ 91  93  85  90  95  93  86  91  87  87  87  86  88  87  90  87  70  73\n",
      "   69  71  76  76  77  78  74  75  76  78  79  80  78  81  65  64  68  67\n",
      "   72  71  74  73  73  70  72  74  77  77  78  78  13  19  24  29  35  37\n",
      "   41  47  44  48  51  55  58  59  59  62 102 100 102  97  99  99  97  96\n",
      "   92  91  89  89  91  91  90  88  76  78  76  77  79  80  81  81  79  81\n",
      "   80  81  81  83  82  80  70  71  72  72  76  76  77  77  74  74  71  76\n",
      "   81  79  80  80 167 163 157 151 149 145 139 136 130 127 122 120 120 120\n",
      "  115 117  36  40  44  47  50  53  58  57  57  59  61  63  67  69  71  69\n",
      "   50  56  55  57  62  64  64  67  64  67  68  65  71  75  73  75  50  52\n",
      "   52  56  62  64  65  66  65  66  69  68  73  73  73  74  43  49  50  54\n",
      "   57  58  61  64  61  65  67  66  69  70  71  74  79  75  73  77  80  81\n",
      "   76  82  80  79  81  82  85  84  84  83  79  79  79  81  82  82  83  85\n",
      "   81  81  81  83  86  87  87  85]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Decision Tree classifier 예측치\n",
      "[[ 91  93  85  90  95  93  86  91  87  87  87  86  88  87  90  87  70  73\n",
      "   69  71  76  76  77  78  74  75  76  78  79  80  78  81  65  64  68  67\n",
      "   72  71  74  73  73  70  72  74  77  77  78  78  13  19  24  29  35  37\n",
      "   41  47  44  48  51  55  58  59  59  62 102 100 102  97  99  99  97  96\n",
      "   92  91  89  89  91  91  90  88  76  78  76  77  79  80  81  81  79  81\n",
      "   80  81  81  83  82  80  70  71  72  72  76  76  77  77  74  74  71  76\n",
      "   81  79  80  80 167 163 157 151 149 145 139 136 130 127 122 120 120 120\n",
      "  115 117  36  40  44  47  50  53  58  57  57  59  61  63  67  69  71  69\n",
      "   50  56  55  57  62  64  64  67  64  67  68  65  71  75  73  75  50  52\n",
      "   52  56  62  64  65  66  65  66  69  68  73  73  73  74  43  49  50  54\n",
      "   57  58  61  64  61  65  67  66  69  70  71  74  79  75  73  77  80  81\n",
      "   76  82  80  79  81  82  85  84  84  83  79  79  79  81  82  82  83  85\n",
      "   81  81  81  83  86  87  87  85]]\n",
      "------------------------------------------------------------------------------------------\n",
      "[[88, 88, 90, 92, 91, 91, 89, 92, 87, 88, 87, 88, 89, 90, 89, 90], [63, 63, 68, 68, 70, 71, 76, 75, 74, 74, 75, 75, 78, 78, 79, 80], [60, 62, 63, 66, 67, 69, 72, 76, 71, 73, 74, 79, 78, 79, 79, 83], [60, 62, 67, 66, 73, 69, 73, 72, 74, 73, 76, 75, 74, 79, 80, 80], [59, 60, 64, 66, 70, 70, 71, 73, 71, 73, 72, 75, 77, 82, 78, 74], [52, 54, 58, 62, 63, 66, 68, 70, 68, 70, 70, 73, 74, 75, 77, 78]]\n",
      "------------------------------------------------------------------------------------------\n",
      "y_test\n",
      "[[88, 88, 90, 92, 91, 91, 89, 92, 87, 88, 87, 88, 89, 90, 89, 90], [63, 63, 68, 68, 70, 71, 76, 75, 74, 74, 75, 75, 78, 78, 79, 80], [60, 62, 63, 66, 67, 69, 72, 76, 71, 73, 74, 79, 78, 79, 79, 83], [60, 62, 67, 66, 73, 69, 73, 72, 74, 73, 76, 75, 74, 79, 80, 80], [59, 60, 64, 66, 70, 70, 71, 73, 71, 73, 72, 75, 77, 82, 78, 74], [52, 54, 58, 62, 63, 66, 68, 70, 68, 70, 70, 73, 74, 75, 77, 78]]\n",
      "index: 0, value: [88, 88, 90, 92, 91, 91, 89, 92, 87, 88, 87, 88, 89, 90, 89, 90]\n",
      "index: 1, value: [63, 63, 68, 68, 70, 71, 76, 75, 74, 74, 75, 75, 78, 78, 79, 80]\n",
      "index: 2, value: [60, 62, 63, 66, 67, 69, 72, 76, 71, 73, 74, 79, 78, 79, 79, 83]\n",
      "index: 3, value: [60, 62, 67, 66, 73, 69, 73, 72, 74, 73, 76, 75, 74, 79, 80, 80]\n",
      "index: 4, value: [59, 60, 64, 66, 70, 70, 71, 73, 71, 73, 72, 75, 77, 82, 78, 74]\n",
      "index: 5, value: [52, 54, 58, 62, 63, 66, 68, 70, 68, 70, 70, 73, 74, 75, 77, 78]\n",
      "------------------------------------------------------------------------------------------\n",
      "y_pred1\n",
      "[[ 91  93  85  90  95  93  86  91  87  87  87  86  88  87  90  87  70  73\n",
      "   69  71  76  76  77  78  74  75  76  78  79  80  78  81  65  64  68  67\n",
      "   72  71  74  73  73  70  72  74  77  77  78  78  13  19  24  29  35  37\n",
      "   41  47  44  48  51  55  58  59  59  62 102 100 102  97  99  99  97  96\n",
      "   92  91  89  89  91  91  90  88  76  78  76  77  79  80  81  81  79  81\n",
      "   80  81  81  83  82  80  70  71  72  72  76  76  77  77  74  74  71  76\n",
      "   81  79  80  80 167 163 157 151 149 145 139 136 130 127 122 120 120 120\n",
      "  115 117  36  40  44  47  50  53  58  57  57  59  61  63  67  69  71  69\n",
      "   50  56  55  57  62  64  64  67  64  67  68  65  71  75  73  75  50  52\n",
      "   52  56  62  64  65  66  65  66  69  68  73  73  73  74  43  49  50  54\n",
      "   57  58  61  64  61  65  67  66  69  70  71  74  79  75  73  77  80  81\n",
      "   76  82  80  79  81  82  85  84  84  83  79  79  79  81  82  82  83  85\n",
      "   81  81  81  83  86  87  87  85]]\n",
      "------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------\n",
      "rows4\n",
      "index: 0, value: 0\n",
      "index: 1, value: 1\n",
      "index: 2, value: 2\n",
      "index: 3, value: 3\n",
      "index: 4, value: 4\n",
      "index: 5, value: 5\n",
      "index: 6, value: 6\n",
      "index: 7, value: 7\n",
      "index: 8, value: 8\n",
      "index: 9, value: 9\n",
      "index: 10, value: 10\n",
      "index: 11, value: 11\n",
      "index: 12, value: 12\n",
      "index: 13, value: 13\n",
      "index: 14, value: 14\n",
      "index: 15, value: 15\n",
      "index: 16, value: 16\n",
      "index: 17, value: 17\n",
      "index: 18, value: 18\n",
      "index: 19, value: 19\n",
      "index: 20, value: 20\n",
      "index: 21, value: 21\n",
      "index: 22, value: 22\n",
      "index: 23, value: 23\n",
      "index: 24, value: 24\n",
      "index: 25, value: 25\n",
      "index: 26, value: 26\n",
      "index: 27, value: 27\n",
      "index: 28, value: 28\n",
      "index: 29, value: 29\n",
      "index: 30, value: 30\n",
      "index: 31, value: 31\n",
      "index: 32, value: 32\n",
      "index: 33, value: 33\n",
      "index: 34, value: 34\n",
      "index: 35, value: 35\n",
      "index: 36, value: 36\n",
      "index: 37, value: 37\n",
      "index: 38, value: 38\n",
      "index: 39, value: 39\n",
      "index: 40, value: 40\n",
      "index: 41, value: 41\n",
      "index: 42, value: 42\n",
      "index: 43, value: 43\n",
      "index: 44, value: 44\n",
      "index: 45, value: 45\n",
      "index: 46, value: 46\n",
      "index: 47, value: 47\n",
      "index: 48, value: 48\n",
      "index: 49, value: 49\n",
      "index: 50, value: 50\n",
      "index: 51, value: 51\n",
      "index: 52, value: 52\n",
      "index: 53, value: 53\n",
      "index: 54, value: 54\n",
      "index: 55, value: 55\n",
      "index: 56, value: 56\n",
      "index: 57, value: 57\n",
      "index: 58, value: 58\n",
      "index: 59, value: 59\n",
      "index: 60, value: 60\n",
      "index: 61, value: 61\n",
      "index: 62, value: 62\n",
      "index: 63, value: 63\n",
      "index: 64, value: 64\n",
      "index: 65, value: 65\n",
      "index: 66, value: 66\n",
      "index: 67, value: 67\n",
      "index: 68, value: 68\n",
      "index: 69, value: 69\n",
      "index: 70, value: 70\n",
      "index: 71, value: 71\n",
      "index: 72, value: 72\n",
      "index: 73, value: 73\n",
      "index: 74, value: 74\n",
      "index: 75, value: 75\n",
      "index: 76, value: 76\n",
      "index: 77, value: 77\n",
      "index: 78, value: 78\n",
      "index: 79, value: 79\n",
      "index: 80, value: 80\n",
      "index: 81, value: 81\n",
      "index: 82, value: 82\n",
      "index: 83, value: 83\n",
      "index: 84, value: 84\n",
      "index: 85, value: 85\n",
      "index: 86, value: 86\n",
      "index: 87, value: 87\n",
      "index: 88, value: 88\n",
      "index: 89, value: 89\n",
      "index: 90, value: 90\n",
      "index: 91, value: 91\n",
      "index: 92, value: 92\n",
      "index: 93, value: 93\n",
      "index: 94, value: 94\n",
      "index: 95, value: 95\n",
      "index: 96, value: 96\n",
      "index: 97, value: 97\n",
      "index: 98, value: 98\n",
      "index: 99, value: 99\n",
      "index: 100, value: 100\n",
      "index: 101, value: 101\n",
      "index: 102, value: 102\n",
      "index: 103, value: 103\n",
      "index: 104, value: 104\n",
      "index: 105, value: 105\n",
      "index: 106, value: 106\n",
      "index: 107, value: 107\n",
      "index: 108, value: 108\n",
      "index: 109, value: 109\n",
      "index: 110, value: 110\n",
      "index: 111, value: 111\n",
      "index: 112, value: 112\n",
      "index: 113, value: 113\n",
      "index: 114, value: 114\n",
      "index: 115, value: 115\n",
      "index: 116, value: 116\n",
      "index: 117, value: 117\n",
      "index: 118, value: 118\n",
      "index: 119, value: 119\n",
      "index: 120, value: 120\n",
      "index: 121, value: 121\n",
      "index: 122, value: 122\n",
      "index: 123, value: 123\n",
      "index: 124, value: 124\n",
      "index: 125, value: 125\n",
      "index: 126, value: 126\n",
      "index: 127, value: 127\n",
      "index: 128, value: 128\n",
      "index: 129, value: 129\n",
      "index: 130, value: 130\n",
      "index: 131, value: 131\n",
      "index: 132, value: 132\n",
      "index: 133, value: 133\n",
      "index: 134, value: 134\n",
      "index: 135, value: 135\n",
      "index: 136, value: 136\n",
      "index: 137, value: 137\n",
      "index: 138, value: 138\n",
      "index: 139, value: 139\n",
      "index: 140, value: 140\n",
      "index: 141, value: 141\n",
      "index: 142, value: 142\n",
      "index: 143, value: 143\n",
      "index: 144, value: 144\n",
      "index: 145, value: 145\n",
      "index: 146, value: 146\n",
      "index: 147, value: 147\n",
      "index: 148, value: 148\n",
      "index: 149, value: 149\n",
      "index: 150, value: 150\n",
      "index: 151, value: 151\n",
      "index: 152, value: 152\n",
      "index: 153, value: 153\n",
      "index: 154, value: 154\n",
      "index: 155, value: 155\n",
      "index: 156, value: 156\n",
      "index: 157, value: 157\n",
      "index: 158, value: 158\n",
      "index: 159, value: 159\n",
      "index: 160, value: 160\n",
      "index: 161, value: 161\n",
      "index: 162, value: 162\n",
      "index: 163, value: 163\n",
      "index: 164, value: 164\n",
      "index: 165, value: 165\n",
      "index: 166, value: 166\n",
      "index: 167, value: 167\n",
      "index: 168, value: 168\n",
      "index: 169, value: 169\n",
      "index: 170, value: 170\n",
      "index: 171, value: 171\n",
      "index: 172, value: 172\n",
      "index: 173, value: 173\n",
      "index: 174, value: 174\n",
      "index: 175, value: 175\n",
      "index: 176, value: 176\n",
      "index: 177, value: 177\n",
      "index: 178, value: 178\n",
      "index: 179, value: 179\n",
      "index: 180, value: 180\n",
      "index: 181, value: 181\n",
      "index: 182, value: 182\n",
      "index: 183, value: 183\n",
      "index: 184, value: 184\n",
      "index: 185, value: 185\n",
      "index: 186, value: 186\n",
      "index: 187, value: 187\n",
      "index: 188, value: 188\n",
      "index: 189, value: 189\n",
      "index: 190, value: 190\n",
      "index: 191, value: 191\n",
      "index: 192, value: 192\n",
      "index: 193, value: 193\n",
      "index: 194, value: 194\n",
      "index: 195, value: 195\n",
      "index: 196, value: 196\n",
      "index: 197, value: 197\n",
      "index: 198, value: 198\n",
      "index: 199, value: 199\n",
      "index: 200, value: 200\n",
      "index: 201, value: 201\n",
      "index: 202, value: 202\n",
      "index: 203, value: 203\n",
      "index: 204, value: 204\n",
      "index: 205, value: 205\n",
      "index: 206, value: 206\n",
      "index: 207, value: 207\n",
      "index: 208, value: 208\n",
      "index: 209, value: 209\n",
      "index: 210, value: 210\n",
      "index: 211, value: 211\n",
      "index: 212, value: 212\n",
      "index: 213, value: 213\n",
      "index: 214, value: 214\n",
      "index: 215, value: 215\n",
      "index: 216, value: 216\n",
      "index: 217, value: 217\n",
      "index: 218, value: 218\n",
      "index: 219, value: 219\n",
      "index: 220, value: 220\n",
      "index: 221, value: 221\n",
      "index: 222, value: 222\n",
      "index: 223, value: 223\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  214  215  216  217  \\\n",
      "0   91   93   85   90   95   93   86   91   87   87  ...   83   85   81   81   \n",
      "\n",
      "   218  219  220  221  222  223  \n",
      "0   81   83   86   87   87   85  \n",
      "\n",
      "[1 rows x 224 columns]\n",
      "------------------------------------------------------------------------------------------\n",
      "rows5\n",
      "   0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15\n",
      "0  88  88  90  92  91  91  89  92  87  88  87  88  89  90  89  90\n",
      "1  63  63  68  68  70  71  76  75  74  74  75  75  78  78  79  80\n",
      "2  60  62  63  66  67  69  72  76  71  73  74  79  78  79  79  83\n",
      "3  60  62  67  66  73  69  73  72  74  73  76  75  74  79  80  80\n",
      "4  59  60  64  66  70  70  71  73  71  73  72  75  77  82  78  74\n",
      "5  52  54  58  62  63  66  68  70  68  70  70  73  74  75  77  78\n",
      "------------------------------------------------------------------------------------------\n",
      "roww2\n",
      "[88 88 90 92 91 91 89 92 87 88 87 88 89 90 89 90 63 63 68 68 70 71 76 75\n",
      " 74 74 75 75 78 78 79 80 60 62 63 66 67 69 72 76 71 73 74 79 78 79 79 83\n",
      " 60 62 67 66 73 69 73 72 74 73 76 75 74 79 80 80 59 60 64 66 70 70 71 73\n",
      " 71 73 72 75 77 82 78 74 52 54 58 62 63 66 68 70 68 70 70 73 74 75 77 78]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 96]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14/1272359087.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'roww2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroww2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroww3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    191\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    570\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 96]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "# 데이터셋 로드하기\n",
    "# [[your code]\n",
    "data = rows\n",
    "data2 = rows2\n",
    "# 훈련용 데이터셋 나누기\n",
    "# [[your code]\n",
    "X_train = rows[:14]\n",
    "X_test = rows[14:]\n",
    "\n",
    "y_train = data[:14]\n",
    "y_test = data[14:]\n",
    "\n",
    "print(\"y_train\")\n",
    "print(y_train)\n",
    "print('-'*90)\n",
    "print('-'*90)\n",
    "print(\"X_train\")\n",
    "print(X_train)\n",
    "# y_test2 = data2[:16]\n",
    "# y_test2 = y_test2.reshape(16,4)\n",
    "# 훈련하기\n",
    "# [[your code]\n",
    "print('-/'*90)\n",
    "print('-/'*90)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "# X2, y2 = make_classification(n_samples=1000, n_features=4,\n",
    "#                              n_informative=2, n_redundant=0,\n",
    "#                              random_state=0, shuffle=False)\n",
    "# clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "# clf.fit(X2, y2)\n",
    "# print(X2)\n",
    "# print('-/'*90)\n",
    "# print('-/'*90)\n",
    "xtt = np.array(X_train)\n",
    "xt = xtt.reshape(-1,)\n",
    "ytt = np.array(y_train) #numpy array 로 바꿈!!\n",
    "yt = ytt.reshape(-1,) # numpy array 차원 축소!!! 1차원으로 만들어주기\n",
    "print(\"xt\")\n",
    "print(xt)\n",
    "print('-'*90)\n",
    "print(\"yt\")\n",
    "print(yt)\n",
    "print('-'*90)\n",
    "\n",
    "xt = np.expand_dims(xt, axis=0) # 차원 확대\n",
    "yt = np.expand_dims(yt, axis=0) # 차원 확대 \n",
    "np.expand_dims(xt, axis=0)\n",
    "np.expand_dims(yt, axis=0)\n",
    "\n",
    "print(\"xt\")\n",
    "print(xt)\n",
    "print('-'*90)\n",
    "print(\"yt\")\n",
    "print(yt)\n",
    "print('-'*90)\n",
    "print('-*'*90)\n",
    "# clf = MultiOutputClassifier(KNeighborsClassifier()).fit(xt,yt) # 2차원 이상의 배열이 필요함...\n",
    "knn = KNeighborsClassifier(n_neighbors=4)#여기에서 n_neighbers =1 이 중요!!! 입력 데이터 형태를 보면 1로 해야함\n",
    "knn = MultiOutputClassifier(KNeighborsClassifier(n_neighbors=1)).fit(xt,yt) #2차원 필요\n",
    "print(\"knn 예측치\")\n",
    "knnmaster1 = knn.predict(xt[-1:]) #We select the training set with the [:-1] Python syntax,\n",
    "#which produces a new array that contains all but the last item from digits.data:\n",
    "print(knnmaster1)\n",
    "print('-*'*90)\n",
    "\n",
    "\n",
    "print(\"정답률=\", knn.score(y_pred2, xt)) ###########################\n",
    "\n",
    "\n",
    "print('-*'*90)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(xt, yt)\n",
    "print('-'*90)\n",
    "# 예측하기\n",
    "# [[your code]\n",
    "y_pred1 = model.predict(xt)\n",
    "# 정답률 출력하기\n",
    "# [[your code]\n",
    "print(y_pred1)\n",
    "print('-'*90)\n",
    "decision_tree = DecisionTreeClassifier(random_state=1)\n",
    "decision_tree.fit(xt, yt)\n",
    "y_pred2 = decision_tree.predict(xt)\n",
    "print(\"Decision Tree classifier 예측치\")\n",
    "print(y_pred2)\n",
    "print('-'*90)\n",
    "\n",
    "y_testt = np.transpose(y_test)\n",
    "print(y_test)\n",
    "print('-'*90)\n",
    "#y_test = np.expand_dims(y_test, axis=0)\n",
    "\n",
    "print('y_test')\n",
    "print(y_test)\n",
    "for idx, value in enumerate(y_test):\n",
    "    print(f'index: {idx}, value: {value}')\n",
    "\n",
    "print('-'*90)\n",
    "print('y_pred1')\n",
    "print(y_pred1)\n",
    "print('-'*90)\n",
    "print('-'*90)\n",
    "print('rows4')\n",
    "for idx, value in enumerate(rows4):\n",
    "    print(f'index: {idx}, value: {value}')\n",
    "    \n",
    "from sklearn import svm\n",
    "#먼저 y_pred 의 shape 은?\n",
    "# for i in y_pred1[1:]:\n",
    "#     rows4.append(list(map(int,i.split(\",\"))))\n",
    "rows4 = pd.DataFrame(y_pred1)\n",
    "rows6 = pd.DataFrame(y_pred2)\n",
    "rows5 = pd.DataFrame(y_test)\n",
    "rows7=[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "print(rows4) #y예측치\n",
    "print('-'*90)\n",
    "print('rows5')\n",
    "print(rows5) #y test\n",
    "clf = svm.SVC()\n",
    "print('-'*90)\n",
    "#roww1 = rows5.reshape(-1,) #dataframe 오류 \n",
    "#roww1 = y_test.reshape(-1,) # list 는 reshape 이 없다... np.array 로 바꿔주기\n",
    "roww1 = np.array(y_test)\n",
    "roww2 = roww1.reshape(-1,)\n",
    "roww3 = pd.DataFrame(roww2)\n",
    "roww4 = y_pred1.reshape(-1,)\n",
    "print('roww2')\n",
    "print(roww2)\n",
    "clf.fit(rows4,roww3)\n",
    "print('-'*90)\n",
    "\n",
    "print('-'*90)\n",
    "print(\"정답률=\", clf.score(rows4, rows5))\n",
    "# from sklearn.datasets import make_blobs\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# X,y = make_multilabel_classification(n_classes= 3,random_state = 0)\n",
    "\n",
    "# clf.predict(X[-2:])\n",
    "\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=3)\n",
    "# classifier = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "# classifier.fit(y_test,y_pred)\n",
    "# predictions = classifier.predict(y_train)\n",
    "# classifier.score(y_true,np.array(y_train))\n",
    "\n",
    "# from sklearn.linear_model import RidgeClassifierCV\n",
    "# clf = RidgeClassifierCV().fit(X_train, y_train)\n",
    "# y_score = clf.decision_function(X_train)\n",
    "# roc_auc_score(y_test, y_train, average=None)\n",
    "\n",
    "# from sklearn.datasets import make_multilabel_classification\n",
    "# from sklearn.multioutput import MultiOutputClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# X, y = make_multilabel_classification(random_state=0)\n",
    "# inner_clf = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "# clf = MultiOutputClassifier(inner_clf).fit(X, y)\n",
    "# y_score = np.transpose([y_pred[:, 1] for y_pred in clf.predict_proba(X)])\n",
    "# roc_auc_score(y, y_score, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bcaf63f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeClassifierCV\n",
    "# clf = RidgeClassifierCV().fit(X_train, y_train)\n",
    "\n",
    "# roc_auc_score(rows4, rows5, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91781e3",
   "metadata": {},
   "source": [
    "\n",
    "#열이 16개인 데이터셋\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea763f15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
