{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a798d813",
   "metadata": {
    "id": "623bcb1c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2364b14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bb154148",
    "outputId": "63de069d-3b2f-4d09-bafb-785e3f0aa134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16, 19, 23, 27, 34, 36, 40, 44, 41, 46, 48, 51, 56, 58, 58, 62,2\n",
      " 79, 80, 80, 80, 82, 81, 81, 81, 78, 80, 79, 79, 80, 83, 82, 82,0\n",
      "\n",
      " 0, 0, 6, 11, 20, 24, 30, 33, 34, 40, 42, 45, 49, 53, 56, 59,1\n",
      "\n",
      " 51, 45, 35, 29, 17, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,2\n",
      "\n",
      " 0, 0, 0, 4, 11, 16, 21, 28, 26, 32, 36, 39, 49, 43, 52, 52,2\n",
      "\n",
      " 15, 16, 12, 12, 11, 7, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0,2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(\"jimin1.csv\", 'r', encoding=\"utf-8\") as read_: #read다음에_는 의미가 없다. read랑 헷갈리지말라고 쓴 것. a 라고 해도 무방.\n",
    "    text=read_.readlines()\n",
    "\n",
    "rows=[]\n",
    "for i in text[1:]:\n",
    "    rows.append(list(map(int,i.split(\",\")))) # 이름으로 끝나기 때문에 , 가 없다 그래서 -1로 슬라이싱 해준다.\n",
    "print(i)\n",
    "\n",
    "df=pd.DataFrame(rows)\n",
    "df.columns=[\"sensor%d\"%i for i in range(1,18)]\n",
    "\n",
    "with open(\"seong2.csv\", 'r', encoding=\"utf-8\") as read_:\n",
    "    text2=read_.readlines()\n",
    "    \n",
    "\n",
    "rows2=[]\n",
    "for i in text2[1:]:\n",
    "    rows2.append(list(map(int,i.split(\",\"))))\n",
    "print(i)\n",
    "\n",
    "with open(\"yeon2.csv\", 'r', encoding=\"utf-8\") as read_:\n",
    "    text3=read_.readlines()\n",
    "    \n",
    "rows9=[]\n",
    "for i in text3[1:]:\n",
    "    rows9.append(list(map(int,i.split(\",\"))))\n",
    "print(i)\n",
    "\n",
    "df2=pd.DataFrame(rows2)\n",
    "df2.columns=[\"sensor%d\"%i for i in range(1,18)]\n",
    "\n",
    "\n",
    "df3=pd.DataFrame(rows9)\n",
    "df3.columns=[\"sensor%d\"%i for i in range(1,18)]\n",
    "\n",
    "# \n",
    "\n",
    "with open(\"yeon3.csv\", 'r', encoding=\"utf-8\") as read_:\n",
    "    text4=read_.readlines()\n",
    "    \n",
    "rows111=[]\n",
    "for i in text4[1:]:\n",
    "    rows111.append(list(map(int,i.split(\",\"))))\n",
    "print(i)\n",
    "\n",
    "df4=pd.DataFrame(rows111)\n",
    "df4.columns=[\"sensor%d\"%i for i in range(1,18)]\n",
    "\n",
    "\n",
    "#\n",
    "with open(\"jimin3.csv\", 'r', encoding=\"utf-8\") as read_:\n",
    "    text5=read_.readlines()\n",
    "    \n",
    "rows110=[]\n",
    "for i in text5[1:]:\n",
    "    rows110.append(list(map(int,i.split(\",\"))))\n",
    "print(i)\n",
    "\n",
    "df5=pd.DataFrame(rows110)\n",
    "df5.columns=[\"sensor%d\"%i for i in range(1,18)]\n",
    "\n",
    "#\n",
    "with open(\"seong3.csv\", 'r', encoding=\"utf-8\") as read_:\n",
    "    text6=read_.readlines()\n",
    "    \n",
    "rows100=[]\n",
    "for i in text6[1:]:\n",
    "    rows100.append(list(map(int,i.split(\",\"))))\n",
    "print(i)\n",
    "\n",
    "df6=pd.DataFrame(rows100)\n",
    "df6.columns=[\"sensor%d\"%i for i in range(1,18)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d6b1759",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "21d82055",
    "outputId": "d43af487-ac4a-434c-e46c-a37cb952f47d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>414</td>\n",
       "      <td>385</td>\n",
       "      <td>337</td>\n",
       "      <td>303</td>\n",
       "      <td>268</td>\n",
       "      <td>250</td>\n",
       "      <td>227</td>\n",
       "      <td>201</td>\n",
       "      <td>174</td>\n",
       "      <td>144</td>\n",
       "      <td>127</td>\n",
       "      <td>117</td>\n",
       "      <td>94</td>\n",
       "      <td>85</td>\n",
       "      <td>71</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>751</td>\n",
       "      <td>725</td>\n",
       "      <td>688</td>\n",
       "      <td>654</td>\n",
       "      <td>633</td>\n",
       "      <td>603</td>\n",
       "      <td>582</td>\n",
       "      <td>548</td>\n",
       "      <td>532</td>\n",
       "      <td>509</td>\n",
       "      <td>483</td>\n",
       "      <td>472</td>\n",
       "      <td>451</td>\n",
       "      <td>437</td>\n",
       "      <td>428</td>\n",
       "      <td>402</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>209</td>\n",
       "      <td>216</td>\n",
       "      <td>225</td>\n",
       "      <td>233</td>\n",
       "      <td>234</td>\n",
       "      <td>240</td>\n",
       "      <td>238</td>\n",
       "      <td>242</td>\n",
       "      <td>232</td>\n",
       "      <td>234</td>\n",
       "      <td>236</td>\n",
       "      <td>232</td>\n",
       "      <td>229</td>\n",
       "      <td>235</td>\n",
       "      <td>230</td>\n",
       "      <td>237</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>740</td>\n",
       "      <td>687</td>\n",
       "      <td>638</td>\n",
       "      <td>597</td>\n",
       "      <td>558</td>\n",
       "      <td>531</td>\n",
       "      <td>499</td>\n",
       "      <td>476</td>\n",
       "      <td>437</td>\n",
       "      <td>410</td>\n",
       "      <td>401</td>\n",
       "      <td>364</td>\n",
       "      <td>355</td>\n",
       "      <td>322</td>\n",
       "      <td>313</td>\n",
       "      <td>294</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>775</td>\n",
       "      <td>736</td>\n",
       "      <td>719</td>\n",
       "      <td>692</td>\n",
       "      <td>664</td>\n",
       "      <td>648</td>\n",
       "      <td>617</td>\n",
       "      <td>602</td>\n",
       "      <td>580</td>\n",
       "      <td>563</td>\n",
       "      <td>548</td>\n",
       "      <td>530</td>\n",
       "      <td>516</td>\n",
       "      <td>497</td>\n",
       "      <td>467</td>\n",
       "      <td>431</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>94</td>\n",
       "      <td>86</td>\n",
       "      <td>95</td>\n",
       "      <td>89</td>\n",
       "      <td>95</td>\n",
       "      <td>106</td>\n",
       "      <td>111</td>\n",
       "      <td>118</td>\n",
       "      <td>109</td>\n",
       "      <td>115</td>\n",
       "      <td>120</td>\n",
       "      <td>122</td>\n",
       "      <td>131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>51</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sensor1  sensor2  sensor3  sensor4  sensor5  sensor6  sensor7  sensor8  \\\n",
       "0        414      385      337      303      268      250      227      201   \n",
       "1        751      725      688      654      633      603      582      548   \n",
       "2        209      216      225      233      234      240      238      242   \n",
       "3          0        0        0        0       11       13       13       24   \n",
       "4          0        0        0        0        0        0        0        0   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "257      740      687      638      597      558      531      499      476   \n",
       "258      775      736      719      692      664      648      617      602   \n",
       "259       63       66       66       94       86       95       89       95   \n",
       "260        0        0        0        3        0        6        7       16   \n",
       "261       51       45       35       29       17       11        0        0   \n",
       "\n",
       "     sensor9  sensor10  sensor11  sensor12  sensor13  sensor14  sensor15  \\\n",
       "0        174       144       127       117        94        85        71   \n",
       "1        532       509       483       472       451       437       428   \n",
       "2        232       234       236       232       229       235       230   \n",
       "3         20        24        28        27        39        36        34   \n",
       "4          0         0         0         0         0         0         0   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "257      437       410       401       364       355       322       313   \n",
       "258      580       563       548       530       516       497       467   \n",
       "259      106       111       118       109       115       120       122   \n",
       "260       19         6        23        22        25        27        23   \n",
       "261        0         0         0         0         0         0         0   \n",
       "\n",
       "     sensor16  sensor17  \n",
       "0          63         2  \n",
       "1         402         2  \n",
       "2         237         2  \n",
       "3          43         2  \n",
       "4           0         2  \n",
       "..        ...       ...  \n",
       "257       294         2  \n",
       "258       431         2  \n",
       "259       131         2  \n",
       "260        27         2  \n",
       "261         0         2  \n",
       "\n",
       "[262 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d6b7b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.sensor17 =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae4449e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>414</td>\n",
       "      <td>385</td>\n",
       "      <td>337</td>\n",
       "      <td>303</td>\n",
       "      <td>268</td>\n",
       "      <td>250</td>\n",
       "      <td>227</td>\n",
       "      <td>201</td>\n",
       "      <td>174</td>\n",
       "      <td>144</td>\n",
       "      <td>127</td>\n",
       "      <td>117</td>\n",
       "      <td>94</td>\n",
       "      <td>85</td>\n",
       "      <td>71</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>751</td>\n",
       "      <td>725</td>\n",
       "      <td>688</td>\n",
       "      <td>654</td>\n",
       "      <td>633</td>\n",
       "      <td>603</td>\n",
       "      <td>582</td>\n",
       "      <td>548</td>\n",
       "      <td>532</td>\n",
       "      <td>509</td>\n",
       "      <td>483</td>\n",
       "      <td>472</td>\n",
       "      <td>451</td>\n",
       "      <td>437</td>\n",
       "      <td>428</td>\n",
       "      <td>402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>209</td>\n",
       "      <td>216</td>\n",
       "      <td>225</td>\n",
       "      <td>233</td>\n",
       "      <td>234</td>\n",
       "      <td>240</td>\n",
       "      <td>238</td>\n",
       "      <td>242</td>\n",
       "      <td>232</td>\n",
       "      <td>234</td>\n",
       "      <td>236</td>\n",
       "      <td>232</td>\n",
       "      <td>229</td>\n",
       "      <td>235</td>\n",
       "      <td>230</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>740</td>\n",
       "      <td>687</td>\n",
       "      <td>638</td>\n",
       "      <td>597</td>\n",
       "      <td>558</td>\n",
       "      <td>531</td>\n",
       "      <td>499</td>\n",
       "      <td>476</td>\n",
       "      <td>437</td>\n",
       "      <td>410</td>\n",
       "      <td>401</td>\n",
       "      <td>364</td>\n",
       "      <td>355</td>\n",
       "      <td>322</td>\n",
       "      <td>313</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>775</td>\n",
       "      <td>736</td>\n",
       "      <td>719</td>\n",
       "      <td>692</td>\n",
       "      <td>664</td>\n",
       "      <td>648</td>\n",
       "      <td>617</td>\n",
       "      <td>602</td>\n",
       "      <td>580</td>\n",
       "      <td>563</td>\n",
       "      <td>548</td>\n",
       "      <td>530</td>\n",
       "      <td>516</td>\n",
       "      <td>497</td>\n",
       "      <td>467</td>\n",
       "      <td>431</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>94</td>\n",
       "      <td>86</td>\n",
       "      <td>95</td>\n",
       "      <td>89</td>\n",
       "      <td>95</td>\n",
       "      <td>106</td>\n",
       "      <td>111</td>\n",
       "      <td>118</td>\n",
       "      <td>109</td>\n",
       "      <td>115</td>\n",
       "      <td>120</td>\n",
       "      <td>122</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>51</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sensor1  sensor2  sensor3  sensor4  sensor5  sensor6  sensor7  sensor8  \\\n",
       "0        414      385      337      303      268      250      227      201   \n",
       "1        751      725      688      654      633      603      582      548   \n",
       "2        209      216      225      233      234      240      238      242   \n",
       "3          0        0        0        0       11       13       13       24   \n",
       "4          0        0        0        0        0        0        0        0   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "257      740      687      638      597      558      531      499      476   \n",
       "258      775      736      719      692      664      648      617      602   \n",
       "259       63       66       66       94       86       95       89       95   \n",
       "260        0        0        0        3        0        6        7       16   \n",
       "261       51       45       35       29       17       11        0        0   \n",
       "\n",
       "     sensor9  sensor10  sensor11  sensor12  sensor13  sensor14  sensor15  \\\n",
       "0        174       144       127       117        94        85        71   \n",
       "1        532       509       483       472       451       437       428   \n",
       "2        232       234       236       232       229       235       230   \n",
       "3         20        24        28        27        39        36        34   \n",
       "4          0         0         0         0         0         0         0   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "257      437       410       401       364       355       322       313   \n",
       "258      580       563       548       530       516       497       467   \n",
       "259      106       111       118       109       115       120       122   \n",
       "260       19         6        23        22        25        27        23   \n",
       "261        0         0         0         0         0         0         0   \n",
       "\n",
       "     sensor16  sensor17  \n",
       "0          63         1  \n",
       "1         402         1  \n",
       "2         237         1  \n",
       "3          43         1  \n",
       "4           0         1  \n",
       "..        ...       ...  \n",
       "257       294         1  \n",
       "258       431         1  \n",
       "259       131         1  \n",
       "260        27         1  \n",
       "261         0         1  \n",
       "\n",
       "[262 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fcc75d9",
   "metadata": {
    "id": "c075c9c2"
   },
   "outputs": [],
   "source": [
    "df = df.iloc[:255,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c499de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.iloc[:255,]\n",
    "df5 = df5.iloc[:255,]\n",
    "df6 = df6.iloc[:255,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9a7081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.sensor17 = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0af39ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700</td>\n",
       "      <td>668</td>\n",
       "      <td>630</td>\n",
       "      <td>600</td>\n",
       "      <td>575</td>\n",
       "      <td>543</td>\n",
       "      <td>518</td>\n",
       "      <td>494</td>\n",
       "      <td>466</td>\n",
       "      <td>445</td>\n",
       "      <td>421</td>\n",
       "      <td>405</td>\n",
       "      <td>387</td>\n",
       "      <td>367</td>\n",
       "      <td>355</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161</td>\n",
       "      <td>165</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>164</td>\n",
       "      <td>160</td>\n",
       "      <td>169</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>164</td>\n",
       "      <td>161</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>172</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>63</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>552</td>\n",
       "      <td>511</td>\n",
       "      <td>472</td>\n",
       "      <td>434</td>\n",
       "      <td>406</td>\n",
       "      <td>372</td>\n",
       "      <td>346</td>\n",
       "      <td>322</td>\n",
       "      <td>290</td>\n",
       "      <td>271</td>\n",
       "      <td>247</td>\n",
       "      <td>231</td>\n",
       "      <td>213</td>\n",
       "      <td>196</td>\n",
       "      <td>184</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>755</td>\n",
       "      <td>710</td>\n",
       "      <td>655</td>\n",
       "      <td>616</td>\n",
       "      <td>579</td>\n",
       "      <td>542</td>\n",
       "      <td>517</td>\n",
       "      <td>477</td>\n",
       "      <td>446</td>\n",
       "      <td>415</td>\n",
       "      <td>388</td>\n",
       "      <td>371</td>\n",
       "      <td>353</td>\n",
       "      <td>330</td>\n",
       "      <td>315</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>598</td>\n",
       "      <td>582</td>\n",
       "      <td>562</td>\n",
       "      <td>545</td>\n",
       "      <td>533</td>\n",
       "      <td>508</td>\n",
       "      <td>496</td>\n",
       "      <td>482</td>\n",
       "      <td>465</td>\n",
       "      <td>454</td>\n",
       "      <td>450</td>\n",
       "      <td>436</td>\n",
       "      <td>427</td>\n",
       "      <td>415</td>\n",
       "      <td>399</td>\n",
       "      <td>372</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>58</td>\n",
       "      <td>69</td>\n",
       "      <td>63</td>\n",
       "      <td>78</td>\n",
       "      <td>76</td>\n",
       "      <td>90</td>\n",
       "      <td>89</td>\n",
       "      <td>98</td>\n",
       "      <td>97</td>\n",
       "      <td>90</td>\n",
       "      <td>105</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>112</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sensor1  sensor2  sensor3  sensor4  sensor5  sensor6  sensor7  sensor8  \\\n",
       "0        700      668      630      600      575      543      518      494   \n",
       "1        161      165      155      157      164      160      169      160   \n",
       "2          0        0        0        8       20       23       30       36   \n",
       "3          0        0        0        0        9        7       19       19   \n",
       "4        552      511      472      434      406      372      346      322   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "280      755      710      655      616      579      542      517      477   \n",
       "281      598      582      562      545      533      508      496      482   \n",
       "282       58       69       63       78       76       90       89       98   \n",
       "283        0        0        0        0        6        7        6       13   \n",
       "284       15       16       12       12       11        7        5        4   \n",
       "\n",
       "     sensor9  sensor10  sensor11  sensor12  sensor13  sensor14  sensor15  \\\n",
       "0        466       445       421       405       387       367       355   \n",
       "1        162       164       161       169       169       169       172   \n",
       "2         39        41        46        52        58        60        63   \n",
       "3         16        24        20        28        37        40        44   \n",
       "4        290       271       247       231       213       196       184   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "280      446       415       388       371       353       330       315   \n",
       "281      465       454       450       436       427       415       399   \n",
       "282       97        90       105       103       104       112       109   \n",
       "283       16        26        27        25        33        33        38   \n",
       "284        0         0         0         0         0         0         0   \n",
       "\n",
       "     sensor16  sensor17  \n",
       "0         333         0  \n",
       "1         168         0  \n",
       "2          57         0  \n",
       "3          40         0  \n",
       "4         173         0  \n",
       "..        ...       ...  \n",
       "280       302         0  \n",
       "281       372         0  \n",
       "282       109         0  \n",
       "283        39         0  \n",
       "284         0         0  \n",
       "\n",
       "[285 rows x 17 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae240ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>65</td>\n",
       "      <td>72</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>611</td>\n",
       "      <td>558</td>\n",
       "      <td>512</td>\n",
       "      <td>475</td>\n",
       "      <td>440</td>\n",
       "      <td>408</td>\n",
       "      <td>378</td>\n",
       "      <td>344</td>\n",
       "      <td>314</td>\n",
       "      <td>291</td>\n",
       "      <td>266</td>\n",
       "      <td>249</td>\n",
       "      <td>225</td>\n",
       "      <td>207</td>\n",
       "      <td>184</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769</td>\n",
       "      <td>742</td>\n",
       "      <td>701</td>\n",
       "      <td>666</td>\n",
       "      <td>637</td>\n",
       "      <td>593</td>\n",
       "      <td>559</td>\n",
       "      <td>531</td>\n",
       "      <td>499</td>\n",
       "      <td>480</td>\n",
       "      <td>450</td>\n",
       "      <td>436</td>\n",
       "      <td>422</td>\n",
       "      <td>411</td>\n",
       "      <td>398</td>\n",
       "      <td>385</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>134</td>\n",
       "      <td>126</td>\n",
       "      <td>121</td>\n",
       "      <td>134</td>\n",
       "      <td>123</td>\n",
       "      <td>131</td>\n",
       "      <td>126</td>\n",
       "      <td>135</td>\n",
       "      <td>145</td>\n",
       "      <td>158</td>\n",
       "      <td>162</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>567</td>\n",
       "      <td>522</td>\n",
       "      <td>491</td>\n",
       "      <td>448</td>\n",
       "      <td>418</td>\n",
       "      <td>386</td>\n",
       "      <td>352</td>\n",
       "      <td>330</td>\n",
       "      <td>300</td>\n",
       "      <td>272</td>\n",
       "      <td>249</td>\n",
       "      <td>227</td>\n",
       "      <td>212</td>\n",
       "      <td>188</td>\n",
       "      <td>174</td>\n",
       "      <td>147</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>751</td>\n",
       "      <td>708</td>\n",
       "      <td>658</td>\n",
       "      <td>621</td>\n",
       "      <td>591</td>\n",
       "      <td>561</td>\n",
       "      <td>537</td>\n",
       "      <td>514</td>\n",
       "      <td>485</td>\n",
       "      <td>469</td>\n",
       "      <td>448</td>\n",
       "      <td>437</td>\n",
       "      <td>417</td>\n",
       "      <td>397</td>\n",
       "      <td>388</td>\n",
       "      <td>370</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>106</td>\n",
       "      <td>117</td>\n",
       "      <td>115</td>\n",
       "      <td>126</td>\n",
       "      <td>138</td>\n",
       "      <td>144</td>\n",
       "      <td>156</td>\n",
       "      <td>150</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>158</td>\n",
       "      <td>156</td>\n",
       "      <td>153</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>158</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sensor1  sensor2  sensor3  sensor4  sensor5  sensor6  sensor7  sensor8  \\\n",
       "0          0        0        0        7       13       12       30       26   \n",
       "1          0        0        0        0        0        0        0        0   \n",
       "2        611      558      512      475      440      408      378      344   \n",
       "3        769      742      701      666      637      593      559      531   \n",
       "4        128      128      134      126      121      134      123      131   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "261       28       32       28       31       30       23       28       19   \n",
       "262      567      522      491      448      418      386      352      330   \n",
       "263      751      708      658      621      591      561      537      514   \n",
       "264      106      117      115      126      138      144      156      150   \n",
       "265        0        0        0        4       11       16       21       28   \n",
       "\n",
       "     sensor9  sensor10  sensor11  sensor12  sensor13  sensor14  sensor15  \\\n",
       "0         38        35        39        51        51        65        72   \n",
       "1          0         0         0         0         0         0         0   \n",
       "2        314       291       266       249       225       207       184   \n",
       "3        499       480       450       436       422       411       398   \n",
       "4        126       135       145       158       162       172       172   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "261       19        14         0         0         0         0         0   \n",
       "262      300       272       249       227       212       188       174   \n",
       "263      485       469       448       437       417       397       388   \n",
       "264      156       157       158       156       153       156       157   \n",
       "265       26        32        36        39        49        43        52   \n",
       "\n",
       "     sensor16  sensor17  \n",
       "0          62         2  \n",
       "1           0         2  \n",
       "2         168         2  \n",
       "3         385         2  \n",
       "4         177         2  \n",
       "..        ...       ...  \n",
       "261         0         2  \n",
       "262       147         2  \n",
       "263       370         2  \n",
       "264       158         2  \n",
       "265        52         2  \n",
       "\n",
       "[266 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f8e5b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700</td>\n",
       "      <td>668</td>\n",
       "      <td>630</td>\n",
       "      <td>600</td>\n",
       "      <td>575</td>\n",
       "      <td>543</td>\n",
       "      <td>518</td>\n",
       "      <td>494</td>\n",
       "      <td>466</td>\n",
       "      <td>445</td>\n",
       "      <td>421</td>\n",
       "      <td>405</td>\n",
       "      <td>387</td>\n",
       "      <td>367</td>\n",
       "      <td>355</td>\n",
       "      <td>333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161</td>\n",
       "      <td>165</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>164</td>\n",
       "      <td>160</td>\n",
       "      <td>169</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>164</td>\n",
       "      <td>161</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>172</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>63</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>552</td>\n",
       "      <td>511</td>\n",
       "      <td>472</td>\n",
       "      <td>434</td>\n",
       "      <td>406</td>\n",
       "      <td>372</td>\n",
       "      <td>346</td>\n",
       "      <td>322</td>\n",
       "      <td>290</td>\n",
       "      <td>271</td>\n",
       "      <td>247</td>\n",
       "      <td>231</td>\n",
       "      <td>213</td>\n",
       "      <td>196</td>\n",
       "      <td>184</td>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>755</td>\n",
       "      <td>710</td>\n",
       "      <td>655</td>\n",
       "      <td>616</td>\n",
       "      <td>579</td>\n",
       "      <td>542</td>\n",
       "      <td>517</td>\n",
       "      <td>477</td>\n",
       "      <td>446</td>\n",
       "      <td>415</td>\n",
       "      <td>388</td>\n",
       "      <td>371</td>\n",
       "      <td>353</td>\n",
       "      <td>330</td>\n",
       "      <td>315</td>\n",
       "      <td>302</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>598</td>\n",
       "      <td>582</td>\n",
       "      <td>562</td>\n",
       "      <td>545</td>\n",
       "      <td>533</td>\n",
       "      <td>508</td>\n",
       "      <td>496</td>\n",
       "      <td>482</td>\n",
       "      <td>465</td>\n",
       "      <td>454</td>\n",
       "      <td>450</td>\n",
       "      <td>436</td>\n",
       "      <td>427</td>\n",
       "      <td>415</td>\n",
       "      <td>399</td>\n",
       "      <td>372</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>58</td>\n",
       "      <td>69</td>\n",
       "      <td>63</td>\n",
       "      <td>78</td>\n",
       "      <td>76</td>\n",
       "      <td>90</td>\n",
       "      <td>89</td>\n",
       "      <td>98</td>\n",
       "      <td>97</td>\n",
       "      <td>90</td>\n",
       "      <td>105</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>112</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sensor1  sensor2  sensor3  sensor4  sensor5  sensor6  sensor7  sensor8  \\\n",
       "0        700      668      630      600      575      543      518      494   \n",
       "1        161      165      155      157      164      160      169      160   \n",
       "2          0        0        0        8       20       23       30       36   \n",
       "3          0        0        0        0        9        7       19       19   \n",
       "4        552      511      472      434      406      372      346      322   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "280      755      710      655      616      579      542      517      477   \n",
       "281      598      582      562      545      533      508      496      482   \n",
       "282       58       69       63       78       76       90       89       98   \n",
       "283        0        0        0        0        6        7        6       13   \n",
       "284       15       16       12       12       11        7        5        4   \n",
       "\n",
       "     sensor9  sensor10  sensor11  sensor12  sensor13  sensor14  sensor15  \\\n",
       "0        466       445       421       405       387       367       355   \n",
       "1        162       164       161       169       169       169       172   \n",
       "2         39        41        46        52        58        60        63   \n",
       "3         16        24        20        28        37        40        44   \n",
       "4        290       271       247       231       213       196       184   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "280      446       415       388       371       353       330       315   \n",
       "281      465       454       450       436       427       415       399   \n",
       "282       97        90       105       103       104       112       109   \n",
       "283       16        26        27        25        33        33        38   \n",
       "284        0         0         0         0         0         0         0   \n",
       "\n",
       "     sensor16  sensor17  \n",
       "0         333         2  \n",
       "1         168         2  \n",
       "2          57         2  \n",
       "3          40         2  \n",
       "4         173         2  \n",
       "..        ...       ...  \n",
       "280       302         2  \n",
       "281       372         2  \n",
       "282       109         2  \n",
       "283        39         2  \n",
       "284         0         2  \n",
       "\n",
       "[285 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25fcc7c",
   "metadata": {
    "id": "3362d9fb"
   },
   "outputs": [],
   "source": [
    "# 20 행마다 잘라서 여러개의 데이터 셋 으로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9c6273be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "6d0b3a45",
    "outputId": "e55273ac-a00d-483c-af1a-5e0038342cf5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>52</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>82</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "      <td>81</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "      <td>83</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>747</td>\n",
       "      <td>699</td>\n",
       "      <td>657</td>\n",
       "      <td>617</td>\n",
       "      <td>583</td>\n",
       "      <td>550</td>\n",
       "      <td>517</td>\n",
       "      <td>491</td>\n",
       "      <td>460</td>\n",
       "      <td>438</td>\n",
       "      <td>410</td>\n",
       "      <td>390</td>\n",
       "      <td>371</td>\n",
       "      <td>353</td>\n",
       "      <td>338</td>\n",
       "      <td>322</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>450</td>\n",
       "      <td>423</td>\n",
       "      <td>398</td>\n",
       "      <td>377</td>\n",
       "      <td>358</td>\n",
       "      <td>340</td>\n",
       "      <td>322</td>\n",
       "      <td>305</td>\n",
       "      <td>287</td>\n",
       "      <td>275</td>\n",
       "      <td>262</td>\n",
       "      <td>250</td>\n",
       "      <td>241</td>\n",
       "      <td>232</td>\n",
       "      <td>221</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>69</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "      <td>77</td>\n",
       "      <td>82</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>82</td>\n",
       "      <td>81</td>\n",
       "      <td>85</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "      <td>59</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>151</td>\n",
       "      <td>143</td>\n",
       "      <td>142</td>\n",
       "      <td>138</td>\n",
       "      <td>136</td>\n",
       "      <td>131</td>\n",
       "      <td>128</td>\n",
       "      <td>125</td>\n",
       "      <td>117</td>\n",
       "      <td>116</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>111</td>\n",
       "      <td>109</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>176</td>\n",
       "      <td>170</td>\n",
       "      <td>165</td>\n",
       "      <td>161</td>\n",
       "      <td>154</td>\n",
       "      <td>151</td>\n",
       "      <td>146</td>\n",
       "      <td>142</td>\n",
       "      <td>134</td>\n",
       "      <td>133</td>\n",
       "      <td>127</td>\n",
       "      <td>126</td>\n",
       "      <td>124</td>\n",
       "      <td>121</td>\n",
       "      <td>116</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>99</td>\n",
       "      <td>97</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>98</td>\n",
       "      <td>97</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>92</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sensor1  sensor2  sensor3  sensor4  sensor5  sensor6  sensor7  sensor8  \\\n",
       "0          0        5       12       17       24       32       33       41   \n",
       "1         75       76       77       78       83       83       82       84   \n",
       "2         80       84       82       83       85       85       84       85   \n",
       "3        747      699      657      617      583      550      517      491   \n",
       "4        450      423      398      377      358      340      322      305   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "250       69       72       74       79       77       82       81       81   \n",
       "251       49       50       53       55       59       62       66       67   \n",
       "252      151      143      142      138      136      131      128      125   \n",
       "253      176      170      165      161      154      151      146      142   \n",
       "254       99       97       96       96       98       97       96       96   \n",
       "\n",
       "     sensor9  sensor10  sensor11  sensor12  sensor13  sensor14  sensor15  \\\n",
       "0         35        43        46        49        52        55        56   \n",
       "1         82        81        82        82        83        84        84   \n",
       "2         81        83        84        83        87        87        87   \n",
       "3        460       438       410       390       371       353       338   \n",
       "4        287       275       262       250       241       232       221   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "250       78        79        82        81        85        90        86   \n",
       "251       66        66        69        71        74        74        76   \n",
       "252      117       116       112       112       111       109       107   \n",
       "253      134       133       127       126       124       121       116   \n",
       "254       92        91        91        90        93        92        92   \n",
       "\n",
       "     sensor16  sensor17  \n",
       "0          57         0  \n",
       "1          85         0  \n",
       "2          87         0  \n",
       "3         322         0  \n",
       "4         214         0  \n",
       "..        ...       ...  \n",
       "250        89         0  \n",
       "251        77         0  \n",
       "252       107         0  \n",
       "253       113         0  \n",
       "254        90         0  \n",
       "\n",
       "[255 rows x 17 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.iloc[:255,]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6989089f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "982ff07b",
    "outputId": "d24c3405-a7cc-41f6-da78-659316db93a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a89151b8-9b4b-4de1-a395-c826d6e9e5d3\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>97</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "      <td>103</td>\n",
       "      <td>93</td>\n",
       "      <td>94</td>\n",
       "      <td>92</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>79</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>76</td>\n",
       "      <td>83</td>\n",
       "      <td>75</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>59</td>\n",
       "      <td>61</td>\n",
       "      <td>67</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>72</td>\n",
       "      <td>70</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>103</td>\n",
       "      <td>100</td>\n",
       "      <td>103</td>\n",
       "      <td>100</td>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>94</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>92</td>\n",
       "      <td>94</td>\n",
       "      <td>96</td>\n",
       "      <td>92</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>104</td>\n",
       "      <td>105</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>103</td>\n",
       "      <td>101</td>\n",
       "      <td>103</td>\n",
       "      <td>99</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>117</td>\n",
       "      <td>115</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>110</td>\n",
       "      <td>107</td>\n",
       "      <td>105</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "      <td>101</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>118</td>\n",
       "      <td>116</td>\n",
       "      <td>117</td>\n",
       "      <td>114</td>\n",
       "      <td>112</td>\n",
       "      <td>111</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>102</td>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>71</td>\n",
       "      <td>67</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows × 17 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a89151b8-9b4b-4de1-a395-c826d6e9e5d3')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a89151b8-9b4b-4de1-a395-c826d6e9e5d3 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a89151b8-9b4b-4de1-a395-c826d6e9e5d3');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     sensor1  sensor2  sensor3  sensor4  sensor5  sensor6  sensor7  sensor8  \\\n",
       "0         58       60       62       64       66       68       71       71   \n",
       "1        100       99       97       99      100       99       98      103   \n",
       "2         62       63       67       67       71       72       73       74   \n",
       "3         76       76       78       78       82       82       76       83   \n",
       "4         55       59       61       67       66       68       70       72   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "250      102      102      103      100      103      100       97       98   \n",
       "251      104      105      103      103      104      103      101      103   \n",
       "252      117      115      111      111      111      110      107      105   \n",
       "253      122      120      118      116      117      114      112      111   \n",
       "254       43       46       50       53       56       56       58       61   \n",
       "\n",
       "     sensor9  sensor10  sensor11  sensor12  sensor13  sensor14  sensor15  \\\n",
       "0         68        70        72        72        76        76        77   \n",
       "1         93        94        92        91        92        92        92   \n",
       "2         73        75        76        77        80        80        79   \n",
       "3         75        81        82        82        84        84        84   \n",
       "4         70        72        73        74        76        78        79   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "250       94        93        93        92        94        96        92   \n",
       "251       99        97        97        97        97        97        97   \n",
       "252      102       102       101       100        99        98       101   \n",
       "253      106       106       103       103       103       102       101   \n",
       "254       62        60        63        61        71        67        70   \n",
       "\n",
       "     sensor16  sensor17  \n",
       "0          78         1  \n",
       "1          92         1  \n",
       "2          81         1  \n",
       "3          85         1  \n",
       "4          78         1  \n",
       "..        ...       ...  \n",
       "250        96         1  \n",
       "251        96         1  \n",
       "252        98         1  \n",
       "253       102         1  \n",
       "254        71         1  \n",
       "\n",
       "[255 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df3.iloc[:255,]\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cd5ff6",
   "metadata": {
    "id": "2c880198"
   },
   "source": [
    "# It is quite useful to add a hierarchical index (Also known as multi-level index) for more sophisticated data analysis. In this case, let’s add index Year 1 and Year 2 for df1 and df2 respectively. To do that, we can simply specify the keys argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aacb91",
   "metadata": {
    "id": "08ffd5e6"
   },
   "outputs": [],
   "source": [
    "# frames = [df,df2,df3]\n",
    "# df_keys = pd.concat(frames, keys = ['1','2','3'])\n",
    "# df_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9501d1d7",
   "metadata": {
    "id": "13378235"
   },
   "outputs": [],
   "source": [
    "frames = [df,df2,df3,df4,df5,df6]\n",
    "df_keys2 = pd.concat(frames, axis=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0deb4a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1617, 17)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keys2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9320db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keys2 = df_keys2[:1605]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "123035f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "f89e77cc",
    "outputId": "92868961-7d8c-4813-b003-2e13d287ef63"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>189</td>\n",
       "      <td>182</td>\n",
       "      <td>177</td>\n",
       "      <td>171</td>\n",
       "      <td>165</td>\n",
       "      <td>161</td>\n",
       "      <td>156</td>\n",
       "      <td>149</td>\n",
       "      <td>144</td>\n",
       "      <td>140</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>132</td>\n",
       "      <td>128</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>75</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>77</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>54</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213</td>\n",
       "      <td>203</td>\n",
       "      <td>196</td>\n",
       "      <td>188</td>\n",
       "      <td>183</td>\n",
       "      <td>177</td>\n",
       "      <td>169</td>\n",
       "      <td>164</td>\n",
       "      <td>157</td>\n",
       "      <td>151</td>\n",
       "      <td>146</td>\n",
       "      <td>143</td>\n",
       "      <td>141</td>\n",
       "      <td>137</td>\n",
       "      <td>133</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>45</td>\n",
       "      <td>52</td>\n",
       "      <td>59</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>379</td>\n",
       "      <td>345</td>\n",
       "      <td>318</td>\n",
       "      <td>285</td>\n",
       "      <td>263</td>\n",
       "      <td>241</td>\n",
       "      <td>218</td>\n",
       "      <td>201</td>\n",
       "      <td>175</td>\n",
       "      <td>166</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>129</td>\n",
       "      <td>106</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>751</td>\n",
       "      <td>722</td>\n",
       "      <td>678</td>\n",
       "      <td>637</td>\n",
       "      <td>616</td>\n",
       "      <td>574</td>\n",
       "      <td>554</td>\n",
       "      <td>520</td>\n",
       "      <td>495</td>\n",
       "      <td>473</td>\n",
       "      <td>451</td>\n",
       "      <td>432</td>\n",
       "      <td>412</td>\n",
       "      <td>400</td>\n",
       "      <td>387</td>\n",
       "      <td>370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>346</td>\n",
       "      <td>347</td>\n",
       "      <td>336</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "      <td>308</td>\n",
       "      <td>300</td>\n",
       "      <td>293</td>\n",
       "      <td>279</td>\n",
       "      <td>283</td>\n",
       "      <td>270</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>254</td>\n",
       "      <td>251</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1605 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sensor1  sensor2  sensor3  sensor4  sensor5  sensor6  sensor7  sensor8  \\\n",
       "0        196      189      182      177      171      165      161      156   \n",
       "1         98      100       99      101      100      101      101      100   \n",
       "2         59       64       65       66       69       75       71       74   \n",
       "3          0        6       12       16       24       28       31       37   \n",
       "4        213      203      196      188      183      177      169      164   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "238        0        6       19       16       29       35       33       43   \n",
       "239        0        0        0        0        6        2       13       13   \n",
       "240      379      345      318      285      263      241      218      201   \n",
       "241      751      722      678      637      616      574      554      520   \n",
       "242      346      347      336      320      320      308      300      293   \n",
       "\n",
       "     sensor9  sensor10  sensor11  sensor12  sensor13  sensor14  sensor15  \\\n",
       "0        149       144       140       135       135       132       128   \n",
       "1         97        97        98        98       101       101       102   \n",
       "2         71        74        75        77        79        79        80   \n",
       "3         36        41        43        48        49        54        56   \n",
       "4        157       151       146       143       141       137       133   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "238       36        36        45        52        59        62        59   \n",
       "239       17        29        25        35        32        24        29   \n",
       "240      175       166       150       130       129       106       100   \n",
       "241      495       473       451       432       412       400       387   \n",
       "242      279       283       270       265       265       254       251   \n",
       "\n",
       "     sensor16  sensor17  \n",
       "0         126         2  \n",
       "1         102         2  \n",
       "2          80         2  \n",
       "3          58         2  \n",
       "4         130         2  \n",
       "..        ...       ...  \n",
       "238        71         0  \n",
       "239        31         0  \n",
       "240        93         0  \n",
       "241       370         0  \n",
       "242       248         0  \n",
       "\n",
       "[1605 rows x 17 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keys2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37636496",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keys2 = df_keys2[:1590]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ecfd7fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75f94d97",
    "outputId": "224785de-5731-4a31-8ba5-ed5295b62082"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1590, 17)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keys2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57013c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keys2 = np.array(df_keys2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf6c5900",
   "metadata": {
    "id": "e4856e76"
   },
   "outputs": [],
   "source": [
    "xtrain1 = df_keys2.reshape(106,5,3,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ed1cb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[196, 189, 182, ..., 128, 126,   2],\n",
       "         [ 98, 100,  99, ..., 102, 102,   2],\n",
       "         [ 59,  64,  65, ...,  80,  80,   2]],\n",
       "\n",
       "        [[  0,   6,  12, ...,  56,  58,   2],\n",
       "         [213, 203, 196, ..., 133, 130,   2],\n",
       "         [ 57,  58,  60, ...,  78,  79,   2]],\n",
       "\n",
       "        [[ 84,  84,  86, ...,  94,  94,   2],\n",
       "         [ 29,  39,  38, ...,  72,  71,   2],\n",
       "         [ 16,  20,  25, ...,  62,  63,   2]],\n",
       "\n",
       "        [[ 67,  69,  72, ...,  74,  76,   2],\n",
       "         [ 90,  84,  89, ...,  89,  89,   2],\n",
       "         [ 51,  53,  60, ...,  82,  81,   2]],\n",
       "\n",
       "        [[ 33,  35,  40, ...,  72,  72,   2],\n",
       "         [ 18,  24,  29, ...,  67,  70,   2],\n",
       "         [104, 103,  99, ...,  90,  91,   2]]],\n",
       "\n",
       "\n",
       "       [[[108, 105, 104, ...,  95,  98,   2],\n",
       "         [ 51,  56,  59, ...,  80,  80,   2],\n",
       "         [ 93,  93,  95, ...,  90,  91,   2]],\n",
       "\n",
       "        [[  0,   5,  12, ...,  60,  63,   2],\n",
       "         [ 73,  73,  73, ...,  80,  80,   2],\n",
       "         [ 62,  64,  65, ...,  79,  79,   2]],\n",
       "\n",
       "        [[131, 129, 124, ..., 104, 103,   2],\n",
       "         [124, 121, 120, ..., 108, 106,   2],\n",
       "         [ 34,  37,  42, ...,  71,  73,   2]],\n",
       "\n",
       "        [[ 24,  29,  34, ...,  66,  69,   2],\n",
       "         [ 47,  52,  52, ...,  71,  71,   2],\n",
       "         [138, 138, 132, ..., 107, 106,   2]],\n",
       "\n",
       "        [[102, 100, 101, ...,  92,  94,   2],\n",
       "         [ 73,  76,  78, ...,  87,  89,   2],\n",
       "         [ 20,  29,  31, ...,  71,  69,   2]]],\n",
       "\n",
       "\n",
       "       [[[  0,   0,   3, ...,  53,  56,   2],\n",
       "         [ 25,  27,  37, ...,  68,  74,   2],\n",
       "         [102, 100, 101, ...,  93,  91,   2]],\n",
       "\n",
       "        [[175, 175, 165, ..., 126, 121,   2],\n",
       "         [ 11,  18,  22, ...,  59,  67,   2],\n",
       "         [  1,   7,  14, ...,  58,  61,   2]],\n",
       "\n",
       "        [[ 91,  91,  89, ...,  81,  82,   2],\n",
       "         [ 79,  77,  79, ...,  84,  85,   2],\n",
       "         [ 65,  68,  70, ...,  87,  87,   2]],\n",
       "\n",
       "        [[ 31,  35,  38, ...,  71,  72,   2],\n",
       "         [ 23,  28,  33, ...,  65,  69,   2],\n",
       "         [ 63,  65,  69, ...,  75,  76,   2]],\n",
       "\n",
       "        [[ 95,  95,  94, ...,  89,  90,   2],\n",
       "         [ 66,  68,  70, ...,  86,  87,   2],\n",
       "         [116, 115, 112, ..., 100,  99,   2]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[169, 163, 151, ...,  27,  20,   0],\n",
       "         [748, 723, 674, ..., 356, 342,   0],\n",
       "         [452, 444, 417, ..., 282, 280,   0]],\n",
       "\n",
       "        [[  3,   8,  21, ...,  88,  85,   0],\n",
       "         [  0,   0,   0, ...,  23,  19,   0],\n",
       "         [323, 293, 279, ...,  83,  72,   0]],\n",
       "\n",
       "        [[745, 710, 663, ..., 316, 300,   0],\n",
       "         [543, 512, 477, ..., 357, 357,   0],\n",
       "         [ 48,  48,  47, ..., 102, 108,   0]],\n",
       "\n",
       "        [[  0,   0,   0, ...,  36,  37,   0],\n",
       "         [154, 133, 121, ...,  37,  30,   0],\n",
       "         [725, 681, 634, ..., 250, 229,   0]],\n",
       "\n",
       "        [[754, 718, 679, ..., 405, 384,   0],\n",
       "         [246, 242, 240, ..., 226, 232,   0],\n",
       "         [  0,   0,   1, ...,  65,  65,   0]]],\n",
       "\n",
       "\n",
       "       [[[  0,   0,   0, ...,  26,  36,   0],\n",
       "         [505, 469, 431, ..., 132, 118,   0],\n",
       "         [755, 728, 696, ..., 399, 382,   0]],\n",
       "\n",
       "        [[263, 265, 252, ..., 231, 235,   0],\n",
       "         [  0,   0,   0, ...,  55,  64,   0],\n",
       "         [  0,   0,   0, ...,  36,  36,   0]],\n",
       "\n",
       "        [[463, 433, 387, ..., 115, 109,   0],\n",
       "         [760, 734, 692, ..., 389, 373,   0],\n",
       "         [292, 290, 289, ..., 244, 242,   0]],\n",
       "\n",
       "        [[  0,   8,   7, ...,  62,  60,   0],\n",
       "         [  0,   0,   0, ...,  32,  22,   0],\n",
       "         [374, 332, 308, ...,  86,  83,   0]],\n",
       "\n",
       "        [[761, 708, 676, ..., 384, 374,   0],\n",
       "         [400, 390, 380, ..., 267, 253,   0],\n",
       "         [  0,   9,  18, ...,  77,  85,   0]]],\n",
       "\n",
       "\n",
       "       [[[  0,   0,   0, ...,  31,  31,   0],\n",
       "         [177, 166, 162, ...,  34,  33,   0],\n",
       "         [753, 712, 669, ..., 336, 312,   0]],\n",
       "\n",
       "        [[519, 502, 467, ..., 372, 360,   0],\n",
       "         [ 51,  59,  58, ..., 107, 104,   0],\n",
       "         [  0,   0,   0, ...,  46,  30,   0]],\n",
       "\n",
       "        [[ 11,  18,   9, ...,   0,   0,   0],\n",
       "         [726, 684, 630, ..., 306, 284,   0],\n",
       "         [763, 730, 702, ..., 436, 423,   0]],\n",
       "\n",
       "        [[109, 113, 108, ..., 116, 116,   0],\n",
       "         [  0,   0,   0, ...,  35,  36,   0],\n",
       "         [  0,   0,   0, ...,   0,   0,   0]],\n",
       "\n",
       "        [[713, 660, 607, ..., 202, 196,   0],\n",
       "         [759, 737, 708, ..., 397, 387,   0],\n",
       "         [146, 133, 135, ..., 192, 191,   0]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a6970cc",
   "metadata": {
    "id": "3f2c6652"
   },
   "outputs": [],
   "source": [
    "y_train1 = df_keys2[:,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44f802c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1590,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "350fdcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc47e5",
   "metadata": {
    "id": "f822fd29"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0039b689",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "555053d6",
    "outputId": "9aa40365-73d3-4e85-ceb2-29fe0d5cc03b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import missingno as msno\n",
    "\n",
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b272ba",
   "metadata": {
    "id": "195e0de5"
   },
   "source": [
    "# msno.matrix(df) 을 통해 결측치가 없음을 확인하였다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ffeb68",
   "metadata": {
    "id": "9a9efa09"
   },
   "source": [
    "# 해야 할 일\n",
    "\n",
    "\n",
    "- csv 파일 만들기\n",
    "- --> 자동으로 data 에 concat 하기\n",
    "- 그것을 train, test split(주로 train 에 배치)\n",
    "- test 는 새로 들어온 데이터를 기준으로 함(신원인증 버튼 누르면 1분동안의 새 데이터)\n",
    "- 레이블링(y_train 의 차원을 x_train 과 맞춰주기 위해서 코딩 필요)\n",
    "- 자동 레이블링 과정 필요(string(id)-->int)\n",
    "\n",
    "\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd554bbf",
   "metadata": {
    "id": "2fbd7b5b"
   },
   "outputs": [],
   "source": [
    "xtrain1 = xtrain1.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf1aa985",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "339cee57",
    "outputId": "f408120e-28ff-4449-98fe-0d8522cadf81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27030,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d8ed3a1",
   "metadata": {
    "id": "86adacb2"
   },
   "outputs": [],
   "source": [
    "addx = xtrain1[:255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e856499e",
   "metadata": {
    "id": "1086d75f"
   },
   "outputs": [],
   "source": [
    "newx = xtrain1[255:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e77acc4",
   "metadata": {
    "id": "8173179d"
   },
   "outputs": [],
   "source": [
    "newx = pd.DataFrame(newx)\n",
    "addx = pd.DataFrame(addx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "444b96b6",
   "metadata": {
    "id": "YN6tmB1-_pbe"
   },
   "outputs": [],
   "source": [
    "list1 = [newx, addx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a786faf",
   "metadata": {
    "id": "da5f973f"
   },
   "outputs": [],
   "source": [
    "h1 = pd.concat(list1, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1929a27",
   "metadata": {
    "id": "441b8854"
   },
   "outputs": [],
   "source": [
    "h2 = h1.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30354737",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh0 = np.array(xtrain1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95691862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27030,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aae35f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh0 = hh0.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed66e0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27030,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06b1b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "hhtrain = hh0[:20400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7302bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "hhtest = hh0[20400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "792c31b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20400,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hhtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741d3b36",
   "metadata": {},
   "source": [
    "# 80개는 테스트, 27개는 훈련 데이터 세트로..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7038854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hhinput = hhtrain.reshape(80,5,3,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5dffbe6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6630,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hhtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ff7380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hhtest = hhtest.reshape(26,5,3,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "67543e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[748, 712, 671, ..., 349, 331,   2],\n",
       "         [444, 428, 401, ..., 265, 269,   2],\n",
       "         [  3,  26,  21, ...,  73,  84,   2]],\n",
       "\n",
       "        [[  0,   0,   0, ...,  33,  31,   2],\n",
       "         [132, 117,  94, ...,  34,  44,   2],\n",
       "         [751, 708, 661, ..., 320, 300,   2]],\n",
       "\n",
       "        [[457, 428, 420, ..., 306, 302,   2],\n",
       "         [ 26,  36,  43, ...,  79,  94,   2],\n",
       "         [  0,   0,   0, ...,  39,  46,   2]],\n",
       "\n",
       "        [[  0,   0,   0, ...,   0,   4,   2],\n",
       "         [692, 640, 594, ..., 223, 202,   2],\n",
       "         [731, 700, 671, ..., 404, 390,   2]],\n",
       "\n",
       "        [[ 97, 100, 101, ..., 110, 109,   2],\n",
       "         [  0,   0,   0, ...,  41,  40,   2],\n",
       "         [ 40,  35,  32, ...,   0,   0,   2]]],\n",
       "\n",
       "\n",
       "       [[[733, 686, 636, ..., 303, 280,   2],\n",
       "         [568, 549, 524, ..., 320, 308,   2],\n",
       "         [ 55,  61,  61, ..., 100, 105,   2]],\n",
       "\n",
       "        [[  0,   0,   0, ...,  42,  41,   2],\n",
       "         [154, 134, 121, ...,  42,  44,   2],\n",
       "         [746, 712, 663, ..., 315, 293,   2]],\n",
       "\n",
       "        [[457, 437, 415, ..., 327, 329,   2],\n",
       "         [ 43,  44,  43, ..., 101,  99,   2],\n",
       "         [  0,   0,   0, ...,  35,  41,   2]],\n",
       "\n",
       "        [[198, 176, 149, ...,  52,  54,   2],\n",
       "         [748, 712, 664, ..., 327, 310,   2],\n",
       "         [459, 433, 413, ..., 307, 309,   2]],\n",
       "\n",
       "        [[ 36,  38,  47, ...,  96,  98,   2],\n",
       "         [  0,   0,   0, ...,  39,  39,   2],\n",
       "         [229, 213, 193, ...,  62,  63,   2]]],\n",
       "\n",
       "\n",
       "       [[[759, 720, 664, ..., 344, 320,   2],\n",
       "         [436, 414, 397, ..., 288, 290,   2],\n",
       "         [ 30,  46,  44, ...,  87,  87,   2]],\n",
       "\n",
       "        [[  0,   0,   0, ...,  42,  36,   2],\n",
       "         [258, 235, 217, ...,  63,  63,   2],\n",
       "         [755, 720, 679, ..., 356, 335,   2]],\n",
       "\n",
       "        [[405, 385, 376, ..., 229, 227,   2],\n",
       "         [  3,  13,  24, ...,  88,  79,   2],\n",
       "         [  0,   0,   0, ...,  24,  32,   2]],\n",
       "\n",
       "        [[336, 308, 284, ..., 102,  90,   2],\n",
       "         [754, 715, 669, ..., 378, 354,   2],\n",
       "         [344, 331, 312, ..., 238, 230,   2]],\n",
       "\n",
       "        [[  0,   6,  19, ...,  80,  80,   2],\n",
       "         [  0,   0,   0, ...,  26,  26,   2],\n",
       "         [430, 394, 357, ..., 127, 118,   2]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[169, 163, 151, ...,  27,  20,   0],\n",
       "         [748, 723, 674, ..., 356, 342,   0],\n",
       "         [452, 444, 417, ..., 282, 280,   0]],\n",
       "\n",
       "        [[  3,   8,  21, ...,  88,  85,   0],\n",
       "         [  0,   0,   0, ...,  23,  19,   0],\n",
       "         [323, 293, 279, ...,  83,  72,   0]],\n",
       "\n",
       "        [[745, 710, 663, ..., 316, 300,   0],\n",
       "         [543, 512, 477, ..., 357, 357,   0],\n",
       "         [ 48,  48,  47, ..., 102, 108,   0]],\n",
       "\n",
       "        [[  0,   0,   0, ...,  36,  37,   0],\n",
       "         [154, 133, 121, ...,  37,  30,   0],\n",
       "         [725, 681, 634, ..., 250, 229,   0]],\n",
       "\n",
       "        [[754, 718, 679, ..., 405, 384,   0],\n",
       "         [246, 242, 240, ..., 226, 232,   0],\n",
       "         [  0,   0,   1, ...,  65,  65,   0]]],\n",
       "\n",
       "\n",
       "       [[[  0,   0,   0, ...,  26,  36,   0],\n",
       "         [505, 469, 431, ..., 132, 118,   0],\n",
       "         [755, 728, 696, ..., 399, 382,   0]],\n",
       "\n",
       "        [[263, 265, 252, ..., 231, 235,   0],\n",
       "         [  0,   0,   0, ...,  55,  64,   0],\n",
       "         [  0,   0,   0, ...,  36,  36,   0]],\n",
       "\n",
       "        [[463, 433, 387, ..., 115, 109,   0],\n",
       "         [760, 734, 692, ..., 389, 373,   0],\n",
       "         [292, 290, 289, ..., 244, 242,   0]],\n",
       "\n",
       "        [[  0,   8,   7, ...,  62,  60,   0],\n",
       "         [  0,   0,   0, ...,  32,  22,   0],\n",
       "         [374, 332, 308, ...,  86,  83,   0]],\n",
       "\n",
       "        [[761, 708, 676, ..., 384, 374,   0],\n",
       "         [400, 390, 380, ..., 267, 253,   0],\n",
       "         [  0,   9,  18, ...,  77,  85,   0]]],\n",
       "\n",
       "\n",
       "       [[[  0,   0,   0, ...,  31,  31,   0],\n",
       "         [177, 166, 162, ...,  34,  33,   0],\n",
       "         [753, 712, 669, ..., 336, 312,   0]],\n",
       "\n",
       "        [[519, 502, 467, ..., 372, 360,   0],\n",
       "         [ 51,  59,  58, ..., 107, 104,   0],\n",
       "         [  0,   0,   0, ...,  46,  30,   0]],\n",
       "\n",
       "        [[ 11,  18,   9, ...,   0,   0,   0],\n",
       "         [726, 684, 630, ..., 306, 284,   0],\n",
       "         [763, 730, 702, ..., 436, 423,   0]],\n",
       "\n",
       "        [[109, 113, 108, ..., 116, 116,   0],\n",
       "         [  0,   0,   0, ...,  35,  36,   0],\n",
       "         [  0,   0,   0, ...,   0,   0,   0]],\n",
       "\n",
       "        [[713, 660, 607, ..., 202, 196,   0],\n",
       "         [759, 737, 708, ..., 397, 387,   0],\n",
       "         [146, 133, 135, ..., 192, 191,   0]]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hhtest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3a2a1f",
   "metadata": {},
   "source": [
    "# hhinput 은 x train data, hhtest 는 test data 로 활용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de029604",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 16 is out of bounds for axis 1 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14/1368261146.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhhinput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 16 is out of bounds for axis 1 with size 5"
     ]
    }
   ],
   "source": [
    "hhinput[:,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf7d5c3b",
   "metadata": {
    "id": "33338ea3"
   },
   "outputs": [],
   "source": [
    "h0 = np.array(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e1e896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c2ac574",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9ae23f3",
    "outputId": "05218fa1-8d5f-4fb7-bf60-55dc203186bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([108, 105, 104, ...,  90,  91,   2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fae92a54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9f9d039f",
    "outputId": "ab260b49-404a-4eec-f835-80f6f6b7ab20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13005, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a618fceb",
   "metadata": {
    "id": "a405ac1c"
   },
   "outputs": [],
   "source": [
    "h0 = h0[:10200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82b03586",
   "metadata": {
    "id": "ef7cf5ad"
   },
   "outputs": [],
   "source": [
    "hout = h0[10200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57474cf1",
   "metadata": {
    "id": "c957316f"
   },
   "outputs": [],
   "source": [
    "hinput = h0.reshape(40,5,3,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc68a3f7",
   "metadata": {
    "id": "1WX5MVnc_0kX"
   },
   "outputs": [],
   "source": [
    "h0 = np.array(h1)\n",
    "h0.flatten()\n",
    "hout = h0[10200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23b1e5e2",
   "metadata": {
    "id": "88262430"
   },
   "outputs": [],
   "source": [
    "htest = hout.reshape(11,5,3,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a711b6d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9dbfd77",
    "outputId": "1a4a99a0-6300-4317-aafa-60f2ed368a79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[108, 105, 104, ...,  95,  98,   2],\n",
       "         [ 51,  56,  59, ...,  80,  80,   2],\n",
       "         [ 93,  93,  95, ...,  90,  91,   2]],\n",
       "\n",
       "        [[  0,   5,  12, ...,  60,  63,   2],\n",
       "         [ 73,  73,  73, ...,  80,  80,   2],\n",
       "         [ 62,  64,  65, ...,  79,  79,   2]],\n",
       "\n",
       "        [[131, 129, 124, ..., 104, 103,   2],\n",
       "         [124, 121, 120, ..., 108, 106,   2],\n",
       "         [ 34,  37,  42, ...,  71,  73,   2]],\n",
       "\n",
       "        [[ 24,  29,  34, ...,  66,  69,   2],\n",
       "         [ 47,  52,  52, ...,  71,  71,   2],\n",
       "         [138, 138, 132, ..., 107, 106,   2]],\n",
       "\n",
       "        [[102, 100, 101, ...,  92,  94,   2],\n",
       "         [ 73,  76,  78, ...,  87,  89,   2],\n",
       "         [ 20,  29,  31, ...,  71,  69,   2]]],\n",
       "\n",
       "\n",
       "       [[[  0,   0,   3, ...,  53,  56,   2],\n",
       "         [ 25,  27,  37, ...,  68,  74,   2],\n",
       "         [102, 100, 101, ...,  93,  91,   2]],\n",
       "\n",
       "        [[175, 175, 165, ..., 126, 121,   2],\n",
       "         [ 11,  18,  22, ...,  59,  67,   2],\n",
       "         [  1,   7,  14, ...,  58,  61,   2]],\n",
       "\n",
       "        [[ 91,  91,  89, ...,  81,  82,   2],\n",
       "         [ 79,  77,  79, ...,  84,  85,   2],\n",
       "         [ 65,  68,  70, ...,  87,  87,   2]],\n",
       "\n",
       "        [[ 31,  35,  38, ...,  71,  72,   2],\n",
       "         [ 23,  28,  33, ...,  65,  69,   2],\n",
       "         [ 63,  65,  69, ...,  75,  76,   2]],\n",
       "\n",
       "        [[ 95,  95,  94, ...,  89,  90,   2],\n",
       "         [ 66,  68,  70, ...,  86,  87,   2],\n",
       "         [116, 115, 112, ..., 100,  99,   2]]],\n",
       "\n",
       "\n",
       "       [[[ 31,  36,  40, ...,  72,  72,   2],\n",
       "         [ 63,  66,  68, ...,  73,  75,   2],\n",
       "         [ 77,  75,  78, ...,  83,  83,   2]],\n",
       "\n",
       "        [[ 80,  85,  82, ...,  89,  93,   2],\n",
       "         [ 39,  42,  46, ...,  76,  79,   2],\n",
       "         [ 32,  36,  37, ...,  70,  70,   2]],\n",
       "\n",
       "        [[ 43,  49,  50, ...,  68,  70,   2],\n",
       "         [ 88,  87,  87, ...,  86,  87,   2],\n",
       "         [112, 110, 112, ...,  97,  97,   2]],\n",
       "\n",
       "        [[ 44,  51,  51, ...,  81,  82,   2],\n",
       "         [  7,  14,  18, ...,  62,  66,   2],\n",
       "         [ 88,  86,  88, ...,  85,  84,   2]],\n",
       "\n",
       "        [[ 65,  67,  68, ...,  73,  73,   2],\n",
       "         [105, 106, 102, ...,  96,  95,   2],\n",
       "         [ 64,  67,  68, ...,  85,  86,   2]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 35,  41,  44, ...,  72,  74,   1],\n",
       "         [ 34,  36,  39, ...,  72,  73,   1],\n",
       "         [ 53,  55,  58, ...,  72,  73,   1]],\n",
       "\n",
       "        [[ 92,  91,  92, ...,  88,  88,   1],\n",
       "         [ 89,  86,  93, ...,  87,  90,   1],\n",
       "         [ 40,  44,  48, ...,  79,  82,   1]],\n",
       "\n",
       "        [[ 37,  43,  46, ...,  71,  73,   1],\n",
       "         [ 45,  49,  54, ...,  72,  74,   1],\n",
       "         [ 79,  80,  80, ...,  87,  84,   1]],\n",
       "\n",
       "        [[ 86,  88,  88, ...,  89,  88,   1],\n",
       "         [ 62,  62,  67, ...,  83,  85,   1],\n",
       "         [ 40,  46,  48, ...,  75,  76,   1]],\n",
       "\n",
       "        [[ 30,  39,  40, ...,  70,  70,   1],\n",
       "         [ 77,  77,  77, ...,  79,  78,   1],\n",
       "         [ 91,  88,  87, ...,  89,  88,   1]]],\n",
       "\n",
       "\n",
       "       [[[ 77,  81,  80, ...,  88,  87,   1],\n",
       "         [ 35,  40,  42, ...,  71,  73,   1],\n",
       "         [ 29,  33,  42, ...,  70,  74,   1]],\n",
       "\n",
       "        [[ 60,  62,  64, ...,  76,  76,   1],\n",
       "         [ 73,  78,  76, ...,  84,  82,   1],\n",
       "         [ 80,  79,  80, ...,  83,  85,   1]],\n",
       "\n",
       "        [[ 60,  62,  63, ...,  82,  83,   1],\n",
       "         [  2,  10,  16, ...,  62,  65,   1],\n",
       "         [ 52,  56,  58, ...,  78,  79,   1]],\n",
       "\n",
       "        [[ 55,  59,  57, ...,  73,  73,   1],\n",
       "         [102, 102, 103, ...,  92,  96,   1],\n",
       "         [104, 105, 103, ...,  97,  96,   1]],\n",
       "\n",
       "        [[117, 115, 111, ..., 101,  98,   1],\n",
       "         [122, 120, 118, ..., 101, 102,   1],\n",
       "         [ 43,  46,  50, ...,  70,  71,   1]]],\n",
       "\n",
       "\n",
       "       [[[196, 189, 182, ..., 128, 126,   2],\n",
       "         [ 98, 100,  99, ..., 102, 102,   2],\n",
       "         [ 59,  64,  65, ...,  80,  80,   2]],\n",
       "\n",
       "        [[  0,   6,  12, ...,  56,  58,   2],\n",
       "         [213, 203, 196, ..., 133, 130,   2],\n",
       "         [ 57,  58,  60, ...,  78,  79,   2]],\n",
       "\n",
       "        [[ 84,  84,  86, ...,  94,  94,   2],\n",
       "         [ 29,  39,  38, ...,  72,  71,   2],\n",
       "         [ 16,  20,  25, ...,  62,  63,   2]],\n",
       "\n",
       "        [[ 67,  69,  72, ...,  74,  76,   2],\n",
       "         [ 90,  84,  89, ...,  89,  89,   2],\n",
       "         [ 51,  53,  60, ...,  82,  81,   2]],\n",
       "\n",
       "        [[ 33,  35,  40, ...,  72,  72,   2],\n",
       "         [ 18,  24,  29, ...,  67,  70,   2],\n",
       "         [104, 103,  99, ...,  90,  91,   2]]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2.reshape(51,5,3,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7583b304",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26ff8c6a",
    "outputId": "132435b9-4cd7-4d7e-bf1b-2fceebbb4d7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1590,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30ee981f",
   "metadata": {
    "id": "d3ab90d8"
   },
   "outputs": [],
   "source": [
    "ylabel = y_train1[0:1590:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "857e4067",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2a2887b",
    "outputId": "303d30b3-7360-4d2c-ba4e-03061741a1a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ylabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a4233e3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8471a848",
    "outputId": "f154986f-8b12-40eb-c853-6827c10b5985"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ylabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b8a1fa7d",
   "metadata": {
    "id": "2d0a4931"
   },
   "outputs": [],
   "source": [
    "y_train = ylabel[0:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dfdb4380",
   "metadata": {
    "id": "7798bc70"
   },
   "outputs": [],
   "source": [
    "y_test = ylabel[80:106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4b153088",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75eb5916",
    "outputId": "18cda8a1-628c-48f5-fd11-47931fc556df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c51bfe11",
   "metadata": {
    "id": "DJ-HXSF2AIf-"
   },
   "outputs": [],
   "source": [
    "y_test1 = [1,1,1,1,1,1,1,1,1,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67cf9f38",
   "metadata": {
    "id": "49d212a1"
   },
   "outputs": [],
   "source": [
    "ytest1 = np.array(y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa222b3c",
   "metadata": {
    "id": "99de2049"
   },
   "outputs": [],
   "source": [
    "xtest = xtrain1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c393c43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92eb5ec1",
    "outputId": "51300c6b-ec27-4a23-cc78-4419e0c3df93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a67ca6",
   "metadata": {
    "id": "7b4c5efc"
   },
   "source": [
    "# 2가 뒤에 붙어있는 x data = h1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d9e2aeb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "5f69a565",
    "outputId": "02ca115a-9461-42c9-8f70-dcef36fd63f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-45e6812d-cba0-46d2-b02e-ff2a92fe976e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13005 rows × 1 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45e6812d-cba0-46d2-b02e-ff2a92fe976e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-45e6812d-cba0-46d2-b02e-ff2a92fe976e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-45e6812d-cba0-46d2-b02e-ff2a92fe976e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       0\n",
       "0    108\n",
       "1    105\n",
       "2    104\n",
       "3    104\n",
       "4    104\n",
       "..   ...\n",
       "250   89\n",
       "251   89\n",
       "252   90\n",
       "253   91\n",
       "254    2\n",
       "\n",
       "[13005 rows x 1 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dfcd9bfa",
   "metadata": {
    "id": "d28eb3fe"
   },
   "outputs": [],
   "source": [
    "xtest1 = xtest[10200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "070b01a6",
   "metadata": {
    "id": "834789b9"
   },
   "outputs": [],
   "source": [
    "xtrain1 = xtrain1[:10200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8189510c",
   "metadata": {
    "id": "b53adcea"
   },
   "outputs": [],
   "source": [
    "xtest2 = xtest1.reshape(11,5,3,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a814fa7",
   "metadata": {
    "id": "b6f68d2d"
   },
   "outputs": [],
   "source": [
    "xtrain2 = xtrain1.reshape(40,5,3,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "707cceb4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15d42df5",
    "outputId": "e582c8a6-432e-494c-c7b1-fb8498dfaff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: 80 x_test: 26\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#예제\n",
    "\n",
    "#\n",
    "#(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    " #   'cats_vs_dogs',\n",
    " #   split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    " #   with_info=True,\n",
    " #   as_supervised=True,\n",
    "# #)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(df2, y, test_size = 0.4,random_state=42) \n",
    "#1). X_train - 여기에는 모든 독립 변수가 포함되며 우리가 지정한 대로 모델을 훈련하는 데 사용되며, 완전한 데이터의 이 관찰 test_size = 0.4수단 60%은 모델을 훈련/적합하는 40%데 사용되고 나머지는 테스트에 사용됩니다. 모델.\n",
    "#2). X_test40% - 학습 단계에서 사용되지 않고 모델의 정확도를 테스트하기 위한 예측을 수행하는 데 사용되는 데이터의 독립 변수의 나머지 부분입니다.\n",
    "#3). y_train - 이것은 이 모델에 의해 예측되어야 하는 종속 변수입니다. 여기에는 독립 변수에 대한 범주 레이블이 포함됩니다. 모델을 훈련/피팅하는 동안 종속 변수를 지정해야 합니다.\n",
    "#4). y_test - 이 데이터에는 테스트 데이터에 대한 범주 레이블이 있으며, 이 레이블은 실제 범주와 예측 범주 간의 정확도를 테스트하는 데 사용됩니다.\n",
    "\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = (hhinput, y_train  ),(hhtest, y_test)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(data, y_train, random_state=random_state, test_size=0.2)\n",
    "\n",
    "print(\"x_train:\", len(x_train), \"x_test:\", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2befc5ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a90b5ea",
    "outputId": "1d533597-a960-45a2-9aa2-e7b6fd2def18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7543a3",
   "metadata": {
    "id": "a37371c7"
   },
   "source": [
    "\n",
    "# 최대한 많은 데이터 확보가 중요함!!!\n",
    "# 밑의 CNN 모델을 쓸 것입니다 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "815f9be5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90abb047",
    "outputId": "69663a03-2918-4573-d58a-108994964764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 5, 3, 17)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 5, 3, 128)         19712     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 3, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 3, 2, 64)          32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 2, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 2, 1, 32)          2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 1, 1, 16)          528       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_34 (Flatten)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "flatten_35 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 57,331\n",
      "Trainable params: 57,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_input = keras.Input(shape=(5,3,17))  # (a,b,c) a는 개수, b는 row ,\n",
    "# c는 column c는 dense 출력층 개수와 똑같아야한다 \n",
    "\n",
    "\n",
    "x = keras.layers.Conv2D(128, (3,3),padding=\"same\",activation='relu')(img_input) #256 filters, 5 kernel size, window stride 1 (defalut)\n",
    "x = keras.layers.MaxPool2D(2, padding= 'same')(x)\n",
    "x = keras.layers.Conv2D(64, (2,2), padding=\"same\",activation='relu')(x)\n",
    "x = keras.layers.MaxPool2D(2, padding= 'same')(x)\n",
    "x = keras.layers.Conv2D(32, (1,1), padding=\"same\",activation='relu')(x)\n",
    "x = keras.layers.MaxPool2D(2, padding= 'same')(x)\n",
    "x = keras.layers.Conv2D(16, (1,1),padding=\"same\", activation='relu')(x)\n",
    "x = keras.layers.MaxPool2D(2, padding= 'same')(x)\n",
    "\n",
    "\n",
    "\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(16, activation='relu')(x)\n",
    "\n",
    "x = keras.layers.Flatten()(x)\n",
    "predictions = keras.layers.Dense(3, activation='softmax')(x) \n",
    "\n",
    "model = keras.Model(inputs=img_input, outputs=predictions)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2a1a7f",
   "metadata": {
    "id": "0d13fdf5"
   },
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!! 모델 학습 !!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0aeacb55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9877478",
    "outputId": "4ef74c41-707b-49aa-cc9b-52740cabda97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ylabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a961189f",
   "metadata": {
    "id": "93e84b22"
   },
   "source": [
    "# 원 핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5566299f",
   "metadata": {
    "id": "0999c12d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "one_hot_encode = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "991c3c3a",
   "metadata": {
    "id": "63d7008e"
   },
   "outputs": [],
   "source": [
    "\n",
    "one1 = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f1b0d2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d7fd8c3",
    "outputId": "6dc7d792-8b1a-49e6-8936-04d495b8f403"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "59667cd4",
   "metadata": {
    "id": "db74ede9"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e7c8a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(factor=0.9, monitor='val_loss', patience=1, verbose=2, min_lr=1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "55099a19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7e72872b",
    "outputId": "69d9f7e6-2dc2-4413-ab29-022f46af1551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/56\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5276 - accuracy: 0.5625\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 2/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8876 - accuracy: 0.7500\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 3/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9484 - accuracy: 0.6250\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 4/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7216 - accuracy: 0.6500\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 5/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6694 - accuracy: 0.7625\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 6/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7625\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 7/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.8000\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 8/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.8250\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 9/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.8250\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 10/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.8750\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 11/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8500\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 12/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8750\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 13/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3325 - accuracy: 0.9250\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 14/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3599 - accuracy: 0.8250\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 15/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3476 - accuracy: 0.9125\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 16/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3297 - accuracy: 0.9250\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 17/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3569 - accuracy: 0.8500\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 18/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3336 - accuracy: 0.9000\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 19/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2886 - accuracy: 0.9125\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 20/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.9125\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 21/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2760 - accuracy: 0.8875\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 22/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2326 - accuracy: 0.9500\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 23/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2546 - accuracy: 0.9500\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 24/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2527 - accuracy: 0.9000\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 25/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2282 - accuracy: 0.9625\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 26/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2206 - accuracy: 0.9375\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 27/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2100 - accuracy: 0.9250\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 28/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2193 - accuracy: 0.9375\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 29/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2129 - accuracy: 0.9500\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 30/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2319 - accuracy: 0.8875\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 31/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2368 - accuracy: 0.9500\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 32/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2247 - accuracy: 0.8750\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 33/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2901 - accuracy: 0.8875\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 34/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8500\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 35/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3471 - accuracy: 0.8250\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 36/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.8125\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 37/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.8000\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 38/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2156 - accuracy: 0.9250\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 39/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3599 - accuracy: 0.8625\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 40/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2660 - accuracy: 0.8750\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 41/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2168 - accuracy: 0.9125\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 42/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2025 - accuracy: 0.9500\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 43/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1889 - accuracy: 0.9750\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 44/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1899 - accuracy: 0.9500\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 45/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1533 - accuracy: 1.0000\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 46/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1476 - accuracy: 0.9750\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 47/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1445 - accuracy: 0.9875\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 48/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1280 - accuracy: 1.0000\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 49/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1307 - accuracy: 0.9875\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 50/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1236 - accuracy: 1.0000\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 51/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1146 - accuracy: 1.0000\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 52/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1161 - accuracy: 0.9875\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 53/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1090 - accuracy: 1.0000\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 54/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1044 - accuracy: 1.0000\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 55/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1018 - accuracy: 1.0000\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 56/56\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1040 - accuracy: 0.9875\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 16.8614 - accuracy: 0.3077\n",
      "test_loss: 16.861412048339844 \n",
      "test_accuracy: 0.3076923191547394\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습!! \n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, \n",
    "                                                 beta_1=0.9, \n",
    "                                                 beta_2=0.999, \n",
    "                                                 epsilon=1e-07, \n",
    "                                                 amsgrad=False,),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history1 = model.fit(x_train, one_hot_encode, epochs=56,callbacks=[lr_scheduler])#Epoch만 학습합니다.\n",
    "# 오류는 dense 의 아웃풋 형태를 조절할 것 여기에서는 17로 줌\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, one1, verbose=1)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f29d0ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 1.0771 - accuracy: 0.7000\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7984 - accuracy: 0.6750\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8159 - accuracy: 0.6500\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9181 - accuracy: 0.7125\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.7125\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4806 - accuracy: 0.6125\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7274 - accuracy: 0.7250\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7907 - accuracy: 0.7500\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6255 - accuracy: 0.6750\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5927 - accuracy: 0.6625\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.8250\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.8000\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.9500\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.9500\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.8625\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3565 - accuracy: 0.8750\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.9625\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3147 - accuracy: 0.9500\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3001 - accuracy: 0.9500\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2832 - accuracy: 0.9250\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2658 - accuracy: 0.9750\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2569 - accuracy: 0.9625\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2369 - accuracy: 0.9625\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2299 - accuracy: 0.9375\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2237 - accuracy: 0.9625\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2105 - accuracy: 0.9625\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1927 - accuracy: 0.9625\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1957 - accuracy: 0.9625\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1748 - accuracy: 0.9750\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1569 - accuracy: 0.9750\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1320 - accuracy: 0.9875\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1388 - accuracy: 0.9750\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1248 - accuracy: 0.9750\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1160 - accuracy: 0.9875\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1099 - accuracy: 0.9625\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 0.9875\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1149 - accuracy: 0.9875\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1595 - accuracy: 0.9625\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1668 - accuracy: 0.9250\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1328 - accuracy: 0.9750\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1615 - accuracy: 0.9625\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2577 - accuracy: 0.8625\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2087 - accuracy: 0.9125\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1372 - accuracy: 0.9500\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0953 - accuracy: 0.9625\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0807 - accuracy: 0.9875\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9875\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1070 - accuracy: 0.9625\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1028 - accuracy: 0.9625\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1571 - accuracy: 0.9375\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 10.0533 - accuracy: 0.5385\n",
      "test_loss: 10.053316116333008 \n",
      "test_accuracy: 0.5384615659713745\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습!! \n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, \n",
    "                                                 beta_1=0.9, \n",
    "                                                 beta_2=0.999, \n",
    "                                                 epsilon=1e-07, \n",
    "                                                 amsgrad=False,),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, one_hot_encode, epochs=50)#Epoch만 학습합니다.\n",
    "# 오류는 dense 의 아웃풋 형태를 조절할 것 여기에서는 17로 줌\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, one1, verbose=1)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ae5c82e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['accuracy', 'loss']):\n",
    "    ax[i].plot(history1.history[met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6068b2c",
   "metadata": {
    "id": "1cc9e218"
   },
   "outputs": [],
   "source": [
    "# # 모델 학습!! \n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n",
    "#               loss='binary_crossentropy',\n",
    "#               #sparse_categorical_crossentropy쓰면 안됨\n",
    "#               metrics = [\n",
    "#                 'accuracy',\n",
    "#                 tf.keras.metrics.Precision(name='precision'),\n",
    "#                 tf.keras.metrics.Recall(name='recall')\n",
    "#                 ])\n",
    "\n",
    "\n",
    "# model.fit(x_train, y_train, epochs=100)    # 66 Epoch만 학습합니다.\n",
    "# # 오류는 dense 의 아웃풋 형태를 조절할 것 여기에서는 17로 줌\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba81598",
   "metadata": {
    "id": "52c83806"
   },
   "source": [
    "# 테스트 데이터로 정확도 뽑는 밑 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931b964e",
   "metadata": {
    "id": "f7202272"
   },
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98fdf24",
   "metadata": {
    "id": "5795fc55"
   },
   "outputs": [],
   "source": [
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb44178a",
   "metadata": {
    "id": "1a93e701",
    "outputId": "ad14ce9d-b15f-478d-9ac8-b5854ecd06c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     level_0\n",
      "45         2\n",
      "46         2\n",
      "47         2\n",
      "48         2\n",
      "49         2\n",
      "..       ...\n",
      "115        2\n",
      "116        2\n",
      "117        2\n",
      "118        2\n",
      "119        2\n",
      "\n",
      "[75 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "y_test = y_test - 1\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3f2542",
   "metadata": {
    "id": "ff81c0dc",
    "outputId": "ffcb2aef-050c-4ce7-f19e-f23b0b763104"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c38358",
   "metadata": {
    "id": "86d155e7",
    "outputId": "a0aa43a1-dee4-4f5d-d0f5-07a97ee6109f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64., 65., 65., ..., 60., 62., 66.])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212cbe28",
   "metadata": {
    "id": "1e29079d"
   },
   "outputs": [],
   "source": [
    "x_test1 = x_test1.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d5628b",
   "metadata": {
    "id": "cb914d9b"
   },
   "outputs": [],
   "source": [
    "x_test1 = x_test1.flatten()\n",
    "x_test2 = x_test1[:1125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337f892",
   "metadata": {
    "id": "784254f3"
   },
   "outputs": [],
   "source": [
    "x_test2 = x_test2.reshape(75,5,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af7463e",
   "metadata": {
    "id": "4bbc6b35"
   },
   "outputs": [],
   "source": [
    "x_test1 = x_test.drop('level_0', axis = 1)\n",
    "\n",
    "y_test = x_test.level_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1ddf08",
   "metadata": {
    "id": "c0062656"
   },
   "outputs": [],
   "source": [
    "y_test = y_test.astype('float')\n",
    "test_scores = model.evaluate(x_test2, y_test, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40e9d25",
   "metadata": {
    "id": "116c49df",
    "outputId": "da0eb52c-f9b1-4fc0-eb58-d1dcfd7b445d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss, test acc: [5.173856735229492, 0.03999999910593033]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\" , test_scores ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e28f76e",
   "metadata": {
    "id": "986d5760"
   },
   "source": [
    "# 테스트 결과값입니다 3.9퍼센트 예측(학습데이터에서 사람2명의 데이터가 대다수, 사람3의 데이터로 학습해보니 현저히 정확도가 낮게 나옴) 을 확인하였습니다 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2ff960",
   "metadata": {
    "id": "07ed9eae"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a64b96b0",
   "metadata": {
    "id": "639e5436"
   },
   "source": [
    "# 위 코드 까지 완벽?하게 먼저 해내기(cnn 돌리기)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c28855",
   "metadata": {
    "id": "a7391f87"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "# 데이터셋 로드하기\n",
    "# [[your code]\n",
    "data = rows\n",
    "data2 = rows2\n",
    "data9 = rows9\n",
    "# 훈련용 데이터셋 나누기\n",
    "# [[your code]\n",
    "X_train = rows[:14]\n",
    "X_test = rows[14:]\n",
    "\n",
    "y_train = data9[:14]\n",
    "y_test = data9[14:]\n",
    "\n",
    "print(\"y_train\")\n",
    "print(y_train)\n",
    "print('-'*90)\n",
    "print('-'*90)\n",
    "print(\"X_train\")\n",
    "print(X_train)\n",
    "# y_test2 = data2[:16]\n",
    "# y_test2 = y_test2.reshape(16,4)\n",
    "# 훈련하기\n",
    "# [[your code]\n",
    "print('-'*90)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eb4298",
   "metadata": {
    "id": "c438480d"
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeClassifierCV\n",
    "# clf = RidgeClassifierCV().fit(X_train, y_train)\n",
    "\n",
    "# roc_auc_score(rows4, rows5, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6aa898",
   "metadata": {
    "id": "a1cdc55b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "# 데이터셋 로드하기\n",
    "# [[your code]\n",
    "data = rows\n",
    "data2 = rows2\n",
    "data9 = rows9\n",
    "# 훈련용 데이터셋 나누기\n",
    "# [[your code]\n",
    "X_train = rows[:14]\n",
    "X_test = rows[14:]\n",
    "\n",
    "y_train = data9[:14]\n",
    "y_test = data9[14:]\n",
    "\n",
    "z_train = data9[:14]\n",
    "\n",
    "print(\"y_train\")\n",
    "print(y_train)\n",
    "print('-'*90)\n",
    "print('-'*90)\n",
    "print(\"X_train\")\n",
    "print(X_train)\n",
    "# y_test2 = data2[:16]\n",
    "# y_test2 = y_test2.reshape(16,4)\n",
    "# 훈련하기\n",
    "# [[your code]\n",
    "print('-'*90)\n",
    "print('-'*90)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "# X2, y2 = make_classification(n_samples=1000, n_features=4,\n",
    "#                              n_informative=2, n_redundant=0,\n",
    "#                              random_state=0, shuffle=False)\n",
    "# clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "# clf.fit(X2, y2)\n",
    "# print(X2)\n",
    "# print('-/'*90)\n",
    "# print('-/'*90)\n",
    "xtt = np.array(X_train)\n",
    "xt = xtt.reshape(-1,)\n",
    "ytt = np.array(y_train) #numpy array 로 바꿈!!\n",
    "yt = ytt.reshape(-1,) # numpy array 차원 축소!!! 1차원으로 만들어주기\n",
    "ett = np.array(y_test)\n",
    "ettt = ett.reshape(-1,)\n",
    "zt = np.array(z_train)\n",
    "\n",
    "print(\"xt : X_train 에 해당\")\n",
    "print(xt)\n",
    "print('-'*90)\n",
    "print(\"yt: y_train 에 해당 \")\n",
    "print(yt)\n",
    "print('-'*90)\n",
    "print(\"ett : y_test 에 해당\")\n",
    "print(ettt)\n",
    "print('-'*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9120da",
   "metadata": {
    "id": "20e2a61c"
   },
   "source": [
    "\n",
    "#열이 16개인 데이터셋\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f454238",
   "metadata": {
    "id": "86a32b2a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "# 데이터셋 로드하기\n",
    "# [[your code]\n",
    "data = rows\n",
    "data2 = rows2\n",
    "data9 = rows9\n",
    "# 훈련용 데이터셋 나누기\n",
    "# [[your code]\n",
    "X_train = rows[:14]\n",
    "X_test = rows[14:]\n",
    "\n",
    "y_train = data9[:14]\n",
    "y_test = data9[14:]\n",
    "\n",
    "z_train = data9[:14]\n",
    "\n",
    "print(\"y_train\")\n",
    "print(y_train)\n",
    "print('-'*90)\n",
    "print('-'*90)\n",
    "print(\"X_train\")\n",
    "print(X_train)\n",
    "# y_test2 = data2[:16]\n",
    "# y_test2 = y_test2.reshape(16,4)\n",
    "# 훈련하기\n",
    "# [[your code]\n",
    "print('-'*90)\n",
    "print('-'*90)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "# X2, y2 = make_classification(n_samples=1000, n_features=4,\n",
    "#                              n_informative=2, n_redundant=0,\n",
    "#                              random_state=0, shuffle=False)\n",
    "# clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "# clf.fit(X2, y2)\n",
    "# print(X2)\n",
    "# print('-/'*90)\n",
    "# print('-/'*90)\n",
    "xtt = np.array(X_train)\n",
    "xt = xtt.reshape(-1,)\n",
    "ytt = np.array(y_train) #numpy array 로 바꿈!!\n",
    "yt = ytt.reshape(-1,) # numpy array 차원 축소!!! 1차원으로 만들어주기\n",
    "ett = np.array(y_test)  \n",
    "ettt = ett.reshape(-1,)\n",
    "zt = np.array(z_train)\n",
    "\n",
    "print(\"xt : X_train 에 해당\")\n",
    "print(xt)\n",
    "print('-'*90)\n",
    "print(\"yt: y_train 에 해당 \")\n",
    "print(yt)\n",
    "print('-'*90)\n",
    "print(\"ett : y_test 에 해당\")\n",
    "print(ettt)\n",
    "print('-'*90)\n",
    "\n",
    "xt = np.expand_dims(xt, axis=0) # 차원 확대\n",
    "yt = np.expand_dims(yt, axis=0) # 차원 확대 \n",
    "xt0909 = np.expand_dims(xt, axis=0)\n",
    "np.expand_dims(yt, axis=0)\n",
    "print(\"xt0909\")\n",
    "print(xt0909)\n",
    "print(\"xt\")\n",
    "print(xt)\n",
    "print('-'*90)\n",
    "print(\"yt\")\n",
    "print(yt)\n",
    "print('-'*90)\n",
    "print('-*'*90)\n",
    "# clf = MultiOutputClassifier(KNeighborsClassifier()).fit(xt,yt) # 2차원 이상의 배열이 필요함...\n",
    "knn = KNeighborsClassifier(n_neighbors=88)#여기에서 n_neighbers =1 이 중요!!! 입력 데이터 형태를 보면 1로 해야함\n",
    "knn = MultiOutputClassifier(KNeighborsClassifier(n_neighbors=1)).fit(xt,yt) #2차원 필요\n",
    "print(\"knn 예측치\")\n",
    "knnmaster1 = knn.predict(xt[-2:]) #We select the training set with the [:-1] Python syntax,\n",
    "#which produces a new array that contains all but the last item from digits.data:\n",
    "print(\"knmaster1\")\n",
    "print(knnmaster1)\n",
    "print('-*'*90)\n",
    "\n",
    "\n",
    "print(\"정답률=\", knn.score(yt, xt)) ###########################\n",
    "\n",
    "\n",
    "print('-*'*90)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(xt, yt)\n",
    "print('-'*90)\n",
    "# 예측하기\n",
    "# [[your code]\n",
    "y_pred1 = model.predict(xt)\n",
    "# 정답률 출력하기\n",
    "# [[your code]\n",
    "print(\"randomforest 예측치 : \" )\n",
    "print(y_pred1)\n",
    "\n",
    "print('-'*90)\n",
    "\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=255,min_samples_split=5,max_depth=6)\n",
    "decision_tree.fit(xt, yt)\n",
    "y_pred2 = decision_tree.predict(xt)\n",
    "print(\"Decision Tree classifier 예측치\")\n",
    "print(y_pred2)\n",
    "print('-'*90)\n",
    "\n",
    "y_testt = np.transpose(y_test)\n",
    "print(y_test)\n",
    "print('-'*90)\n",
    "#y_test = np.expand_dims(y_test, axis=0)\n",
    "\n",
    "print('decision tree 테스트 : y_test')\n",
    "print(y_test)\n",
    "print('-'*90)\n",
    "print('decision tree 예측치 : y_pred1')\n",
    "print(y_pred1)\n",
    "print('-'*90)\n",
    "print('-'*90) \n",
    "#svm 은 y 가 1차원이어야 한다고 한다.\n",
    "yt2 = yt.reshape(-1,) # numpy array 차원 축소!!! 1차원으로 만들어주기\n",
    "xt2 = xt.reshape(-1,)\n",
    "xt3 = xt2.reshape(-1, 1)\n",
    "yt3 = yt2.reshape(-1, 1) #조진호(사람2) 데이터            \n",
    "ett2 = ett.reshape(-1,)\n",
    "ett3 = ett.reshape(-1, 1) #최주원(사람3) 데이터\n",
    "zt3 = zt.reshape(-1,)\n",
    "zt3 = zt.reshape(-1,1)\n",
    "\n",
    "print(\"zt3\")\n",
    "print(zt3)\n",
    "print('--'*60)\n",
    "print(\"xt2 : xt를 reshape 으로(-1,) 한 결과 \")\n",
    "print(xt2)\n",
    "print('--'*90)\n",
    "print(\"xt3 : xt2를 reshape 으로 (-1,1)한 결과 \")\n",
    "print(xt3)\n",
    "print('--'*90)\n",
    "from sklearn import svm\n",
    "\n",
    "print('-'*90)\n",
    "print('-'*90)\n",
    "\n",
    "\n",
    "ett4 =ett3.reshape(-1,)\n",
    "yt33 = yt3.reshape(-1,) #차원축소\n",
    "xt33 = xt3.reshape(-1,)\n",
    "\n",
    "print('--'*90)\n",
    "\n",
    "yt4 = yt3.reshape(-1,)\n",
    "ett3= ett3.reshape(-1,)\n",
    "\n",
    "print(ett4)\n",
    "yt5 = yt4[:96]\n",
    "\n",
    "accuracy = accuracy_score(ett4, yt5) #같은 shape 이어야 함. accuracy 랑 다른게 있다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46013318",
   "metadata": {
    "id": "99210522"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78894f97",
   "metadata": {
    "id": "3ac62f5e"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"정확도 계산중... \")\n",
    "print(\" 정확도는 다음과 같다 \")\n",
    "print(accuracy*100)\n",
    "# from sklearn.datasets import make_blobs\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# X,y = make_multilabel_classification(n_classes= 3,random_state = 0)\n",
    "\n",
    "# clf.predict(X[-2:])\n",
    "yt999 = yt3.reshape(-1,1)\n",
    "ytridge2 = yt999.reshape(-1,)\n",
    "xt35 = xt3.reshape(-1,1)\n",
    "# knn = KNeighborsClassifier(n_neighbors=3)\n",
    "# classifier = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "# classifier.fit(y_test,y_pred)\n",
    "# predictions = classifier.predict(y_train)\n",
    "# classifier.score(y_true,np.array(y_train))\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "clf = RidgeClassifierCV(cv = 5, normalize = True,).fit(xt35 , yt999) #1d array 필요 .ravel() 써서 평평하게 함 \n",
    "y_score = clf.decision_function(yt999) #2d array 필요 \n",
    "print(\"ridgeclassifier 스코어\")\n",
    "print(y_score)\n",
    "\n",
    "# from sklearn.datasets import make_multilabel_classification\n",
    "# from sklearn.multioutput import MultiOutputClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# X, y = make_multilabel_classification(random_state=0)\n",
    "# inner_clf = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "# clf = MultiOutputClassifier(inner_clf).fit(X, y)\n",
    "# y_score = np.transpose([y_pred[:, 1] for y_pred in clf.predict_proba(X)])\n",
    "# roc_auc_score(y, y_score, average=None)\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn import datasets\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "\n",
    "# clf9 = Pipeline([\n",
    "#   ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\"))),\n",
    "#   ('classification', RandomForestClassifier())\n",
    "# ])\n",
    "ett999 = ett3.reshape(-1,1)\n",
    "\n",
    "gbrt = GradientBoostingClassifier(learning_rate=0.1,n_estimators =650,max_leaf_nodes=None, random_state=0,max_depth=6)\n",
    "gbrt.fit(xt3, yt3)\n",
    "print(\"gbrt결정 함수의 결과 형태: {}\".format(gbrt.decision_function(yt999).shape))#2차원 요구--> ett3\n",
    "# plot the first few entries of the decision function\n",
    "print(\"gbrt결정 함수 결과:\\n{}\".format(gbrt.decision_function(yt999)[:6, :]))\n",
    "print('/*/'*90)\n",
    "print(\"gbrt가장 큰 결정 함수의 인덱스:\\n{}\".format(\n",
    "      np.argmax(gbrt.decision_function(yt999), axis=1)))\n",
    "print(\"gbrt예측:\\n{}\".format(gbrt.predict(yt999)))\n",
    "print(\"gbrt 스코어\")\n",
    "print(gbrt.score(xt3,yt3))\n",
    "\n",
    "# 가장 큰 결정 함수의 인덱스:\n",
    "# [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
    "#  0]\n",
    "# 예측:\n",
    "# [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
    "#  0]\n",
    "print('/*/'*90)\n",
    "# predict_proba 결과 중 앞부분 일부를 확인합니다\n",
    "print(\"예측 확률:\\n{}\".format(gbrt.predict_proba(yt999)[:9]))\n",
    "# 행 방향으로 확률을 더하면 1 이 됩니다\n",
    "print(\"합: {}\".format(gbrt.predict_proba(yt999)[:9].sum(axis=1)))\n",
    "# 예측 확률:\n",
    "# [[0.10664722 0.7840248  0.10932798]\n",
    "#  [0.78880668 0.10599243 0.10520089]\n",
    "#  [0.10231173 0.10822274 0.78946553]\n",
    "#  [0.10664722 0.7840248  0.10932798]\n",
    "#  [0.10825347 0.66344934 0.22829719]\n",
    "#  [0.78880668 0.10599243 0.10520089]]\n",
    "# 합: [1. 1. 1. 1. 1. 1.]\n",
    "print('/*/'*90)\n",
    "x8x8 = pd.DataFrame(gbrt.decision_function(ett999))\n",
    "\n",
    "x9x9 = x8x8.corr()\n",
    "\n",
    "e9e9 = sns.heatmap(x9x9, cmap = 'viridis')\n",
    "\n",
    "e0e0 = sns.scatterplot(xt33,yt33)\n",
    "plt.show()\n",
    "print('/*/'*90)\n",
    "print(e0e0)\n",
    "print('/*/'*90)\n",
    "\n",
    "x88x88 = pd.DataFrame(gbrt.decision_function(yt999))\n",
    "x99x99 = x88x88.corr()\n",
    "e99e99 = sns.heatmap(x99x99, cmap = 'viridis')\n",
    "# e0e0 = sns.scatterplot(xt33,yt33)\n",
    "plt.show()\n",
    "\n",
    "print(e99e99)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xt39 = np.transpose(xt3)\n",
    "yt39 = np.transpose(yt3)\n",
    "ett39 = np.transpose(ett3)\n",
    "zt39 = np.transpose(zt3)\n",
    "print(\"zt39\")\n",
    "print(zt39.shape)\n",
    "print(zt39)\n",
    "print('/*/'*90)\n",
    "s = [0.7*np.linalg.norm([a, b]) for a, b in zip(xt3, yt3)]\n",
    "s = [a / max(s) for a in s]  # scale\n",
    "print(\"ett3.shape\")\n",
    "print(ett3.shape)\n",
    "print('/*/'*90)\n",
    "print(\"xt39.shape :xt39 = np.transpose(xt3)\")\n",
    "print(xt39.shape)\n",
    "print('/*/'*90)\n",
    "print(\"xt39\")\n",
    "print(xt39)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00ef275",
   "metadata": {
    "id": "7b09cf1a"
   },
   "outputs": [],
   "source": [
    "\n",
    "ax= plt.scatter(xt39[:300], yt39[:300], c=s, s=30, cmap=plt.cm.Paired)\n",
    "clf = SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2, gamma=0.2,\n",
    "  kernel='rbf', shrinking=True, tol=0.001)#파이프라인만들기\n",
    "\n",
    "clf.fit(xt3,yt3) #2차원으로 fit X(왼쪽 xt3)에는 포인트가 있고 Y에는 해당 포인트가 속한 클래스가 있습니다.\n",
    "\n",
    "# 초평면(Hyper-Plane) 표현\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "print(\"XX.shape :np.meshgrid(yy, xx)\")\n",
    "print(XX.shape)\n",
    "\n",
    "\n",
    "\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "print(\"xy.shape : np.vstack([XX.ravel(), YY.ravel()]).T \")\n",
    "print(xy.shape)\n",
    "xy = xy.reshape(-1,1)\n",
    "\n",
    "\n",
    "xy1 = xy[:30]\n",
    "xy1 = xy1.flatten()\n",
    "xy1 = xy1[:899]\n",
    "print(\"xy1\")\n",
    "print(xy1)\n",
    "xy1 = xy1.reshape(-1,1)#$$$\n",
    "xy2 = xy1[:30]#$$$\n",
    "xy3 = xy2.flatten()#$$$\n",
    "print(\"xy3\")\n",
    "print(xy3)\n",
    "xy3 = xy3[:30]\n",
    "xy99 = xy3.reshape(30,)#$$$\n",
    "print(\"xy3\")\n",
    "print(xy3)\n",
    "xy5= xy99.reshape(-1,1)#$$$\n",
    "# print(\"clfdecisionfuction\")\n",
    "# print(fig.add_subplot(112, clf.decision_function(xy5)))\n",
    "# Z = clf.decision_function(xy5).reshape(30,30)\n",
    "# Z = clf.decision_function(xy5).reshape(-1,)#1차원으로 만들기\n",
    "# print(Z)\n",
    "# Z = Z[:900] # 900개까지 나열\n",
    "# Z = Z.reshape(30,30) #30*30 행렬로 reshape\n",
    "# ax.contour(XX, YY, Z, colors='k', levels=[-1,0,1], alpha=0.9, linestyles=['--', '-', '--'])\n",
    "# # 지지벡터(Support Vector) 표현 \n",
    "# ax.scatter(clf.support_vectors_[:,1], clf.support_vectors_[:,1], s=60, facecolors='r')\n",
    "# plt.show()\n",
    "# fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "\n",
    "# ax2 = fig.add_subplot(111, projection='3d')\n",
    "# ax2.scatter(xt39[:100], yt39[:100], yt39[:100], c= s , marker='o', s=15, cmap='Greens')\n",
    "\n",
    "# print(yt3.shape)\n",
    "# yt4 = yt3.reshape(-1,)\n",
    "# print(yt4)\n",
    "# print(\"ett4\")\n",
    "# print(ett4)\n",
    "# yt5 = yt4[:96]\n",
    "# print(\"yt5\")\n",
    "# print(yt5)\n",
    "# accuracy = accuracy_score(ett4, yt5) #같은 shape 이어야 함. accuracy 랑 다른게 있다. \n",
    "\n",
    "\n",
    "# print(\"정확도 계산중... \")\n",
    "# print(\" 정확도는 다음과 같다 \")\n",
    "# print(accuracy*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da03f9",
   "metadata": {
    "id": "58d39b2d"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# from sklearn.datasets import make_blobs\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# X,y = make_multilabel_classification(n_classes= 3,random_state = 0)\n",
    "\n",
    "# clf.predict(X[-2:])\n",
    "\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=3)\n",
    "# classifier = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "# classifier.fit(y_test,y_pred)\n",
    "# predictions = classifier.predict(y_train)\n",
    "# classifier.score(y_true,np.array(y_train))\n",
    "\n",
    "# from sklearn.linear_model import RidgeClassifierCV\n",
    "# clf = RidgeClassifierCV().fit(X_train, y_train)\n",
    "# y_score = clf.decision_function(X_train)\n",
    "# roc_auc_score(y_test, y_train, average=None)\n",
    "\n",
    "# from sklearn.datasets import make_multilabel_classification\n",
    "# from sklearn.multioutput import MultiOutputClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# X, y = make_multilabel_classification(random_state=0)\n",
    "# inner_clf = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "# clf = MultiOutputClassifier(inner_clf).fit(X, y)\n",
    "# y_score = np.transpose([y_pred[:, 1] for y_pred in clf.predict_proba(X)])\n",
    "# roc_auc_score(y, y_score, average=None)\n",
    "clf = svm.SVC(kernel=\"linear\", C=1000)\n",
    "x__train = xt3.reshape(-1,1)\n",
    "y__train = yt3.reshape(-1,1)\n",
    "\n",
    "clf.fit(x__train, y__train)\n",
    "print(xt3.shape)\n",
    "print(yt3.shape)\n",
    "s = [0.1*np.linalg.norm([a, b]) for a, b in zip(xt3, yt3)]\n",
    "s = [a / max(s) for a in s]  # scale\n",
    "\n",
    "plt.scatter(xt3[:224], xt3[:224], c=s, s=30, cmap=plt.cm.Paired)\n",
    "\n",
    "# decision function 표현 초평면(Hyper-Plane) 표현\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "# plot decision boundary and margins\n",
    "# Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "ax.contour(XX, YY, colors=\"k\", levels=[-1, 0, 1], alpha=0.5, linestyles=[\"--\", \"-\", \"--\"])\n",
    "\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()])\n",
    "\n",
    "\n",
    "\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, colors=\"k\", levels=[-1, 0, 1], alpha=0.5, linestyles=[\"--\", \"-\", \"--\"])\n",
    "\n",
    "# 지지벡터(Support Vector) 표현\n",
    "ax.scatter(\n",
    "    clf.support_vectors_[:, 0],\n",
    "    clf.support_vectors_[:, 1],\n",
    "    s=100,\n",
    "    linewidth=1,\n",
    "    facecolors=\"none\",\n",
    "    edgecolors=\"k\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fed84f",
   "metadata": {
    "id": "28bd740a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56461e85",
   "metadata": {
    "id": "736eea9c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffa1832",
   "metadata": {
    "id": "4dba1a47"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "0323-12.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
