{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58237efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52,54,58,62,63,66,68,70,68,70,70,73,74,75,77,78,Mei\n",
      "65,68,66,68,71,74,74,76,72,74,74,75,76,77,80,80,조진호\n",
      "51,55,58,60,66,67,67,69,68,70,74,73,78,76,78,80,최주원\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "\n",
    "with open(\"mei.csv\", 'r', encoding=\"utf-8\") as read_: #read다음에_는 의미가 없다. read랑 헷갈리지말라고 쓴 것. a 라고 해도 무방.\n",
    "    text=read_.readlines()\n",
    "\n",
    "rows=[]\n",
    "for i in text[1:]:\n",
    "    rows.append(list(map(int,i.split(\",\")[:-1])))\n",
    "print(i)\n",
    "\n",
    "df=pd.DataFrame(rows)\n",
    "df.columns=[\"sensor%d\"%i for i in range(1,17)]\n",
    "\n",
    "with open(\"jo.csv\", 'r', encoding=\"utf-8\") as read_:\n",
    "    text2=read_.readlines()\n",
    "    \n",
    "\n",
    "rows2=[]\n",
    "for i in text2[1:]:\n",
    "    rows2.append(list(map(int,i.split(\",\")[:-1])))\n",
    "print(i)\n",
    "\n",
    "with open(\"joo.csv\", 'r', encoding=\"utf-8\") as read_:\n",
    "    text3=read_.readlines()\n",
    "    \n",
    "rows9=[]\n",
    "for i in text3[1:]:\n",
    "    rows9.append(list(map(int,i.split(\",\")[:-1])))\n",
    "print(i)\n",
    "\n",
    "df2=pd.DataFrame(rows2)\n",
    "df2.columns=[\"sensor%d\"%i for i in range(1,17)]\n",
    "\n",
    "\n",
    "df3=pd.DataFrame(rows3)\n",
    "df3.columns=[\"sensor%d\"%i for i in range(1,17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd58e4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 16)\n",
      "   sensor1  sensor2  sensor3  sensor4  sensor5  sensor6  sensor7  sensor8  \\\n",
      "0       91       93       85       90       95       93       86       91   \n",
      "1       70       73       69       71       76       76       77       78   \n",
      "2       65       64       68       67       72       71       74       73   \n",
      "3       13       19       24       29       35       37       41       47   \n",
      "4      102      100      102       97       99       99       97       96   \n",
      "\n",
      "   sensor9  sensor10  sensor11  sensor12  sensor13  sensor14  sensor15  \\\n",
      "0       87        87        87        86        88        87        90   \n",
      "1       74        75        76        78        79        80        78   \n",
      "2       73        70        72        74        77        77        78   \n",
      "3       44        48        51        55        58        59        59   \n",
      "4       92        91        89        89        91        91        90   \n",
      "\n",
      "   sensor16  \n",
      "0        87  \n",
      "1        81  \n",
      "2        78  \n",
      "3        62  \n",
      "4        88  \n",
      "(20, 16)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import seaborn;\n",
    "seaborn.set()\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "image1 = df.astype('float')\n",
    "image2 = df2.astype('float')\n",
    "\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "y2 = ['sensor1']\n",
    "y1 = ['sensor1','sensor2','sensor3','sensor4','sensor5','sensor6','sensor7','sensor8','sensor9','sensor10','sensor11','sensor12','sensor13','sensor14','sensor15','sensor16'] # define y variable, i.e., what we want to predict\n",
    "print(df.shape) # print the number of rows anc columns\n",
    "\n",
    "print(df.head())\n",
    "print(df2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "188c7434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train\n",
      "[[58, 59, 60, 63, 66, 69, 70, 70, 70, 70, 71, 72, 76, 76, 77, 78], [55, 59, 64, 64, 66, 69, 70, 71, 68, 71, 70, 73, 75, 75, 78, 76], [55, 58, 59, 63, 67, 68, 70, 71, 68, 70, 71, 72, 76, 77, 77, 77], [56, 58, 61, 63, 62, 67, 71, 71, 69, 71, 71, 73, 75, 76, 75, 78], [58, 59, 62, 68, 67, 70, 69, 74, 69, 71, 73, 73, 77, 78, 77, 78], [50, 52, 55, 58, 60, 63, 65, 67, 67, 66, 68, 69, 73, 73, 75, 76], [29, 34, 37, 41, 46, 51, 52, 55, 54, 56, 59, 61, 65, 66, 68, 70], [35, 39, 44, 46, 52, 54, 58, 60, 58, 60, 62, 64, 68, 70, 71, 72], [58, 61, 63, 66, 67, 69, 71, 72, 68, 72, 73, 72, 77, 77, 77, 82], [60, 62, 64, 66, 69, 71, 73, 73, 74, 71, 72, 75, 77, 78, 78, 80], [55, 59, 59, 63, 64, 67, 67, 70, 69, 74, 71, 73, 76, 79, 78, 78], [27, 32, 40, 41, 48, 49, 53, 53, 55, 57, 58, 61, 64, 67, 68, 70], [0, 0, 6, 12, 21, 25, 30, 34, 35, 41, 42, 49, 52, 49, 56, 58], [21, 26, 34, 35, 40, 44, 50, 48, 52, 55, 59, 58, 62, 64, 66, 68]]\n",
      "------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------\n",
      "X_train\n",
      "[[91, 93, 85, 90, 95, 93, 86, 91, 87, 87, 87, 86, 88, 87, 90, 87], [70, 73, 69, 71, 76, 76, 77, 78, 74, 75, 76, 78, 79, 80, 78, 81], [65, 64, 68, 67, 72, 71, 74, 73, 73, 70, 72, 74, 77, 77, 78, 78], [13, 19, 24, 29, 35, 37, 41, 47, 44, 48, 51, 55, 58, 59, 59, 62], [102, 100, 102, 97, 99, 99, 97, 96, 92, 91, 89, 89, 91, 91, 90, 88], [76, 78, 76, 77, 79, 80, 81, 81, 79, 81, 80, 81, 81, 83, 82, 80], [70, 71, 72, 72, 76, 76, 77, 77, 74, 74, 71, 76, 81, 79, 80, 80], [167, 163, 157, 151, 149, 145, 139, 136, 130, 127, 122, 120, 120, 120, 115, 117], [36, 40, 44, 47, 50, 53, 58, 57, 57, 59, 61, 63, 67, 69, 71, 69], [50, 56, 55, 57, 62, 64, 64, 67, 64, 67, 68, 65, 71, 75, 73, 75], [50, 52, 52, 56, 62, 64, 65, 66, 65, 66, 69, 68, 73, 73, 73, 74], [43, 49, 50, 54, 57, 58, 61, 64, 61, 65, 67, 66, 69, 70, 71, 74], [79, 75, 73, 77, 80, 81, 76, 82, 80, 79, 81, 82, 85, 84, 84, 83], [79, 79, 79, 81, 82, 82, 83, 85, 81, 81, 81, 83, 86, 87, 87, 85]]\n",
      "-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/\n",
      "-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/\n",
      "xt : X_train 에 해당\n",
      "[ 91  93  85  90  95  93  86  91  87  87  87  86  88  87  90  87  70  73\n",
      "  69  71  76  76  77  78  74  75  76  78  79  80  78  81  65  64  68  67\n",
      "  72  71  74  73  73  70  72  74  77  77  78  78  13  19  24  29  35  37\n",
      "  41  47  44  48  51  55  58  59  59  62 102 100 102  97  99  99  97  96\n",
      "  92  91  89  89  91  91  90  88  76  78  76  77  79  80  81  81  79  81\n",
      "  80  81  81  83  82  80  70  71  72  72  76  76  77  77  74  74  71  76\n",
      "  81  79  80  80 167 163 157 151 149 145 139 136 130 127 122 120 120 120\n",
      " 115 117  36  40  44  47  50  53  58  57  57  59  61  63  67  69  71  69\n",
      "  50  56  55  57  62  64  64  67  64  67  68  65  71  75  73  75  50  52\n",
      "  52  56  62  64  65  66  65  66  69  68  73  73  73  74  43  49  50  54\n",
      "  57  58  61  64  61  65  67  66  69  70  71  74  79  75  73  77  80  81\n",
      "  76  82  80  79  81  82  85  84  84  83  79  79  79  81  82  82  83  85\n",
      "  81  81  81  83  86  87  87  85]\n",
      "------------------------------------------------------------------------------------------\n",
      "yt: y_train 에 해당 \n",
      "[58 59 60 63 66 69 70 70 70 70 71 72 76 76 77 78 55 59 64 64 66 69 70 71\n",
      " 68 71 70 73 75 75 78 76 55 58 59 63 67 68 70 71 68 70 71 72 76 77 77 77\n",
      " 56 58 61 63 62 67 71 71 69 71 71 73 75 76 75 78 58 59 62 68 67 70 69 74\n",
      " 69 71 73 73 77 78 77 78 50 52 55 58 60 63 65 67 67 66 68 69 73 73 75 76\n",
      " 29 34 37 41 46 51 52 55 54 56 59 61 65 66 68 70 35 39 44 46 52 54 58 60\n",
      " 58 60 62 64 68 70 71 72 58 61 63 66 67 69 71 72 68 72 73 72 77 77 77 82\n",
      " 60 62 64 66 69 71 73 73 74 71 72 75 77 78 78 80 55 59 59 63 64 67 67 70\n",
      " 69 74 71 73 76 79 78 78 27 32 40 41 48 49 53 53 55 57 58 61 64 67 68 70\n",
      "  0  0  6 12 21 25 30 34 35 41 42 49 52 49 56 58 21 26 34 35 40 44 50 48\n",
      " 52 55 59 58 62 64 66 68]\n",
      "------------------------------------------------------------------------------------------\n",
      "ett : y_test 에 해당\n",
      "[103 103 103 102 103 103  99 102  96  95  93  95  96  95  94  95  80  80\n",
      "  80  82  84  83  84  85  81  81  81  82  87  85  84  85  76  78  78  80\n",
      "  80  85  83  83  80  82  81  84  84  88  85  86  66  66  68  69  74  74\n",
      "  75  76  75  76  77  78  82  81  83  82  65  66  68  70  73  76  73  77\n",
      "  73  78  76  79  80  83  81  82  51  55  58  60  66  67  67  69  68  70\n",
      "  74  73  78  76  78  80]\n",
      "------------------------------------------------------------------------------------------\n",
      "xt\n",
      "[[ 91  93  85  90  95  93  86  91  87  87  87  86  88  87  90  87  70  73\n",
      "   69  71  76  76  77  78  74  75  76  78  79  80  78  81  65  64  68  67\n",
      "   72  71  74  73  73  70  72  74  77  77  78  78  13  19  24  29  35  37\n",
      "   41  47  44  48  51  55  58  59  59  62 102 100 102  97  99  99  97  96\n",
      "   92  91  89  89  91  91  90  88  76  78  76  77  79  80  81  81  79  81\n",
      "   80  81  81  83  82  80  70  71  72  72  76  76  77  77  74  74  71  76\n",
      "   81  79  80  80 167 163 157 151 149 145 139 136 130 127 122 120 120 120\n",
      "  115 117  36  40  44  47  50  53  58  57  57  59  61  63  67  69  71  69\n",
      "   50  56  55  57  62  64  64  67  64  67  68  65  71  75  73  75  50  52\n",
      "   52  56  62  64  65  66  65  66  69  68  73  73  73  74  43  49  50  54\n",
      "   57  58  61  64  61  65  67  66  69  70  71  74  79  75  73  77  80  81\n",
      "   76  82  80  79  81  82  85  84  84  83  79  79  79  81  82  82  83  85\n",
      "   81  81  81  83  86  87  87  85]]\n",
      "------------------------------------------------------------------------------------------\n",
      "yt\n",
      "[[58 59 60 63 66 69 70 70 70 70 71 72 76 76 77 78 55 59 64 64 66 69 70 71\n",
      "  68 71 70 73 75 75 78 76 55 58 59 63 67 68 70 71 68 70 71 72 76 77 77 77\n",
      "  56 58 61 63 62 67 71 71 69 71 71 73 75 76 75 78 58 59 62 68 67 70 69 74\n",
      "  69 71 73 73 77 78 77 78 50 52 55 58 60 63 65 67 67 66 68 69 73 73 75 76\n",
      "  29 34 37 41 46 51 52 55 54 56 59 61 65 66 68 70 35 39 44 46 52 54 58 60\n",
      "  58 60 62 64 68 70 71 72 58 61 63 66 67 69 71 72 68 72 73 72 77 77 77 82\n",
      "  60 62 64 66 69 71 73 73 74 71 72 75 77 78 78 80 55 59 59 63 64 67 67 70\n",
      "  69 74 71 73 76 79 78 78 27 32 40 41 48 49 53 53 55 57 58 61 64 67 68 70\n",
      "   0  0  6 12 21 25 30 34 35 41 42 49 52 49 56 58 21 26 34 35 40 44 50 48\n",
      "  52 55 59 58 62 64 66 68]]\n",
      "------------------------------------------------------------------------------------------\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "knn 예측치\n",
      "[[58 59 60 63 66 69 70 70 70 70 71 72 76 76 77 78 55 59 64 64 66 69 70 71\n",
      "  68 71 70 73 75 75 78 76 55 58 59 63 67 68 70 71 68 70 71 72 76 77 77 77\n",
      "  56 58 61 63 62 67 71 71 69 71 71 73 75 76 75 78 58 59 62 68 67 70 69 74\n",
      "  69 71 73 73 77 78 77 78 50 52 55 58 60 63 65 67 67 66 68 69 73 73 75 76\n",
      "  29 34 37 41 46 51 52 55 54 56 59 61 65 66 68 70 35 39 44 46 52 54 58 60\n",
      "  58 60 62 64 68 70 71 72 58 61 63 66 67 69 71 72 68 72 73 72 77 77 77 82\n",
      "  60 62 64 66 69 71 73 73 74 71 72 75 77 78 78 80 55 59 59 63 64 67 67 70\n",
      "  69 74 71 73 76 79 78 78 27 32 40 41 48 49 53 53 55 57 58 61 64 67 68 70\n",
      "   0  0  6 12 21 25 30 34 35 41 42 49 52 49 56 58 21 26 34 35 40 44 50 48\n",
      "  52 55 59 58 62 64 66 68]]\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "정답률= 0.0\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "------------------------------------------------------------------------------------------\n",
      "[[58 59 60 63 66 69 70 70 70 70 71 72 76 76 77 78 55 59 64 64 66 69 70 71\n",
      "  68 71 70 73 75 75 78 76 55 58 59 63 67 68 70 71 68 70 71 72 76 77 77 77\n",
      "  56 58 61 63 62 67 71 71 69 71 71 73 75 76 75 78 58 59 62 68 67 70 69 74\n",
      "  69 71 73 73 77 78 77 78 50 52 55 58 60 63 65 67 67 66 68 69 73 73 75 76\n",
      "  29 34 37 41 46 51 52 55 54 56 59 61 65 66 68 70 35 39 44 46 52 54 58 60\n",
      "  58 60 62 64 68 70 71 72 58 61 63 66 67 69 71 72 68 72 73 72 77 77 77 82\n",
      "  60 62 64 66 69 71 73 73 74 71 72 75 77 78 78 80 55 59 59 63 64 67 67 70\n",
      "  69 74 71 73 76 79 78 78 27 32 40 41 48 49 53 53 55 57 58 61 64 67 68 70\n",
      "   0  0  6 12 21 25 30 34 35 41 42 49 52 49 56 58 21 26 34 35 40 44 50 48\n",
      "  52 55 59 58 62 64 66 68]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Decision Tree classifier 예측치\n",
      "[[58 59 60 63 66 69 70 70 70 70 71 72 76 76 77 78 55 59 64 64 66 69 70 71\n",
      "  68 71 70 73 75 75 78 76 55 58 59 63 67 68 70 71 68 70 71 72 76 77 77 77\n",
      "  56 58 61 63 62 67 71 71 69 71 71 73 75 76 75 78 58 59 62 68 67 70 69 74\n",
      "  69 71 73 73 77 78 77 78 50 52 55 58 60 63 65 67 67 66 68 69 73 73 75 76\n",
      "  29 34 37 41 46 51 52 55 54 56 59 61 65 66 68 70 35 39 44 46 52 54 58 60\n",
      "  58 60 62 64 68 70 71 72 58 61 63 66 67 69 71 72 68 72 73 72 77 77 77 82\n",
      "  60 62 64 66 69 71 73 73 74 71 72 75 77 78 78 80 55 59 59 63 64 67 67 70\n",
      "  69 74 71 73 76 79 78 78 27 32 40 41 48 49 53 53 55 57 58 61 64 67 68 70\n",
      "   0  0  6 12 21 25 30 34 35 41 42 49 52 49 56 58 21 26 34 35 40 44 50 48\n",
      "  52 55 59 58 62 64 66 68]]\n",
      "------------------------------------------------------------------------------------------\n",
      "[[103, 103, 103, 102, 103, 103, 99, 102, 96, 95, 93, 95, 96, 95, 94, 95], [80, 80, 80, 82, 84, 83, 84, 85, 81, 81, 81, 82, 87, 85, 84, 85], [76, 78, 78, 80, 80, 85, 83, 83, 80, 82, 81, 84, 84, 88, 85, 86], [66, 66, 68, 69, 74, 74, 75, 76, 75, 76, 77, 78, 82, 81, 83, 82], [65, 66, 68, 70, 73, 76, 73, 77, 73, 78, 76, 79, 80, 83, 81, 82], [51, 55, 58, 60, 66, 67, 67, 69, 68, 70, 74, 73, 78, 76, 78, 80]]\n",
      "------------------------------------------------------------------------------------------\n",
      "y_test\n",
      "[[103, 103, 103, 102, 103, 103, 99, 102, 96, 95, 93, 95, 96, 95, 94, 95], [80, 80, 80, 82, 84, 83, 84, 85, 81, 81, 81, 82, 87, 85, 84, 85], [76, 78, 78, 80, 80, 85, 83, 83, 80, 82, 81, 84, 84, 88, 85, 86], [66, 66, 68, 69, 74, 74, 75, 76, 75, 76, 77, 78, 82, 81, 83, 82], [65, 66, 68, 70, 73, 76, 73, 77, 73, 78, 76, 79, 80, 83, 81, 82], [51, 55, 58, 60, 66, 67, 67, 69, 68, 70, 74, 73, 78, 76, 78, 80]]\n",
      "index: 0, value: [103, 103, 103, 102, 103, 103, 99, 102, 96, 95, 93, 95, 96, 95, 94, 95]\n",
      "index: 1, value: [80, 80, 80, 82, 84, 83, 84, 85, 81, 81, 81, 82, 87, 85, 84, 85]\n",
      "index: 2, value: [76, 78, 78, 80, 80, 85, 83, 83, 80, 82, 81, 84, 84, 88, 85, 86]\n",
      "index: 3, value: [66, 66, 68, 69, 74, 74, 75, 76, 75, 76, 77, 78, 82, 81, 83, 82]\n",
      "index: 4, value: [65, 66, 68, 70, 73, 76, 73, 77, 73, 78, 76, 79, 80, 83, 81, 82]\n",
      "index: 5, value: [51, 55, 58, 60, 66, 67, 67, 69, 68, 70, 74, 73, 78, 76, 78, 80]\n",
      "------------------------------------------------------------------------------------------\n",
      "y_pred1\n",
      "[[58 59 60 63 66 69 70 70 70 70 71 72 76 76 77 78 55 59 64 64 66 69 70 71\n",
      "  68 71 70 73 75 75 78 76 55 58 59 63 67 68 70 71 68 70 71 72 76 77 77 77\n",
      "  56 58 61 63 62 67 71 71 69 71 71 73 75 76 75 78 58 59 62 68 67 70 69 74\n",
      "  69 71 73 73 77 78 77 78 50 52 55 58 60 63 65 67 67 66 68 69 73 73 75 76\n",
      "  29 34 37 41 46 51 52 55 54 56 59 61 65 66 68 70 35 39 44 46 52 54 58 60\n",
      "  58 60 62 64 68 70 71 72 58 61 63 66 67 69 71 72 68 72 73 72 77 77 77 82\n",
      "  60 62 64 66 69 71 73 73 74 71 72 75 77 78 78 80 55 59 59 63 64 67 67 70\n",
      "  69 74 71 73 76 79 78 78 27 32 40 41 48 49 53 53 55 57 58 61 64 67 68 70\n",
      "   0  0  6 12 21 25 30 34 35 41 42 49 52 49 56 58 21 26 34 35 40 44 50 48\n",
      "  52 55 59 58 62 64 66 68]]\n",
      "------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------\n",
      "rows4\n",
      "index: 0, value: 0\n",
      "index: 1, value: 1\n",
      "index: 2, value: 2\n",
      "index: 3, value: 3\n",
      "index: 4, value: 4\n",
      "index: 5, value: 5\n",
      "index: 6, value: 6\n",
      "index: 7, value: 7\n",
      "index: 8, value: 8\n",
      "index: 9, value: 9\n",
      "index: 10, value: 10\n",
      "index: 11, value: 11\n",
      "index: 12, value: 12\n",
      "index: 13, value: 13\n",
      "index: 14, value: 14\n",
      "index: 15, value: 15\n",
      "index: 16, value: 16\n",
      "index: 17, value: 17\n",
      "index: 18, value: 18\n",
      "index: 19, value: 19\n",
      "index: 20, value: 20\n",
      "index: 21, value: 21\n",
      "index: 22, value: 22\n",
      "index: 23, value: 23\n",
      "index: 24, value: 24\n",
      "index: 25, value: 25\n",
      "index: 26, value: 26\n",
      "index: 27, value: 27\n",
      "index: 28, value: 28\n",
      "index: 29, value: 29\n",
      "index: 30, value: 30\n",
      "index: 31, value: 31\n",
      "index: 32, value: 32\n",
      "index: 33, value: 33\n",
      "index: 34, value: 34\n",
      "index: 35, value: 35\n",
      "index: 36, value: 36\n",
      "index: 37, value: 37\n",
      "index: 38, value: 38\n",
      "index: 39, value: 39\n",
      "index: 40, value: 40\n",
      "index: 41, value: 41\n",
      "index: 42, value: 42\n",
      "index: 43, value: 43\n",
      "index: 44, value: 44\n",
      "index: 45, value: 45\n",
      "index: 46, value: 46\n",
      "index: 47, value: 47\n",
      "index: 48, value: 48\n",
      "index: 49, value: 49\n",
      "index: 50, value: 50\n",
      "index: 51, value: 51\n",
      "index: 52, value: 52\n",
      "index: 53, value: 53\n",
      "index: 54, value: 54\n",
      "index: 55, value: 55\n",
      "index: 56, value: 56\n",
      "index: 57, value: 57\n",
      "index: 58, value: 58\n",
      "index: 59, value: 59\n",
      "index: 60, value: 60\n",
      "index: 61, value: 61\n",
      "index: 62, value: 62\n",
      "index: 63, value: 63\n",
      "index: 64, value: 64\n",
      "index: 65, value: 65\n",
      "index: 66, value: 66\n",
      "index: 67, value: 67\n",
      "index: 68, value: 68\n",
      "index: 69, value: 69\n",
      "index: 70, value: 70\n",
      "index: 71, value: 71\n",
      "index: 72, value: 72\n",
      "index: 73, value: 73\n",
      "index: 74, value: 74\n",
      "index: 75, value: 75\n",
      "index: 76, value: 76\n",
      "index: 77, value: 77\n",
      "index: 78, value: 78\n",
      "index: 79, value: 79\n",
      "index: 80, value: 80\n",
      "index: 81, value: 81\n",
      "index: 82, value: 82\n",
      "index: 83, value: 83\n",
      "index: 84, value: 84\n",
      "index: 85, value: 85\n",
      "index: 86, value: 86\n",
      "index: 87, value: 87\n",
      "index: 88, value: 88\n",
      "index: 89, value: 89\n",
      "index: 90, value: 90\n",
      "index: 91, value: 91\n",
      "index: 92, value: 92\n",
      "index: 93, value: 93\n",
      "index: 94, value: 94\n",
      "index: 95, value: 95\n",
      "index: 96, value: 96\n",
      "index: 97, value: 97\n",
      "index: 98, value: 98\n",
      "index: 99, value: 99\n",
      "index: 100, value: 100\n",
      "index: 101, value: 101\n",
      "index: 102, value: 102\n",
      "index: 103, value: 103\n",
      "index: 104, value: 104\n",
      "index: 105, value: 105\n",
      "index: 106, value: 106\n",
      "index: 107, value: 107\n",
      "index: 108, value: 108\n",
      "index: 109, value: 109\n",
      "index: 110, value: 110\n",
      "index: 111, value: 111\n",
      "index: 112, value: 112\n",
      "index: 113, value: 113\n",
      "index: 114, value: 114\n",
      "index: 115, value: 115\n",
      "index: 116, value: 116\n",
      "index: 117, value: 117\n",
      "index: 118, value: 118\n",
      "index: 119, value: 119\n",
      "index: 120, value: 120\n",
      "index: 121, value: 121\n",
      "index: 122, value: 122\n",
      "index: 123, value: 123\n",
      "index: 124, value: 124\n",
      "index: 125, value: 125\n",
      "index: 126, value: 126\n",
      "index: 127, value: 127\n",
      "index: 128, value: 128\n",
      "index: 129, value: 129\n",
      "index: 130, value: 130\n",
      "index: 131, value: 131\n",
      "index: 132, value: 132\n",
      "index: 133, value: 133\n",
      "index: 134, value: 134\n",
      "index: 135, value: 135\n",
      "index: 136, value: 136\n",
      "index: 137, value: 137\n",
      "index: 138, value: 138\n",
      "index: 139, value: 139\n",
      "index: 140, value: 140\n",
      "index: 141, value: 141\n",
      "index: 142, value: 142\n",
      "index: 143, value: 143\n",
      "index: 144, value: 144\n",
      "index: 145, value: 145\n",
      "index: 146, value: 146\n",
      "index: 147, value: 147\n",
      "index: 148, value: 148\n",
      "index: 149, value: 149\n",
      "index: 150, value: 150\n",
      "index: 151, value: 151\n",
      "index: 152, value: 152\n",
      "index: 153, value: 153\n",
      "index: 154, value: 154\n",
      "index: 155, value: 155\n",
      "index: 156, value: 156\n",
      "index: 157, value: 157\n",
      "index: 158, value: 158\n",
      "index: 159, value: 159\n",
      "index: 160, value: 160\n",
      "index: 161, value: 161\n",
      "index: 162, value: 162\n",
      "index: 163, value: 163\n",
      "index: 164, value: 164\n",
      "index: 165, value: 165\n",
      "index: 166, value: 166\n",
      "index: 167, value: 167\n",
      "index: 168, value: 168\n",
      "index: 169, value: 169\n",
      "index: 170, value: 170\n",
      "index: 171, value: 171\n",
      "index: 172, value: 172\n",
      "index: 173, value: 173\n",
      "index: 174, value: 174\n",
      "index: 175, value: 175\n",
      "index: 176, value: 176\n",
      "index: 177, value: 177\n",
      "index: 178, value: 178\n",
      "index: 179, value: 179\n",
      "index: 180, value: 180\n",
      "index: 181, value: 181\n",
      "index: 182, value: 182\n",
      "index: 183, value: 183\n",
      "index: 184, value: 184\n",
      "index: 185, value: 185\n",
      "index: 186, value: 186\n",
      "index: 187, value: 187\n",
      "index: 188, value: 188\n",
      "index: 189, value: 189\n",
      "index: 190, value: 190\n",
      "index: 191, value: 191\n",
      "index: 192, value: 192\n",
      "index: 193, value: 193\n",
      "index: 194, value: 194\n",
      "index: 195, value: 195\n",
      "index: 196, value: 196\n",
      "index: 197, value: 197\n",
      "index: 198, value: 198\n",
      "index: 199, value: 199\n",
      "index: 200, value: 200\n",
      "index: 201, value: 201\n",
      "index: 202, value: 202\n",
      "index: 203, value: 203\n",
      "index: 204, value: 204\n",
      "index: 205, value: 205\n",
      "index: 206, value: 206\n",
      "index: 207, value: 207\n",
      "index: 208, value: 208\n",
      "index: 209, value: 209\n",
      "index: 210, value: 210\n",
      "index: 211, value: 211\n",
      "index: 212, value: 212\n",
      "index: 213, value: 213\n",
      "index: 214, value: 214\n",
      "index: 215, value: 215\n",
      "index: 216, value: 216\n",
      "index: 217, value: 217\n",
      "index: 218, value: 218\n",
      "index: 219, value: 219\n",
      "index: 220, value: 220\n",
      "index: 221, value: 221\n",
      "index: 222, value: 222\n",
      "index: 223, value: 223\n",
      "[ 91  93  85  90  95  93  86  91  87  87  87  86  88  87  90  87  70  73\n",
      "  69  71  76  76  77  78  74  75  76  78  79  80  78  81  65  64  68  67\n",
      "  72  71  74  73  73  70  72  74  77  77  78  78  13  19  24  29  35  37\n",
      "  41  47  44  48  51  55  58  59  59  62 102 100 102  97  99  99  97  96\n",
      "  92  91  89  89  91  91  90  88  76  78  76  77  79  80  81  81  79  81\n",
      "  80  81  81  83  82  80  70  71  72  72  76  76  77  77  74  74  71  76\n",
      "  81  79  80  80 167 163 157 151 149 145 139 136 130 127 122 120 120 120\n",
      " 115 117  36  40  44  47  50  53  58  57  57  59  61  63  67  69  71  69\n",
      "  50  56  55  57  62  64  64  67  64  67  68  65  71  75  73  75  50  52\n",
      "  52  56  62  64  65  66  65  66  69  68  73  73  73  74  43  49  50  54\n",
      "  57  58  61  64  61  65  67  66  69  70  71  74  79  75  73  77  80  81\n",
      "  76  82  80  79  81  82  85  84  84  83  79  79  79  81  82  82  83  85\n",
      "  81  81  81  83  86  87  87  85]\n",
      ",=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=\n",
      "xt3\n",
      "[[ 91]\n",
      " [ 93]\n",
      " [ 85]\n",
      " [ 90]\n",
      " [ 95]\n",
      " [ 93]\n",
      " [ 86]\n",
      " [ 91]\n",
      " [ 87]\n",
      " [ 87]\n",
      " [ 87]\n",
      " [ 86]\n",
      " [ 88]\n",
      " [ 87]\n",
      " [ 90]\n",
      " [ 87]\n",
      " [ 70]\n",
      " [ 73]\n",
      " [ 69]\n",
      " [ 71]\n",
      " [ 76]\n",
      " [ 76]\n",
      " [ 77]\n",
      " [ 78]\n",
      " [ 74]\n",
      " [ 75]\n",
      " [ 76]\n",
      " [ 78]\n",
      " [ 79]\n",
      " [ 80]\n",
      " [ 78]\n",
      " [ 81]\n",
      " [ 65]\n",
      " [ 64]\n",
      " [ 68]\n",
      " [ 67]\n",
      " [ 72]\n",
      " [ 71]\n",
      " [ 74]\n",
      " [ 73]\n",
      " [ 73]\n",
      " [ 70]\n",
      " [ 72]\n",
      " [ 74]\n",
      " [ 77]\n",
      " [ 77]\n",
      " [ 78]\n",
      " [ 78]\n",
      " [ 13]\n",
      " [ 19]\n",
      " [ 24]\n",
      " [ 29]\n",
      " [ 35]\n",
      " [ 37]\n",
      " [ 41]\n",
      " [ 47]\n",
      " [ 44]\n",
      " [ 48]\n",
      " [ 51]\n",
      " [ 55]\n",
      " [ 58]\n",
      " [ 59]\n",
      " [ 59]\n",
      " [ 62]\n",
      " [102]\n",
      " [100]\n",
      " [102]\n",
      " [ 97]\n",
      " [ 99]\n",
      " [ 99]\n",
      " [ 97]\n",
      " [ 96]\n",
      " [ 92]\n",
      " [ 91]\n",
      " [ 89]\n",
      " [ 89]\n",
      " [ 91]\n",
      " [ 91]\n",
      " [ 90]\n",
      " [ 88]\n",
      " [ 76]\n",
      " [ 78]\n",
      " [ 76]\n",
      " [ 77]\n",
      " [ 79]\n",
      " [ 80]\n",
      " [ 81]\n",
      " [ 81]\n",
      " [ 79]\n",
      " [ 81]\n",
      " [ 80]\n",
      " [ 81]\n",
      " [ 81]\n",
      " [ 83]\n",
      " [ 82]\n",
      " [ 80]\n",
      " [ 70]\n",
      " [ 71]\n",
      " [ 72]\n",
      " [ 72]\n",
      " [ 76]\n",
      " [ 76]\n",
      " [ 77]\n",
      " [ 77]\n",
      " [ 74]\n",
      " [ 74]\n",
      " [ 71]\n",
      " [ 76]\n",
      " [ 81]\n",
      " [ 79]\n",
      " [ 80]\n",
      " [ 80]\n",
      " [167]\n",
      " [163]\n",
      " [157]\n",
      " [151]\n",
      " [149]\n",
      " [145]\n",
      " [139]\n",
      " [136]\n",
      " [130]\n",
      " [127]\n",
      " [122]\n",
      " [120]\n",
      " [120]\n",
      " [120]\n",
      " [115]\n",
      " [117]\n",
      " [ 36]\n",
      " [ 40]\n",
      " [ 44]\n",
      " [ 47]\n",
      " [ 50]\n",
      " [ 53]\n",
      " [ 58]\n",
      " [ 57]\n",
      " [ 57]\n",
      " [ 59]\n",
      " [ 61]\n",
      " [ 63]\n",
      " [ 67]\n",
      " [ 69]\n",
      " [ 71]\n",
      " [ 69]\n",
      " [ 50]\n",
      " [ 56]\n",
      " [ 55]\n",
      " [ 57]\n",
      " [ 62]\n",
      " [ 64]\n",
      " [ 64]\n",
      " [ 67]\n",
      " [ 64]\n",
      " [ 67]\n",
      " [ 68]\n",
      " [ 65]\n",
      " [ 71]\n",
      " [ 75]\n",
      " [ 73]\n",
      " [ 75]\n",
      " [ 50]\n",
      " [ 52]\n",
      " [ 52]\n",
      " [ 56]\n",
      " [ 62]\n",
      " [ 64]\n",
      " [ 65]\n",
      " [ 66]\n",
      " [ 65]\n",
      " [ 66]\n",
      " [ 69]\n",
      " [ 68]\n",
      " [ 73]\n",
      " [ 73]\n",
      " [ 73]\n",
      " [ 74]\n",
      " [ 43]\n",
      " [ 49]\n",
      " [ 50]\n",
      " [ 54]\n",
      " [ 57]\n",
      " [ 58]\n",
      " [ 61]\n",
      " [ 64]\n",
      " [ 61]\n",
      " [ 65]\n",
      " [ 67]\n",
      " [ 66]\n",
      " [ 69]\n",
      " [ 70]\n",
      " [ 71]\n",
      " [ 74]\n",
      " [ 79]\n",
      " [ 75]\n",
      " [ 73]\n",
      " [ 77]\n",
      " [ 80]\n",
      " [ 81]\n",
      " [ 76]\n",
      " [ 82]\n",
      " [ 80]\n",
      " [ 79]\n",
      " [ 81]\n",
      " [ 82]\n",
      " [ 85]\n",
      " [ 84]\n",
      " [ 84]\n",
      " [ 83]\n",
      " [ 79]\n",
      " [ 79]\n",
      " [ 79]\n",
      " [ 81]\n",
      " [ 82]\n",
      " [ 82]\n",
      " [ 83]\n",
      " [ 85]\n",
      " [ 81]\n",
      " [ 81]\n",
      " [ 81]\n",
      " [ 83]\n",
      " [ 86]\n",
      " [ 87]\n",
      " [ 87]\n",
      " [ 85]]\n",
      "/./././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././.\n",
      "------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------\n",
      "[[103]\n",
      " [103]\n",
      " [103]\n",
      " [102]\n",
      " [103]\n",
      " [103]\n",
      " [ 99]\n",
      " [102]\n",
      " [ 96]\n",
      " [ 95]\n",
      " [ 93]\n",
      " [ 95]\n",
      " [ 96]\n",
      " [ 95]\n",
      " [ 94]\n",
      " [ 95]\n",
      " [ 80]\n",
      " [ 80]\n",
      " [ 80]\n",
      " [ 82]\n",
      " [ 84]\n",
      " [ 83]\n",
      " [ 84]\n",
      " [ 85]\n",
      " [ 81]\n",
      " [ 81]\n",
      " [ 81]\n",
      " [ 82]\n",
      " [ 87]\n",
      " [ 85]\n",
      " [ 84]\n",
      " [ 85]\n",
      " [ 76]\n",
      " [ 78]\n",
      " [ 78]\n",
      " [ 80]\n",
      " [ 80]\n",
      " [ 85]\n",
      " [ 83]\n",
      " [ 83]\n",
      " [ 80]\n",
      " [ 82]\n",
      " [ 81]\n",
      " [ 84]\n",
      " [ 84]\n",
      " [ 88]\n",
      " [ 85]\n",
      " [ 86]\n",
      " [ 66]\n",
      " [ 66]\n",
      " [ 68]\n",
      " [ 69]\n",
      " [ 74]\n",
      " [ 74]\n",
      " [ 75]\n",
      " [ 76]\n",
      " [ 75]\n",
      " [ 76]\n",
      " [ 77]\n",
      " [ 78]\n",
      " [ 82]\n",
      " [ 81]\n",
      " [ 83]\n",
      " [ 82]\n",
      " [ 65]\n",
      " [ 66]\n",
      " [ 68]\n",
      " [ 70]\n",
      " [ 73]\n",
      " [ 76]\n",
      " [ 73]\n",
      " [ 77]\n",
      " [ 73]\n",
      " [ 78]\n",
      " [ 76]\n",
      " [ 79]\n",
      " [ 80]\n",
      " [ 83]\n",
      " [ 81]\n",
      " [ 82]\n",
      " [ 51]\n",
      " [ 55]\n",
      " [ 58]\n",
      " [ 60]\n",
      " [ 66]\n",
      " [ 67]\n",
      " [ 67]\n",
      " [ 69]\n",
      " [ 68]\n",
      " [ 70]\n",
      " [ 74]\n",
      " [ 73]\n",
      " [ 78]\n",
      " [ 76]\n",
      " [ 78]\n",
      " [ 80]]\n",
      "0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [96, 224]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14/453034397.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0-0-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mett4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [96, 224]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "# 데이터셋 로드하기\n",
    "# [[your code]\n",
    "data = rows\n",
    "data2 = rows2\n",
    "data9 = rows9\n",
    "# 훈련용 데이터셋 나누기\n",
    "# [[your code]\n",
    "X_train = rows[:14]\n",
    "X_test = rows[14:]\n",
    "\n",
    "y_train = data9[:14]\n",
    "y_test = data9[14:]\n",
    "\n",
    "print(\"y_train\")\n",
    "print(y_train)\n",
    "print('-'*90)\n",
    "print('-'*90)\n",
    "print(\"X_train\")\n",
    "print(X_train)\n",
    "# y_test2 = data2[:16]\n",
    "# y_test2 = y_test2.reshape(16,4)\n",
    "# 훈련하기\n",
    "# [[your code]\n",
    "print('-/'*90)\n",
    "print('-/'*90)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "# X2, y2 = make_classification(n_samples=1000, n_features=4,\n",
    "#                              n_informative=2, n_redundant=0,\n",
    "#                              random_state=0, shuffle=False)\n",
    "# clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "# clf.fit(X2, y2)\n",
    "# print(X2)\n",
    "# print('-/'*90)\n",
    "# print('-/'*90)\n",
    "xtt = np.array(X_train)\n",
    "xt = xtt.reshape(-1,)\n",
    "ytt = np.array(y_train) #numpy array 로 바꿈!!\n",
    "yt = ytt.reshape(-1,) # numpy array 차원 축소!!! 1차원으로 만들어주기\n",
    "ett = np.array(y_test)\n",
    "ettt = ett.reshape(-1,)\n",
    "\n",
    "print(\"xt : X_train 에 해당\")\n",
    "print(xt)\n",
    "print('-'*90)\n",
    "print(\"yt: y_train 에 해당 \")\n",
    "print(yt)\n",
    "print('-'*90)\n",
    "print(\"ett : y_test 에 해당\")\n",
    "print(ettt)\n",
    "print('-'*90)\n",
    "\n",
    "xt = np.expand_dims(xt, axis=0) # 차원 확대\n",
    "yt = np.expand_dims(yt, axis=0) # 차원 확대 \n",
    "np.expand_dims(xt, axis=0)\n",
    "np.expand_dims(yt, axis=0)\n",
    "\n",
    "print(\"xt\")\n",
    "print(xt)\n",
    "print('-'*90)\n",
    "print(\"yt\")\n",
    "print(yt)\n",
    "print('-'*90)\n",
    "print('-*'*90)\n",
    "# clf = MultiOutputClassifier(KNeighborsClassifier()).fit(xt,yt) # 2차원 이상의 배열이 필요함...\n",
    "knn = KNeighborsClassifier(n_neighbors=1)#여기에서 n_neighbers =1 이 중요!!! 입력 데이터 형태를 보면 1로 해야함\n",
    "knn = MultiOutputClassifier(KNeighborsClassifier(n_neighbors=1)).fit(xt,yt) #2차원 필요\n",
    "print(\"knn 예측치\")\n",
    "knnmaster1 = knn.predict(xt[-2:]) #We select the training set with the [:-1] Python syntax,\n",
    "#which produces a new array that contains all but the last item from digits.data:\n",
    "print(knnmaster1)\n",
    "print('-*'*90)\n",
    "\n",
    "\n",
    "print(\"정답률=\", knn.score(y_pred2, xt)) ###########################\n",
    "\n",
    "\n",
    "print('-*'*90)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(xt, yt)\n",
    "print('-'*90)\n",
    "# 예측하기\n",
    "# [[your code]\n",
    "y_pred1 = model.predict(xt)\n",
    "# 정답률 출력하기\n",
    "# [[your code]\n",
    "print(y_pred1)\n",
    "print('-'*90)\n",
    "decision_tree = DecisionTreeClassifier(random_state=1)\n",
    "decision_tree.fit(xt, yt)\n",
    "y_pred2 = decision_tree.predict(xt)\n",
    "print(\"Decision Tree classifier 예측치\")\n",
    "print(y_pred2)\n",
    "print('-'*90)\n",
    "\n",
    "y_testt = np.transpose(y_test)\n",
    "print(y_test)\n",
    "print('-'*90)\n",
    "#y_test = np.expand_dims(y_test, axis=0)\n",
    "\n",
    "print('y_test')\n",
    "print(y_test)\n",
    "for idx, value in enumerate(y_test):\n",
    "    print(f'index: {idx}, value: {value}')\n",
    "\n",
    "print('-'*90)\n",
    "print('y_pred1')\n",
    "print(y_pred1)\n",
    "print('-'*90)\n",
    "print('-'*90)\n",
    "print('rows4')\n",
    "for idx, value in enumerate(rows4):\n",
    "    print(f'index: {idx}, value: {value}')\n",
    "    \n",
    "    \n",
    "#svm 은 y 가 1차원이어야 한다고 한다.\n",
    "\n",
    "yt2 = yt.reshape(-1,) # numpy array 차원 축소!!! 1차원으로 만들어주기\n",
    "xt2 = xt.reshape(-1,)\n",
    "xt3 = xt2.reshape(-1, 1)\n",
    "yt3 = yt2.reshape(-1, 1)\n",
    "                  \n",
    "ett2 = ett.reshape(-1,)\n",
    "ett3 = ett.reshape(-1, 1)\n",
    "print(xt2)\n",
    "print(',=,='*90)\n",
    "print(\"xt3\")\n",
    "print(xt3)\n",
    "print('/./.'*90)\n",
    "from sklearn import svm\n",
    "#먼저 y_pred 의 shape 은?\n",
    "# for i in y_pred1[1:]:\n",
    "#     rows4.append(list(map(int,i.split(\",\"))))\n",
    "# rows4 = pd.DataFrame(y_pred1)\n",
    "# rows6 = pd.DataFrame(y_pred2)\n",
    "# rows5 = pd.DataFrame(y_test)\n",
    "# rows7=[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "# print(rows4) #y예측치\n",
    "# print('-'*90)\n",
    "# print('rows5')\n",
    "# print(rows5) #y test\n",
    "clf = svm.SVC()\n",
    "print('-'*90)\n",
    "#roww1 = rows5.reshape(-1,) #dataframe 오류 \n",
    "#roww1 = y_test.reshape(-1,) # list 는 reshape 이 없다... np.array 로 바꿔주기\n",
    "# roww1 = np.array(y_test)\n",
    "# roww2 = roww1.reshape(-1,)\n",
    "# roww3 = pd.DataFrame(roww2)\n",
    "# roww4 = y_pred1.reshape(-1,)\n",
    "# print('roww2')\n",
    "# print(roww2)\n",
    "\n",
    "print('-'*90)\n",
    "print('-'*90)\n",
    "#print(\"정답률=\", clf.score(ett, yt3))\n",
    "print(ett3)\n",
    "ett4 =ett3.reshape(-1,)\n",
    "yt33 = yt3.reshape(-1,)\n",
    "xt33 = xt3.reshape(-1,)\n",
    "clf.fit(xt3,yt3)\n",
    "print('0-0-'*90)\n",
    "\n",
    "accuracy = accuracy_score(ett4, yt3)\n",
    "\n",
    "print(accuracy)\n",
    "# from sklearn.datasets import make_blobs\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# X,y = make_multilabel_classification(n_classes= 3,random_state = 0)\n",
    "\n",
    "# clf.predict(X[-2:])\n",
    "\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=3)\n",
    "# classifier = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "# classifier.fit(y_test,y_pred)\n",
    "# predictions = classifier.predict(y_train)\n",
    "# classifier.score(y_true,np.array(y_train))\n",
    "\n",
    "# from sklearn.linear_model import RidgeClassifierCV\n",
    "# clf = RidgeClassifierCV().fit(X_train, y_train)\n",
    "# y_score = clf.decision_function(X_train)\n",
    "# roc_auc_score(y_test, y_train, average=None)\n",
    "\n",
    "# from sklearn.datasets import make_multilabel_classification\n",
    "# from sklearn.multioutput import MultiOutputClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# X, y = make_multilabel_classification(random_state=0)\n",
    "# inner_clf = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "# clf = MultiOutputClassifier(inner_clf).fit(X, y)\n",
    "# y_score = np.transpose([y_pred[:, 1] for y_pred in clf.predict_proba(X)])\n",
    "# roc_auc_score(y, y_score, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6efc752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeClassifierCV\n",
    "# clf = RidgeClassifierCV().fit(X_train, y_train)\n",
    "\n",
    "# roc_auc_score(rows4, rows5, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c929bc",
   "metadata": {},
   "source": [
    "\n",
    "#열이 16개인 데이터셋\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6065627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
