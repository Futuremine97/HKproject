{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "52c119e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52,54,58,62,63,66,68,70,68,70,70,73,74,75,77,78,Mei\n",
      "65,68,66,68,71,74,74,76,72,74,74,75,76,77,80,80,조진호\n",
      "51,55,58,60,66,67,67,69,68,70,74,73,78,76,78,80,최주원\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "\n",
    "with open(\"mei.csv\", 'r', encoding=\"utf-8\") as read_: #read다음에_는 의미가 없다. read랑 헷갈리지말라고 쓴 것. a 라고 해도 무방.\n",
    "    text=read_.readlines()\n",
    "\n",
    "rows=[]\n",
    "for i in text[1:]:\n",
    "    rows.append(list(map(int,i.split(\",\")[:-1])))\n",
    "print(i)\n",
    "\n",
    "df=pd.DataFrame(rows)\n",
    "df.columns=[\"sensor%d\"%i for i in range(1,17)]\n",
    "\n",
    "with open(\"jo.csv\", 'r', encoding=\"utf-8\") as read_:\n",
    "    text2=read_.readlines()\n",
    "    \n",
    "\n",
    "rows2=[]\n",
    "for i in text2[1:]:\n",
    "    rows2.append(list(map(int,i.split(\",\")[:-1])))\n",
    "print(i)\n",
    "\n",
    "with open(\"joo.csv\", 'r', encoding=\"utf-8\") as read_:\n",
    "    text3=read_.readlines()\n",
    "    \n",
    "rows3=[]\n",
    "for i in text3[1:]:\n",
    "    rows3.append(list(map(int,i.split(\",\")[:-1])))\n",
    "print(i)\n",
    "\n",
    "df2=pd.DataFrame(rows2)\n",
    "df2.columns=[\"sensor%d\"%i for i in range(1,17)]\n",
    "\n",
    "\n",
    "df3=pd.DataFrame(rows3)\n",
    "df3.columns=[\"sensor%d\"%i for i in range(1,17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6167aa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 16)\n",
      "   sensor1  sensor2  sensor3  sensor4  sensor5  sensor6  sensor7  sensor8  \\\n",
      "0       91       93       85       90       95       93       86       91   \n",
      "1       70       73       69       71       76       76       77       78   \n",
      "2       65       64       68       67       72       71       74       73   \n",
      "3       13       19       24       29       35       37       41       47   \n",
      "4      102      100      102       97       99       99       97       96   \n",
      "\n",
      "   sensor9  sensor10  sensor11  sensor12  sensor13  sensor14  sensor15  \\\n",
      "0       87        87        87        86        88        87        90   \n",
      "1       74        75        76        78        79        80        78   \n",
      "2       73        70        72        74        77        77        78   \n",
      "3       44        48        51        55        58        59        59   \n",
      "4       92        91        89        89        91        91        90   \n",
      "\n",
      "   sensor16  \n",
      "0        87  \n",
      "1        81  \n",
      "2        78  \n",
      "3        62  \n",
      "4        88  \n",
      "(20, 16)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import seaborn;\n",
    "seaborn.set()\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "image1 = df.astype('float')\n",
    "image2 = df2.astype('float')\n",
    "\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "y2 = ['sensor1']\n",
    "y1 = ['sensor1','sensor2','sensor3','sensor4','sensor5','sensor6','sensor7','sensor8','sensor9','sensor10','sensor11','sensor12','sensor13','sensor14','sensor15','sensor16'] # define y variable, i.e., what we want to predict\n",
    "print(df.shape) # print the number of rows anc columns\n",
    "\n",
    "print(df.head())\n",
    "print(df2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3c54714b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96, 94, 92, 92, 93, 93, 95, 92, 90, 89, 89, 88, 89, 92, 91, 90], [92, 92, 92, 91, 93, 94, 91, 95, 87, 88, 86, 86, 88, 90, 87, 88], [112, 110, 107, 106, 107, 104, 102, 102, 99, 96, 96, 95, 88, 94, 97, 93], [93, 91, 90, 91, 93, 92, 91, 91, 87, 87, 88, 89, 87, 87, 87, 88], [93, 93, 90, 91, 92, 93, 93, 91, 87, 87, 87, 87, 90, 88, 89, 88], [92, 93, 92, 90, 94, 92, 91, 92, 87, 88, 84, 86, 87, 87, 85, 88], [91, 91, 88, 91, 89, 92, 89, 89, 85, 86, 85, 87, 87, 86, 85, 86], [89, 89, 89, 88, 90, 91, 88, 87, 86, 85, 84, 83, 86, 87, 87, 85], [89, 87, 86, 86, 87, 90, 87, 89, 82, 86, 83, 84, 84, 79, 84, 85], [91, 90, 90, 90, 94, 90, 88, 89, 87, 85, 85, 86, 86, 87, 85, 89], [95, 94, 92, 92, 94, 92, 91, 92, 88, 87, 87, 86, 89, 87, 85, 87], [69, 69, 73, 73, 75, 76, 76, 76, 73, 74, 74, 76, 78, 79, 79, 81], [92, 91, 91, 90, 91, 90, 88, 89, 83, 85, 85, 85, 84, 85, 85, 84], [77, 77, 77, 80, 78, 79, 79, 81, 77, 78, 77, 79, 79, 80, 79, 81], [74, 74, 76, 75, 77, 76, 78, 77, 79, 76, 76, 81, 79, 74, 79, 80], [74, 74, 75, 79, 76, 81, 78, 80, 76, 75, 79, 75, 82, 79, 74, 79]]\n",
      "------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------\n",
      "[[91, 93, 85, 90, 95, 93, 86, 91, 87, 87, 87, 86, 88, 87, 90, 87], [70, 73, 69, 71, 76, 76, 77, 78, 74, 75, 76, 78, 79, 80, 78, 81], [65, 64, 68, 67, 72, 71, 74, 73, 73, 70, 72, 74, 77, 77, 78, 78], [13, 19, 24, 29, 35, 37, 41, 47, 44, 48, 51, 55, 58, 59, 59, 62], [102, 100, 102, 97, 99, 99, 97, 96, 92, 91, 89, 89, 91, 91, 90, 88], [76, 78, 76, 77, 79, 80, 81, 81, 79, 81, 80, 81, 81, 83, 82, 80], [70, 71, 72, 72, 76, 76, 77, 77, 74, 74, 71, 76, 81, 79, 80, 80], [167, 163, 157, 151, 149, 145, 139, 136, 130, 127, 122, 120, 120, 120, 115, 117], [36, 40, 44, 47, 50, 53, 58, 57, 57, 59, 61, 63, 67, 69, 71, 69], [50, 56, 55, 57, 62, 64, 64, 67, 64, 67, 68, 65, 71, 75, 73, 75], [50, 52, 52, 56, 62, 64, 65, 66, 65, 66, 69, 68, 73, 73, 73, 74], [43, 49, 50, 54, 57, 58, 61, 64, 61, 65, 67, 66, 69, 70, 71, 74], [79, 75, 73, 77, 80, 81, 76, 82, 80, 79, 81, 82, 85, 84, 84, 83], [79, 79, 79, 81, 82, 82, 83, 85, 81, 81, 81, 83, 86, 87, 87, 85], [88, 88, 90, 92, 91, 91, 89, 92, 87, 88, 87, 88, 89, 90, 89, 90], [63, 63, 68, 68, 70, 71, 76, 75, 74, 74, 75, 75, 78, 78, 79, 80]]\n",
      "------------------------------------------------------------------------------------------\n",
      "[[ 74  74  75  79  76  81  78  80  76  75  79  75  82  79  74  79]\n",
      " [ 74  74  75  79  76  81  78  80  76  75  79  75  88  79  74  79]\n",
      " [112 110 107 106 107 104 102 102  99  96  96  95  88  94  97  93]\n",
      " [ 91  90  90  90  94  90  88  89  87  85  85  86  86  87  85  89]]\n",
      "------------------------------------------------------------------------------------------\n",
      "[[74 74 75 79 76 81 78 80 76 75 79 75 82 79 74 79]\n",
      " [74 74 75 79 76 81 78 80 76 75 79 75 82 79 74 79]\n",
      " [74 74 75 79 76 81 78 80 76 75 79 75 82 79 74 79]\n",
      " [95 94 92 92 94 92 91 92 88 87 87 86 89 87 85 87]]\n",
      "------------------------------------------------------------------------------------------\n",
      "[[60, 62, 63, 66, 67, 69, 72, 76, 71, 73, 74, 79, 78, 79, 79, 83], [60, 62, 67, 66, 73, 69, 73, 72, 74, 73, 76, 75, 74, 79, 80, 80], [59, 60, 64, 66, 70, 70, 71, 73, 71, 73, 72, 75, 77, 82, 78, 74], [52, 54, 58, 62, 63, 66, 68, 70, 68, 70, 70, 73, 74, 75, 77, 78]]\n",
      "------------------------------------------------------------------------------------------\n",
      "[0 0 1 0 1 2 1 0 1 0 1 0 0 2 1 0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0 0 1 0 1 2 1 0 1 0 1 0 0 2 1 0].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"/opt/conda/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/opt/conda/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 209, in __call__\n    return self.function(*args, **kwargs)\n  File \"/opt/conda/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 214, in predict\n    X = self._validate_data(X, accept_sparse=\"csr\", reset=False)\n  File \"/opt/conda/lib/python3.9/site-packages/sklearn/base.py\", line 557, in _validate_data\n    X = check_array(X, **check_params)\n  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 761, in check_array\n    raise ValueError(\nValueError: Expected 2D array, got 1D array instead:\narray=[0 0 1 0 1 2 1 0 1 0 1 0 0 2 1 0].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67/1482249410.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    503\u001b[0m                 \u001b[0;34m\" score {1} should be same\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             )\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The base estimator should implement a predict method\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         y = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    443\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0 0 1 0 1 2 1 0 1 0 1 0 0 2 1 0].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# 데이터셋 로드하기\n",
    "# [[your code]\n",
    "data = rows\n",
    "data2 = rows2\n",
    "# 훈련용 데이터셋 나누기\n",
    "# [[your code]\n",
    "X_train = data[:16]\n",
    "X_test = data[16:]\n",
    "\n",
    "y_train = data2[:16]\n",
    "y_test = data[16:]\n",
    "\n",
    "print(y_train)\n",
    "print('-'*90)\n",
    "print('-'*90)\n",
    "print(X_train)\n",
    "# y_test2 = data2[:16]\n",
    "# y_test2 = y_test2.reshape(16,4)\n",
    "# 훈련하기\n",
    "# [[your code]\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print('-'*90)\n",
    "# 예측하기\n",
    "# [[your code]\n",
    "y_pred = model.predict(X_test)\n",
    "# 정답률 출력하기\n",
    "# [[your code]\n",
    "print(y_pred)\n",
    "print('-'*90)\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "print(y_pred)\n",
    "print('-'*90)\n",
    "y_true = np.argmax(y_test, axis=0)\n",
    "\n",
    "print(y_test)\n",
    "print('-'*90)\n",
    "print(y_true)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "classifier.fit(y_test,y_pred)\n",
    "predictions = classifier.predict(y_train)\n",
    "classifier.score(y_true,np.array(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92067953",
   "metadata": {},
   "source": [
    "\n",
    "#열이 16개인 데이터셋\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e5b788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
