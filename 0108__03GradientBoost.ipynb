{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d481098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52,54,58,62,63,66,68,70,68,70,70,73,74,75,77,78,Mei\n",
      "65,68,66,68,71,74,74,76,72,74,74,75,76,77,80,80,조진호\n",
      "51,55,58,60,66,67,67,69,68,70,74,73,78,76,78,80,최주원\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "\n",
    "with open(\"mei.csv\", 'r', encoding=\"utf-8\") as read_: #read다음에_는 의미가 없다. read랑 헷갈리지말라고 쓴 것. a 라고 해도 무방.\n",
    "    text=read_.readlines()\n",
    "\n",
    "rows=[]\n",
    "for i in text[1:]:\n",
    "    rows.append(list(map(int,i.split(\",\")[:-1])))\n",
    "print(i)\n",
    "\n",
    "df=pd.DataFrame(rows)\n",
    "df.columns=[\"sensor%d\"%i for i in range(1,17)]\n",
    "\n",
    "with open(\"jo.csv\", 'r', encoding=\"utf-8\") as read_:\n",
    "    text2=read_.readlines()\n",
    "    \n",
    "\n",
    "rows2=[]\n",
    "for i in text2[1:]:\n",
    "    rows2.append(list(map(int,i.split(\",\")[:-1])))\n",
    "print(i)\n",
    "\n",
    "with open(\"joo.csv\", 'r', encoding=\"utf-8\") as read_:\n",
    "    text3=read_.readlines()\n",
    "    \n",
    "rows9=[]\n",
    "for i in text3[1:]:\n",
    "    rows9.append(list(map(int,i.split(\",\")[:-1])))\n",
    "print(i)\n",
    "\n",
    "df2=pd.DataFrame(rows2)\n",
    "df2.columns=[\"sensor%d\"%i for i in range(1,17)]\n",
    "\n",
    "\n",
    "df3=pd.DataFrame(rows9)\n",
    "df3.columns=[\"sensor%d\"%i for i in range(1,17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2c8a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 16)\n",
      "   sensor1  sensor2  sensor3  sensor4  sensor5  sensor6  sensor7  sensor8  \\\n",
      "0       91       93       85       90       95       93       86       91   \n",
      "1       70       73       69       71       76       76       77       78   \n",
      "2       65       64       68       67       72       71       74       73   \n",
      "3       13       19       24       29       35       37       41       47   \n",
      "4      102      100      102       97       99       99       97       96   \n",
      "\n",
      "   sensor9  sensor10  sensor11  sensor12  sensor13  sensor14  sensor15  \\\n",
      "0       87        87        87        86        88        87        90   \n",
      "1       74        75        76        78        79        80        78   \n",
      "2       73        70        72        74        77        77        78   \n",
      "3       44        48        51        55        58        59        59   \n",
      "4       92        91        89        89        91        91        90   \n",
      "\n",
      "   sensor16  \n",
      "0        87  \n",
      "1        81  \n",
      "2        78  \n",
      "3        62  \n",
      "4        88  \n",
      "(20, 16)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import seaborn;\n",
    "seaborn.set()\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "image1 = df.astype('float')\n",
    "image2 = df2.astype('float')\n",
    "\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "y2 = ['sensor1']\n",
    "y1 = ['sensor1','sensor2','sensor3','sensor4','sensor5','sensor6','sensor7','sensor8','sensor9','sensor10','sensor11','sensor12','sensor13','sensor14','sensor15','sensor16'] # define y variable, i.e., what we want to predict\n",
    "print(df.shape) # print the number of rows anc columns\n",
    "\n",
    "print(df.head())\n",
    "print(df2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "77e0f687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train\n",
      "[[58, 59, 60, 63, 66, 69, 70, 70, 70, 70, 71, 72, 76, 76, 77, 78], [55, 59, 64, 64, 66, 69, 70, 71, 68, 71, 70, 73, 75, 75, 78, 76], [55, 58, 59, 63, 67, 68, 70, 71, 68, 70, 71, 72, 76, 77, 77, 77], [56, 58, 61, 63, 62, 67, 71, 71, 69, 71, 71, 73, 75, 76, 75, 78], [58, 59, 62, 68, 67, 70, 69, 74, 69, 71, 73, 73, 77, 78, 77, 78], [50, 52, 55, 58, 60, 63, 65, 67, 67, 66, 68, 69, 73, 73, 75, 76], [29, 34, 37, 41, 46, 51, 52, 55, 54, 56, 59, 61, 65, 66, 68, 70], [35, 39, 44, 46, 52, 54, 58, 60, 58, 60, 62, 64, 68, 70, 71, 72], [58, 61, 63, 66, 67, 69, 71, 72, 68, 72, 73, 72, 77, 77, 77, 82], [60, 62, 64, 66, 69, 71, 73, 73, 74, 71, 72, 75, 77, 78, 78, 80], [55, 59, 59, 63, 64, 67, 67, 70, 69, 74, 71, 73, 76, 79, 78, 78], [27, 32, 40, 41, 48, 49, 53, 53, 55, 57, 58, 61, 64, 67, 68, 70], [0, 0, 6, 12, 21, 25, 30, 34, 35, 41, 42, 49, 52, 49, 56, 58], [21, 26, 34, 35, 40, 44, 50, 48, 52, 55, 59, 58, 62, 64, 66, 68]]\n",
      "------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------\n",
      "X_train\n",
      "[[91, 93, 85, 90, 95, 93, 86, 91, 87, 87, 87, 86, 88, 87, 90, 87], [70, 73, 69, 71, 76, 76, 77, 78, 74, 75, 76, 78, 79, 80, 78, 81], [65, 64, 68, 67, 72, 71, 74, 73, 73, 70, 72, 74, 77, 77, 78, 78], [13, 19, 24, 29, 35, 37, 41, 47, 44, 48, 51, 55, 58, 59, 59, 62], [102, 100, 102, 97, 99, 99, 97, 96, 92, 91, 89, 89, 91, 91, 90, 88], [76, 78, 76, 77, 79, 80, 81, 81, 79, 81, 80, 81, 81, 83, 82, 80], [70, 71, 72, 72, 76, 76, 77, 77, 74, 74, 71, 76, 81, 79, 80, 80], [167, 163, 157, 151, 149, 145, 139, 136, 130, 127, 122, 120, 120, 120, 115, 117], [36, 40, 44, 47, 50, 53, 58, 57, 57, 59, 61, 63, 67, 69, 71, 69], [50, 56, 55, 57, 62, 64, 64, 67, 64, 67, 68, 65, 71, 75, 73, 75], [50, 52, 52, 56, 62, 64, 65, 66, 65, 66, 69, 68, 73, 73, 73, 74], [43, 49, 50, 54, 57, 58, 61, 64, 61, 65, 67, 66, 69, 70, 71, 74], [79, 75, 73, 77, 80, 81, 76, 82, 80, 79, 81, 82, 85, 84, 84, 83], [79, 79, 79, 81, 82, 82, 83, 85, 81, 81, 81, 83, 86, 87, 87, 85]]\n",
      "-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/\n",
      "-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "# 데이터셋 로드하기\n",
    "# [[your code]\n",
    "data = rows\n",
    "data2 = rows2\n",
    "data9 = rows9\n",
    "# 훈련용 데이터셋 나누기\n",
    "# [[your code]\n",
    "X_train = rows[:14]\n",
    "X_test = rows[14:]\n",
    "\n",
    "y_train = data9[:14]\n",
    "y_test = data9[14:]\n",
    "\n",
    "print(\"y_train\")\n",
    "print(y_train)\n",
    "print('-'*90)\n",
    "print('-'*90)\n",
    "print(\"X_train\")\n",
    "print(X_train)\n",
    "# y_test2 = data2[:16]\n",
    "# y_test2 = y_test2.reshape(16,4)\n",
    "# 훈련하기\n",
    "# [[your code]\n",
    "print('-/'*90)\n",
    "print('-/'*90)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67286662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeClassifierCV\n",
    "# clf = RidgeClassifierCV().fit(X_train, y_train)\n",
    "\n",
    "# roc_auc_score(rows4, rows5, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9444fe4b",
   "metadata": {},
   "source": [
    "\n",
    "#열이 16개인 데이터셋\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d0623165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train\n",
      "[[58, 59, 60, 63, 66, 69, 70, 70, 70, 70, 71, 72, 76, 76, 77, 78], [55, 59, 64, 64, 66, 69, 70, 71, 68, 71, 70, 73, 75, 75, 78, 76], [55, 58, 59, 63, 67, 68, 70, 71, 68, 70, 71, 72, 76, 77, 77, 77], [56, 58, 61, 63, 62, 67, 71, 71, 69, 71, 71, 73, 75, 76, 75, 78], [58, 59, 62, 68, 67, 70, 69, 74, 69, 71, 73, 73, 77, 78, 77, 78], [50, 52, 55, 58, 60, 63, 65, 67, 67, 66, 68, 69, 73, 73, 75, 76], [29, 34, 37, 41, 46, 51, 52, 55, 54, 56, 59, 61, 65, 66, 68, 70], [35, 39, 44, 46, 52, 54, 58, 60, 58, 60, 62, 64, 68, 70, 71, 72], [58, 61, 63, 66, 67, 69, 71, 72, 68, 72, 73, 72, 77, 77, 77, 82], [60, 62, 64, 66, 69, 71, 73, 73, 74, 71, 72, 75, 77, 78, 78, 80], [55, 59, 59, 63, 64, 67, 67, 70, 69, 74, 71, 73, 76, 79, 78, 78], [27, 32, 40, 41, 48, 49, 53, 53, 55, 57, 58, 61, 64, 67, 68, 70], [0, 0, 6, 12, 21, 25, 30, 34, 35, 41, 42, 49, 52, 49, 56, 58], [21, 26, 34, 35, 40, 44, 50, 48, 52, 55, 59, 58, 62, 64, 66, 68]]\n",
      "------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------\n",
      "X_train\n",
      "[[91, 93, 85, 90, 95, 93, 86, 91, 87, 87, 87, 86, 88, 87, 90, 87], [70, 73, 69, 71, 76, 76, 77, 78, 74, 75, 76, 78, 79, 80, 78, 81], [65, 64, 68, 67, 72, 71, 74, 73, 73, 70, 72, 74, 77, 77, 78, 78], [13, 19, 24, 29, 35, 37, 41, 47, 44, 48, 51, 55, 58, 59, 59, 62], [102, 100, 102, 97, 99, 99, 97, 96, 92, 91, 89, 89, 91, 91, 90, 88], [76, 78, 76, 77, 79, 80, 81, 81, 79, 81, 80, 81, 81, 83, 82, 80], [70, 71, 72, 72, 76, 76, 77, 77, 74, 74, 71, 76, 81, 79, 80, 80], [167, 163, 157, 151, 149, 145, 139, 136, 130, 127, 122, 120, 120, 120, 115, 117], [36, 40, 44, 47, 50, 53, 58, 57, 57, 59, 61, 63, 67, 69, 71, 69], [50, 56, 55, 57, 62, 64, 64, 67, 64, 67, 68, 65, 71, 75, 73, 75], [50, 52, 52, 56, 62, 64, 65, 66, 65, 66, 69, 68, 73, 73, 73, 74], [43, 49, 50, 54, 57, 58, 61, 64, 61, 65, 67, 66, 69, 70, 71, 74], [79, 75, 73, 77, 80, 81, 76, 82, 80, 79, 81, 82, 85, 84, 84, 83], [79, 79, 79, 81, 82, 82, 83, 85, 81, 81, 81, 83, 86, 87, 87, 85]]\n",
      "-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/\n",
      "-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/\n",
      "xt : X_train 에 해당\n",
      "[ 91  93  85  90  95  93  86  91  87  87  87  86  88  87  90  87  70  73\n",
      "  69  71  76  76  77  78  74  75  76  78  79  80  78  81  65  64  68  67\n",
      "  72  71  74  73  73  70  72  74  77  77  78  78  13  19  24  29  35  37\n",
      "  41  47  44  48  51  55  58  59  59  62 102 100 102  97  99  99  97  96\n",
      "  92  91  89  89  91  91  90  88  76  78  76  77  79  80  81  81  79  81\n",
      "  80  81  81  83  82  80  70  71  72  72  76  76  77  77  74  74  71  76\n",
      "  81  79  80  80 167 163 157 151 149 145 139 136 130 127 122 120 120 120\n",
      " 115 117  36  40  44  47  50  53  58  57  57  59  61  63  67  69  71  69\n",
      "  50  56  55  57  62  64  64  67  64  67  68  65  71  75  73  75  50  52\n",
      "  52  56  62  64  65  66  65  66  69  68  73  73  73  74  43  49  50  54\n",
      "  57  58  61  64  61  65  67  66  69  70  71  74  79  75  73  77  80  81\n",
      "  76  82  80  79  81  82  85  84  84  83  79  79  79  81  82  82  83  85\n",
      "  81  81  81  83  86  87  87  85]\n",
      "------------------------------------------------------------------------------------------\n",
      "yt: y_train 에 해당 \n",
      "[58 59 60 63 66 69 70 70 70 70 71 72 76 76 77 78 55 59 64 64 66 69 70 71\n",
      " 68 71 70 73 75 75 78 76 55 58 59 63 67 68 70 71 68 70 71 72 76 77 77 77\n",
      " 56 58 61 63 62 67 71 71 69 71 71 73 75 76 75 78 58 59 62 68 67 70 69 74\n",
      " 69 71 73 73 77 78 77 78 50 52 55 58 60 63 65 67 67 66 68 69 73 73 75 76\n",
      " 29 34 37 41 46 51 52 55 54 56 59 61 65 66 68 70 35 39 44 46 52 54 58 60\n",
      " 58 60 62 64 68 70 71 72 58 61 63 66 67 69 71 72 68 72 73 72 77 77 77 82\n",
      " 60 62 64 66 69 71 73 73 74 71 72 75 77 78 78 80 55 59 59 63 64 67 67 70\n",
      " 69 74 71 73 76 79 78 78 27 32 40 41 48 49 53 53 55 57 58 61 64 67 68 70\n",
      "  0  0  6 12 21 25 30 34 35 41 42 49 52 49 56 58 21 26 34 35 40 44 50 48\n",
      " 52 55 59 58 62 64 66 68]\n",
      "------------------------------------------------------------------------------------------\n",
      "ett : y_test 에 해당\n",
      "[103 103 103 102 103 103  99 102  96  95  93  95  96  95  94  95  80  80\n",
      "  80  82  84  83  84  85  81  81  81  82  87  85  84  85  76  78  78  80\n",
      "  80  85  83  83  80  82  81  84  84  88  85  86  66  66  68  69  74  74\n",
      "  75  76  75  76  77  78  82  81  83  82  65  66  68  70  73  76  73  77\n",
      "  73  78  76  79  80  83  81  82  51  55  58  60  66  67  67  69  68  70\n",
      "  74  73  78  76  78  80]\n",
      "------------------------------------------------------------------------------------------\n",
      "xt\n",
      "[[ 91  93  85  90  95  93  86  91  87  87  87  86  88  87  90  87  70  73\n",
      "   69  71  76  76  77  78  74  75  76  78  79  80  78  81  65  64  68  67\n",
      "   72  71  74  73  73  70  72  74  77  77  78  78  13  19  24  29  35  37\n",
      "   41  47  44  48  51  55  58  59  59  62 102 100 102  97  99  99  97  96\n",
      "   92  91  89  89  91  91  90  88  76  78  76  77  79  80  81  81  79  81\n",
      "   80  81  81  83  82  80  70  71  72  72  76  76  77  77  74  74  71  76\n",
      "   81  79  80  80 167 163 157 151 149 145 139 136 130 127 122 120 120 120\n",
      "  115 117  36  40  44  47  50  53  58  57  57  59  61  63  67  69  71  69\n",
      "   50  56  55  57  62  64  64  67  64  67  68  65  71  75  73  75  50  52\n",
      "   52  56  62  64  65  66  65  66  69  68  73  73  73  74  43  49  50  54\n",
      "   57  58  61  64  61  65  67  66  69  70  71  74  79  75  73  77  80  81\n",
      "   76  82  80  79  81  82  85  84  84  83  79  79  79  81  82  82  83  85\n",
      "   81  81  81  83  86  87  87  85]]\n",
      "------------------------------------------------------------------------------------------\n",
      "yt\n",
      "[[58 59 60 63 66 69 70 70 70 70 71 72 76 76 77 78 55 59 64 64 66 69 70 71\n",
      "  68 71 70 73 75 75 78 76 55 58 59 63 67 68 70 71 68 70 71 72 76 77 77 77\n",
      "  56 58 61 63 62 67 71 71 69 71 71 73 75 76 75 78 58 59 62 68 67 70 69 74\n",
      "  69 71 73 73 77 78 77 78 50 52 55 58 60 63 65 67 67 66 68 69 73 73 75 76\n",
      "  29 34 37 41 46 51 52 55 54 56 59 61 65 66 68 70 35 39 44 46 52 54 58 60\n",
      "  58 60 62 64 68 70 71 72 58 61 63 66 67 69 71 72 68 72 73 72 77 77 77 82\n",
      "  60 62 64 66 69 71 73 73 74 71 72 75 77 78 78 80 55 59 59 63 64 67 67 70\n",
      "  69 74 71 73 76 79 78 78 27 32 40 41 48 49 53 53 55 57 58 61 64 67 68 70\n",
      "   0  0  6 12 21 25 30 34 35 41 42 49 52 49 56 58 21 26 34 35 40 44 50 48\n",
      "  52 55 59 58 62 64 66 68]]\n",
      "------------------------------------------------------------------------------------------\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "knn 예측치\n",
      "knmaster1\n",
      "[[58 59 60 63 66 69 70 70 70 70 71 72 76 76 77 78 55 59 64 64 66 69 70 71\n",
      "  68 71 70 73 75 75 78 76 55 58 59 63 67 68 70 71 68 70 71 72 76 77 77 77\n",
      "  56 58 61 63 62 67 71 71 69 71 71 73 75 76 75 78 58 59 62 68 67 70 69 74\n",
      "  69 71 73 73 77 78 77 78 50 52 55 58 60 63 65 67 67 66 68 69 73 73 75 76\n",
      "  29 34 37 41 46 51 52 55 54 56 59 61 65 66 68 70 35 39 44 46 52 54 58 60\n",
      "  58 60 62 64 68 70 71 72 58 61 63 66 67 69 71 72 68 72 73 72 77 77 77 82\n",
      "  60 62 64 66 69 71 73 73 74 71 72 75 77 78 78 80 55 59 59 63 64 67 67 70\n",
      "  69 74 71 73 76 79 78 78 27 32 40 41 48 49 53 53 55 57 58 61 64 67 68 70\n",
      "   0  0  6 12 21 25 30 34 35 41 42 49 52 49 56 58 21 26 34 35 40 44 50 48\n",
      "  52 55 59 58 62 64 66 68]]\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "정답률= 0.0\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "------------------------------------------------------------------------------------------\n",
      "[[58 59 60 63 66 69 70 70 70 70 71 72 76 76 77 78 55 59 64 64 66 69 70 71\n",
      "  68 71 70 73 75 75 78 76 55 58 59 63 67 68 70 71 68 70 71 72 76 77 77 77\n",
      "  56 58 61 63 62 67 71 71 69 71 71 73 75 76 75 78 58 59 62 68 67 70 69 74\n",
      "  69 71 73 73 77 78 77 78 50 52 55 58 60 63 65 67 67 66 68 69 73 73 75 76\n",
      "  29 34 37 41 46 51 52 55 54 56 59 61 65 66 68 70 35 39 44 46 52 54 58 60\n",
      "  58 60 62 64 68 70 71 72 58 61 63 66 67 69 71 72 68 72 73 72 77 77 77 82\n",
      "  60 62 64 66 69 71 73 73 74 71 72 75 77 78 78 80 55 59 59 63 64 67 67 70\n",
      "  69 74 71 73 76 79 78 78 27 32 40 41 48 49 53 53 55 57 58 61 64 67 68 70\n",
      "   0  0  6 12 21 25 30 34 35 41 42 49 52 49 56 58 21 26 34 35 40 44 50 48\n",
      "  52 55 59 58 62 64 66 68]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Decision Tree classifier 예측치\n",
      "[[58 59 60 63 66 69 70 70 70 70 71 72 76 76 77 78 55 59 64 64 66 69 70 71\n",
      "  68 71 70 73 75 75 78 76 55 58 59 63 67 68 70 71 68 70 71 72 76 77 77 77\n",
      "  56 58 61 63 62 67 71 71 69 71 71 73 75 76 75 78 58 59 62 68 67 70 69 74\n",
      "  69 71 73 73 77 78 77 78 50 52 55 58 60 63 65 67 67 66 68 69 73 73 75 76\n",
      "  29 34 37 41 46 51 52 55 54 56 59 61 65 66 68 70 35 39 44 46 52 54 58 60\n",
      "  58 60 62 64 68 70 71 72 58 61 63 66 67 69 71 72 68 72 73 72 77 77 77 82\n",
      "  60 62 64 66 69 71 73 73 74 71 72 75 77 78 78 80 55 59 59 63 64 67 67 70\n",
      "  69 74 71 73 76 79 78 78 27 32 40 41 48 49 53 53 55 57 58 61 64 67 68 70\n",
      "   0  0  6 12 21 25 30 34 35 41 42 49 52 49 56 58 21 26 34 35 40 44 50 48\n",
      "  52 55 59 58 62 64 66 68]]\n",
      "------------------------------------------------------------------------------------------\n",
      "[[103, 103, 103, 102, 103, 103, 99, 102, 96, 95, 93, 95, 96, 95, 94, 95], [80, 80, 80, 82, 84, 83, 84, 85, 81, 81, 81, 82, 87, 85, 84, 85], [76, 78, 78, 80, 80, 85, 83, 83, 80, 82, 81, 84, 84, 88, 85, 86], [66, 66, 68, 69, 74, 74, 75, 76, 75, 76, 77, 78, 82, 81, 83, 82], [65, 66, 68, 70, 73, 76, 73, 77, 73, 78, 76, 79, 80, 83, 81, 82], [51, 55, 58, 60, 66, 67, 67, 69, 68, 70, 74, 73, 78, 76, 78, 80]]\n",
      "------------------------------------------------------------------------------------------\n",
      "y_test\n",
      "[[103, 103, 103, 102, 103, 103, 99, 102, 96, 95, 93, 95, 96, 95, 94, 95], [80, 80, 80, 82, 84, 83, 84, 85, 81, 81, 81, 82, 87, 85, 84, 85], [76, 78, 78, 80, 80, 85, 83, 83, 80, 82, 81, 84, 84, 88, 85, 86], [66, 66, 68, 69, 74, 74, 75, 76, 75, 76, 77, 78, 82, 81, 83, 82], [65, 66, 68, 70, 73, 76, 73, 77, 73, 78, 76, 79, 80, 83, 81, 82], [51, 55, 58, 60, 66, 67, 67, 69, 68, 70, 74, 73, 78, 76, 78, 80]]\n",
      "------------------------------------------------------------------------------------------\n",
      "y_pred1\n",
      "[[58 59 60 63 66 69 70 70 70 70 71 72 76 76 77 78 55 59 64 64 66 69 70 71\n",
      "  68 71 70 73 75 75 78 76 55 58 59 63 67 68 70 71 68 70 71 72 76 77 77 77\n",
      "  56 58 61 63 62 67 71 71 69 71 71 73 75 76 75 78 58 59 62 68 67 70 69 74\n",
      "  69 71 73 73 77 78 77 78 50 52 55 58 60 63 65 67 67 66 68 69 73 73 75 76\n",
      "  29 34 37 41 46 51 52 55 54 56 59 61 65 66 68 70 35 39 44 46 52 54 58 60\n",
      "  58 60 62 64 68 70 71 72 58 61 63 66 67 69 71 72 68 72 73 72 77 77 77 82\n",
      "  60 62 64 66 69 71 73 73 74 71 72 75 77 78 78 80 55 59 59 63 64 67 67 70\n",
      "  69 74 71 73 76 79 78 78 27 32 40 41 48 49 53 53 55 57 58 61 64 67 68 70\n",
      "   0  0  6 12 21 25 30 34 35 41 42 49 52 49 56 58 21 26 34 35 40 44 50 48\n",
      "  52 55 59 58 62 64 66 68]]\n",
      "------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------\n",
      "zt3\n",
      "[[58]\n",
      " [59]\n",
      " [60]\n",
      " [63]\n",
      " [66]\n",
      " [69]\n",
      " [70]\n",
      " [70]\n",
      " [70]\n",
      " [70]\n",
      " [71]\n",
      " [72]\n",
      " [76]\n",
      " [76]\n",
      " [77]\n",
      " [78]\n",
      " [55]\n",
      " [59]\n",
      " [64]\n",
      " [64]\n",
      " [66]\n",
      " [69]\n",
      " [70]\n",
      " [71]\n",
      " [68]\n",
      " [71]\n",
      " [70]\n",
      " [73]\n",
      " [75]\n",
      " [75]\n",
      " [78]\n",
      " [76]\n",
      " [55]\n",
      " [58]\n",
      " [59]\n",
      " [63]\n",
      " [67]\n",
      " [68]\n",
      " [70]\n",
      " [71]\n",
      " [68]\n",
      " [70]\n",
      " [71]\n",
      " [72]\n",
      " [76]\n",
      " [77]\n",
      " [77]\n",
      " [77]\n",
      " [56]\n",
      " [58]\n",
      " [61]\n",
      " [63]\n",
      " [62]\n",
      " [67]\n",
      " [71]\n",
      " [71]\n",
      " [69]\n",
      " [71]\n",
      " [71]\n",
      " [73]\n",
      " [75]\n",
      " [76]\n",
      " [75]\n",
      " [78]\n",
      " [58]\n",
      " [59]\n",
      " [62]\n",
      " [68]\n",
      " [67]\n",
      " [70]\n",
      " [69]\n",
      " [74]\n",
      " [69]\n",
      " [71]\n",
      " [73]\n",
      " [73]\n",
      " [77]\n",
      " [78]\n",
      " [77]\n",
      " [78]\n",
      " [50]\n",
      " [52]\n",
      " [55]\n",
      " [58]\n",
      " [60]\n",
      " [63]\n",
      " [65]\n",
      " [67]\n",
      " [67]\n",
      " [66]\n",
      " [68]\n",
      " [69]\n",
      " [73]\n",
      " [73]\n",
      " [75]\n",
      " [76]\n",
      " [29]\n",
      " [34]\n",
      " [37]\n",
      " [41]\n",
      " [46]\n",
      " [51]\n",
      " [52]\n",
      " [55]\n",
      " [54]\n",
      " [56]\n",
      " [59]\n",
      " [61]\n",
      " [65]\n",
      " [66]\n",
      " [68]\n",
      " [70]\n",
      " [35]\n",
      " [39]\n",
      " [44]\n",
      " [46]\n",
      " [52]\n",
      " [54]\n",
      " [58]\n",
      " [60]\n",
      " [58]\n",
      " [60]\n",
      " [62]\n",
      " [64]\n",
      " [68]\n",
      " [70]\n",
      " [71]\n",
      " [72]\n",
      " [58]\n",
      " [61]\n",
      " [63]\n",
      " [66]\n",
      " [67]\n",
      " [69]\n",
      " [71]\n",
      " [72]\n",
      " [68]\n",
      " [72]\n",
      " [73]\n",
      " [72]\n",
      " [77]\n",
      " [77]\n",
      " [77]\n",
      " [82]\n",
      " [60]\n",
      " [62]\n",
      " [64]\n",
      " [66]\n",
      " [69]\n",
      " [71]\n",
      " [73]\n",
      " [73]\n",
      " [74]\n",
      " [71]\n",
      " [72]\n",
      " [75]\n",
      " [77]\n",
      " [78]\n",
      " [78]\n",
      " [80]\n",
      " [55]\n",
      " [59]\n",
      " [59]\n",
      " [63]\n",
      " [64]\n",
      " [67]\n",
      " [67]\n",
      " [70]\n",
      " [69]\n",
      " [74]\n",
      " [71]\n",
      " [73]\n",
      " [76]\n",
      " [79]\n",
      " [78]\n",
      " [78]\n",
      " [27]\n",
      " [32]\n",
      " [40]\n",
      " [41]\n",
      " [48]\n",
      " [49]\n",
      " [53]\n",
      " [53]\n",
      " [55]\n",
      " [57]\n",
      " [58]\n",
      " [61]\n",
      " [64]\n",
      " [67]\n",
      " [68]\n",
      " [70]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 6]\n",
      " [12]\n",
      " [21]\n",
      " [25]\n",
      " [30]\n",
      " [34]\n",
      " [35]\n",
      " [41]\n",
      " [42]\n",
      " [49]\n",
      " [52]\n",
      " [49]\n",
      " [56]\n",
      " [58]\n",
      " [21]\n",
      " [26]\n",
      " [34]\n",
      " [35]\n",
      " [40]\n",
      " [44]\n",
      " [50]\n",
      " [48]\n",
      " [52]\n",
      " [55]\n",
      " [59]\n",
      " [58]\n",
      " [62]\n",
      " [64]\n",
      " [66]\n",
      " [68]]\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "xt2 : xt를 reshape 으로(-1,) 한 결과 \n",
      "[ 91  93  85  90  95  93  86  91  87  87  87  86  88  87  90  87  70  73\n",
      "  69  71  76  76  77  78  74  75  76  78  79  80  78  81  65  64  68  67\n",
      "  72  71  74  73  73  70  72  74  77  77  78  78  13  19  24  29  35  37\n",
      "  41  47  44  48  51  55  58  59  59  62 102 100 102  97  99  99  97  96\n",
      "  92  91  89  89  91  91  90  88  76  78  76  77  79  80  81  81  79  81\n",
      "  80  81  81  83  82  80  70  71  72  72  76  76  77  77  74  74  71  76\n",
      "  81  79  80  80 167 163 157 151 149 145 139 136 130 127 122 120 120 120\n",
      " 115 117  36  40  44  47  50  53  58  57  57  59  61  63  67  69  71  69\n",
      "  50  56  55  57  62  64  64  67  64  67  68  65  71  75  73  75  50  52\n",
      "  52  56  62  64  65  66  65  66  69  68  73  73  73  74  43  49  50  54\n",
      "  57  58  61  64  61  65  67  66  69  70  71  74  79  75  73  77  80  81\n",
      "  76  82  80  79  81  82  85  84  84  83  79  79  79  81  82  82  83  85\n",
      "  81  81  81  83  86  87  87  85]\n",
      ",=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=,=\n",
      "xt3 : xt2를 reshape 으로 (-1,1)한 결과 \n",
      "[[ 91]\n",
      " [ 93]\n",
      " [ 85]\n",
      " [ 90]\n",
      " [ 95]\n",
      " [ 93]\n",
      " [ 86]\n",
      " [ 91]\n",
      " [ 87]\n",
      " [ 87]\n",
      " [ 87]\n",
      " [ 86]\n",
      " [ 88]\n",
      " [ 87]\n",
      " [ 90]\n",
      " [ 87]\n",
      " [ 70]\n",
      " [ 73]\n",
      " [ 69]\n",
      " [ 71]\n",
      " [ 76]\n",
      " [ 76]\n",
      " [ 77]\n",
      " [ 78]\n",
      " [ 74]\n",
      " [ 75]\n",
      " [ 76]\n",
      " [ 78]\n",
      " [ 79]\n",
      " [ 80]\n",
      " [ 78]\n",
      " [ 81]\n",
      " [ 65]\n",
      " [ 64]\n",
      " [ 68]\n",
      " [ 67]\n",
      " [ 72]\n",
      " [ 71]\n",
      " [ 74]\n",
      " [ 73]\n",
      " [ 73]\n",
      " [ 70]\n",
      " [ 72]\n",
      " [ 74]\n",
      " [ 77]\n",
      " [ 77]\n",
      " [ 78]\n",
      " [ 78]\n",
      " [ 13]\n",
      " [ 19]\n",
      " [ 24]\n",
      " [ 29]\n",
      " [ 35]\n",
      " [ 37]\n",
      " [ 41]\n",
      " [ 47]\n",
      " [ 44]\n",
      " [ 48]\n",
      " [ 51]\n",
      " [ 55]\n",
      " [ 58]\n",
      " [ 59]\n",
      " [ 59]\n",
      " [ 62]\n",
      " [102]\n",
      " [100]\n",
      " [102]\n",
      " [ 97]\n",
      " [ 99]\n",
      " [ 99]\n",
      " [ 97]\n",
      " [ 96]\n",
      " [ 92]\n",
      " [ 91]\n",
      " [ 89]\n",
      " [ 89]\n",
      " [ 91]\n",
      " [ 91]\n",
      " [ 90]\n",
      " [ 88]\n",
      " [ 76]\n",
      " [ 78]\n",
      " [ 76]\n",
      " [ 77]\n",
      " [ 79]\n",
      " [ 80]\n",
      " [ 81]\n",
      " [ 81]\n",
      " [ 79]\n",
      " [ 81]\n",
      " [ 80]\n",
      " [ 81]\n",
      " [ 81]\n",
      " [ 83]\n",
      " [ 82]\n",
      " [ 80]\n",
      " [ 70]\n",
      " [ 71]\n",
      " [ 72]\n",
      " [ 72]\n",
      " [ 76]\n",
      " [ 76]\n",
      " [ 77]\n",
      " [ 77]\n",
      " [ 74]\n",
      " [ 74]\n",
      " [ 71]\n",
      " [ 76]\n",
      " [ 81]\n",
      " [ 79]\n",
      " [ 80]\n",
      " [ 80]\n",
      " [167]\n",
      " [163]\n",
      " [157]\n",
      " [151]\n",
      " [149]\n",
      " [145]\n",
      " [139]\n",
      " [136]\n",
      " [130]\n",
      " [127]\n",
      " [122]\n",
      " [120]\n",
      " [120]\n",
      " [120]\n",
      " [115]\n",
      " [117]\n",
      " [ 36]\n",
      " [ 40]\n",
      " [ 44]\n",
      " [ 47]\n",
      " [ 50]\n",
      " [ 53]\n",
      " [ 58]\n",
      " [ 57]\n",
      " [ 57]\n",
      " [ 59]\n",
      " [ 61]\n",
      " [ 63]\n",
      " [ 67]\n",
      " [ 69]\n",
      " [ 71]\n",
      " [ 69]\n",
      " [ 50]\n",
      " [ 56]\n",
      " [ 55]\n",
      " [ 57]\n",
      " [ 62]\n",
      " [ 64]\n",
      " [ 64]\n",
      " [ 67]\n",
      " [ 64]\n",
      " [ 67]\n",
      " [ 68]\n",
      " [ 65]\n",
      " [ 71]\n",
      " [ 75]\n",
      " [ 73]\n",
      " [ 75]\n",
      " [ 50]\n",
      " [ 52]\n",
      " [ 52]\n",
      " [ 56]\n",
      " [ 62]\n",
      " [ 64]\n",
      " [ 65]\n",
      " [ 66]\n",
      " [ 65]\n",
      " [ 66]\n",
      " [ 69]\n",
      " [ 68]\n",
      " [ 73]\n",
      " [ 73]\n",
      " [ 73]\n",
      " [ 74]\n",
      " [ 43]\n",
      " [ 49]\n",
      " [ 50]\n",
      " [ 54]\n",
      " [ 57]\n",
      " [ 58]\n",
      " [ 61]\n",
      " [ 64]\n",
      " [ 61]\n",
      " [ 65]\n",
      " [ 67]\n",
      " [ 66]\n",
      " [ 69]\n",
      " [ 70]\n",
      " [ 71]\n",
      " [ 74]\n",
      " [ 79]\n",
      " [ 75]\n",
      " [ 73]\n",
      " [ 77]\n",
      " [ 80]\n",
      " [ 81]\n",
      " [ 76]\n",
      " [ 82]\n",
      " [ 80]\n",
      " [ 79]\n",
      " [ 81]\n",
      " [ 82]\n",
      " [ 85]\n",
      " [ 84]\n",
      " [ 84]\n",
      " [ 83]\n",
      " [ 79]\n",
      " [ 79]\n",
      " [ 79]\n",
      " [ 81]\n",
      " [ 82]\n",
      " [ 82]\n",
      " [ 83]\n",
      " [ 85]\n",
      " [ 81]\n",
      " [ 81]\n",
      " [ 81]\n",
      " [ 83]\n",
      " [ 86]\n",
      " [ 87]\n",
      " [ 87]\n",
      " [ 85]]\n",
      "/./././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././././.\n",
      "------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------\n",
      "ett3\n",
      "[[103]\n",
      " [103]\n",
      " [103]\n",
      " [102]\n",
      " [103]\n",
      " [103]\n",
      " [ 99]\n",
      " [102]\n",
      " [ 96]\n",
      " [ 95]\n",
      " [ 93]\n",
      " [ 95]\n",
      " [ 96]\n",
      " [ 95]\n",
      " [ 94]\n",
      " [ 95]\n",
      " [ 80]\n",
      " [ 80]\n",
      " [ 80]\n",
      " [ 82]\n",
      " [ 84]\n",
      " [ 83]\n",
      " [ 84]\n",
      " [ 85]\n",
      " [ 81]\n",
      " [ 81]\n",
      " [ 81]\n",
      " [ 82]\n",
      " [ 87]\n",
      " [ 85]\n",
      " [ 84]\n",
      " [ 85]\n",
      " [ 76]\n",
      " [ 78]\n",
      " [ 78]\n",
      " [ 80]\n",
      " [ 80]\n",
      " [ 85]\n",
      " [ 83]\n",
      " [ 83]\n",
      " [ 80]\n",
      " [ 82]\n",
      " [ 81]\n",
      " [ 84]\n",
      " [ 84]\n",
      " [ 88]\n",
      " [ 85]\n",
      " [ 86]\n",
      " [ 66]\n",
      " [ 66]\n",
      " [ 68]\n",
      " [ 69]\n",
      " [ 74]\n",
      " [ 74]\n",
      " [ 75]\n",
      " [ 76]\n",
      " [ 75]\n",
      " [ 76]\n",
      " [ 77]\n",
      " [ 78]\n",
      " [ 82]\n",
      " [ 81]\n",
      " [ 83]\n",
      " [ 82]\n",
      " [ 65]\n",
      " [ 66]\n",
      " [ 68]\n",
      " [ 70]\n",
      " [ 73]\n",
      " [ 76]\n",
      " [ 73]\n",
      " [ 77]\n",
      " [ 73]\n",
      " [ 78]\n",
      " [ 76]\n",
      " [ 79]\n",
      " [ 80]\n",
      " [ 83]\n",
      " [ 81]\n",
      " [ 82]\n",
      " [ 51]\n",
      " [ 55]\n",
      " [ 58]\n",
      " [ 60]\n",
      " [ 66]\n",
      " [ 67]\n",
      " [ 67]\n",
      " [ 69]\n",
      " [ 68]\n",
      " [ 70]\n",
      " [ 74]\n",
      " [ 73]\n",
      " [ 78]\n",
      " [ 76]\n",
      " [ 78]\n",
      " [ 80]]\n",
      "0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-\n",
      "(96,)\n",
      "(224, 1)\n",
      "[58 59 60 63 66 69 70 70 70 70 71 72 76 76 77 78 55 59 64 64 66 69 70 71\n",
      " 68 71 70 73 75 75 78 76 55 58 59 63 67 68 70 71 68 70 71 72 76 77 77 77\n",
      " 56 58 61 63 62 67 71 71 69 71 71 73 75 76 75 78 58 59 62 68 67 70 69 74\n",
      " 69 71 73 73 77 78 77 78 50 52 55 58 60 63 65 67 67 66 68 69 73 73 75 76\n",
      " 29 34 37 41 46 51 52 55 54 56 59 61 65 66 68 70 35 39 44 46 52 54 58 60\n",
      " 58 60 62 64 68 70 71 72 58 61 63 66 67 69 71 72 68 72 73 72 77 77 77 82\n",
      " 60 62 64 66 69 71 73 73 74 71 72 75 77 78 78 80 55 59 59 63 64 67 67 70\n",
      " 69 74 71 73 76 79 78 78 27 32 40 41 48 49 53 53 55 57 58 61 64 67 68 70\n",
      "  0  0  6 12 21 25 30 34 35 41 42 49 52 49 56 58 21 26 34 35 40 44 50 48\n",
      " 52 55 59 58 62 64 66 68]\n",
      "ett4\n",
      "[103 103 103 102 103 103  99 102  96  95  93  95  96  95  94  95  80  80\n",
      "  80  82  84  83  84  85  81  81  81  82  87  85  84  85  76  78  78  80\n",
      "  80  85  83  83  80  82  81  84  84  88  85  86  66  66  68  69  74  74\n",
      "  75  76  75  76  77  78  82  81  83  82  65  66  68  70  73  76  73  77\n",
      "  73  78  76  79  80  83  81  82  51  55  58  60  66  67  67  69  68  70\n",
      "  74  73  78  76  78  80]\n",
      "yt5\n",
      "[58 59 60 63 66 69 70 70 70 70 71 72 76 76 77 78 55 59 64 64 66 69 70 71\n",
      " 68 71 70 73 75 75 78 76 55 58 59 63 67 68 70 71 68 70 71 72 76 77 77 77\n",
      " 56 58 61 63 62 67 71 71 69 71 71 73 75 76 75 78 58 59 62 68 67 70 69 74\n",
      " 69 71 73 73 77 78 77 78 50 52 55 58 60 63 65 67 67 66 68 69 73 73 75 76]\n",
      "정확도 계산중... \n",
      " 정확도는 다음과 같다 \n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결정 함수의 결과 형태: (96, 53)\n",
      "결정 함수 결과:\n",
      "[[-5.4035253  -6.39562771 -6.39568423 -5.70539454 -6.39566688 -6.3956696\n",
      "  -6.39564565 -6.39568309 -6.39550453 -6.39553983 -4.75870015 -5.18080093\n",
      "  -6.39563002 -6.39563515 -5.70529522 -5.09453347 -6.39566688 -5.70534539\n",
      "  -5.70496208 -5.70519773 -4.98146457 -4.96858573 -6.39550453 -4.35560358\n",
      "  -5.70511779 -5.70501043 -4.46720846 -4.83767735 -6.39551901 -1.81494742\n",
      "  -3.66670658 -4.10659888 -4.88673925 -1.07430955 -3.88003217 -3.7831589\n",
      "  -5.70541836 -3.74193618 -3.61342851 -3.07148241 -4.19662563 -2.36358102\n",
      "  -2.71176409 -3.88216474 -3.68266963 -5.3020476  -4.3319896  -4.01592487\n",
      "  -3.15560377 -3.34015143 -6.39562771 -6.39550453 -6.39561164]\n",
      " [-5.4035253  -6.39562771 -6.39568423 -5.70539454 -6.39566688 -6.3956696\n",
      "  -6.39564565 -6.39568309 -6.39550453 -6.39553983 -4.75870015 -5.18080093\n",
      "  -6.39563002 -6.39563515 -5.70529522 -5.09453347 -6.39566688 -5.70534539\n",
      "  -5.70496208 -5.70519773 -4.98146457 -4.96858573 -6.39550453 -4.35560358\n",
      "  -5.70511779 -5.70501043 -4.46720846 -4.83767735 -6.39551901 -1.81494742\n",
      "  -3.66670658 -4.10659888 -4.88673925 -1.07430955 -3.88003217 -3.7831589\n",
      "  -5.70541836 -3.74193618 -3.61342851 -3.07148241 -4.19662563 -2.36358102\n",
      "  -2.71176409 -3.88216474 -3.68266963 -5.3020476  -4.3319896  -4.01592487\n",
      "  -3.15560377 -3.34015143 -6.39562771 -6.39550453 -6.39561164]\n",
      " [-5.4035253  -6.39562771 -6.39568423 -5.70539454 -6.39566688 -6.3956696\n",
      "  -6.39564565 -6.39568309 -6.39550453 -6.39553983 -4.75870015 -5.18080093\n",
      "  -6.39563002 -6.39563515 -5.70529522 -5.09453347 -6.39566688 -5.70534539\n",
      "  -5.70496208 -5.70519773 -4.98146457 -4.96858573 -6.39550453 -4.35560358\n",
      "  -5.70511779 -5.70501043 -4.46720846 -4.83767735 -6.39551901 -1.81494742\n",
      "  -3.66670658 -4.10659888 -4.88673925 -1.07430955 -3.88003217 -3.7831589\n",
      "  -5.70541836 -3.74193618 -3.61342851 -3.07148241 -4.19662563 -2.36358102\n",
      "  -2.71176409 -3.88216474 -3.68266963 -5.3020476  -4.3319896  -4.01592487\n",
      "  -3.15560377 -3.34015143 -6.39562771 -6.39550453 -6.39561164]\n",
      " [-5.4035253  -6.39562771 -6.39568423 -5.70539454 -6.39566688 -6.3956696\n",
      "  -6.39564565 -6.39568309 -6.39550453 -6.39553983 -4.75870015 -5.18080093\n",
      "  -6.39563002 -6.39563515 -5.70529522 -5.09453347 -6.39566688 -5.70534539\n",
      "  -5.70496208 -5.70519773 -4.98146457 -4.96858573 -6.39550453 -4.35560358\n",
      "  -5.70511779 -5.70501043 -4.46720846 -4.83767735 -6.39551901 -1.81494742\n",
      "  -3.66670658 -4.10659888 -4.88673925 -1.07430955 -3.88003217 -3.7831589\n",
      "  -5.70541836 -3.74193618 -3.61342851 -3.07148241 -4.19662563 -2.36358102\n",
      "  -2.71176409 -3.88216474 -3.68266963 -5.3020476  -4.3319896  -4.01592487\n",
      "  -3.15560377 -3.34015143 -6.39562771 -6.39550453 -6.39561164]\n",
      " [-5.4035253  -6.39562771 -6.39568423 -5.70539454 -6.39566688 -6.3956696\n",
      "  -6.39564565 -6.39568309 -6.39550453 -6.39553983 -4.75870015 -5.18080093\n",
      "  -6.39563002 -6.39563515 -5.70529522 -5.09453347 -6.39566688 -5.70534539\n",
      "  -5.70496208 -5.70519773 -4.98146457 -4.96858573 -6.39550453 -4.35560358\n",
      "  -5.70511779 -5.70501043 -4.46720846 -4.83767735 -6.39551901 -1.81494742\n",
      "  -3.66670658 -4.10659888 -4.88673925 -1.07430955 -3.88003217 -3.7831589\n",
      "  -5.70541836 -3.74193618 -3.61342851 -3.07148241 -4.19662563 -2.36358102\n",
      "  -2.71176409 -3.88216474 -3.68266963 -5.3020476  -4.3319896  -4.01592487\n",
      "  -3.15560377 -3.34015143 -6.39562771 -6.39550453 -6.39561164]\n",
      " [-5.4035253  -6.39562771 -6.39568423 -5.70539454 -6.39566688 -6.3956696\n",
      "  -6.39564565 -6.39568309 -6.39550453 -6.39553983 -4.75870015 -5.18080093\n",
      "  -6.39563002 -6.39563515 -5.70529522 -5.09453347 -6.39566688 -5.70534539\n",
      "  -5.70496208 -5.70519773 -4.98146457 -4.96858573 -6.39550453 -4.35560358\n",
      "  -5.70511779 -5.70501043 -4.46720846 -4.83767735 -6.39551901 -1.81494742\n",
      "  -3.66670658 -4.10659888 -4.88673925 -1.07430955 -3.88003217 -3.7831589\n",
      "  -5.70541836 -3.74193618 -3.61342851 -3.07148241 -4.19662563 -2.36358102\n",
      "  -2.71176409 -3.88216474 -3.68266963 -5.3020476  -4.3319896  -4.01592487\n",
      "  -3.15560377 -3.34015143 -6.39562771 -6.39550453 -6.39561164]]\n",
      "/*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*/\n",
      "가장 큰 결정 함수의 인덱스:\n",
      "[33 33 33 33 33 33 38 33 45 40 40 40 45 40 40 40  3  3  3 14 20 29 20 19\n",
      " 36 36 36 14 41 19 20 19 26 23 23  3  3 19 29 29  3 14 36 20 20 47 19 41\n",
      " 45 45 43 35 41 41 51 26 51 26 23 23 14 36 29 14 28 45 43  7 49 26 49 23\n",
      " 49 23 26  3  3 29 36 14 42 44 20 47 45 48 48 35 43  7 41 49 23 26 23  3]\n",
      "예측:\n",
      "[62 62 62 62 62 62 67 62 74 69 69 69 74 69 69 69 21 21 21 40 49 58 49 48\n",
      " 65 65 65 40 70 48 49 48 55 52 52 21 21 48 58 58 21 40 65 49 49 76 48 70\n",
      " 74 74 72 64 70 70 80 55 80 55 52 52 40 65 58 40 57 74 72 29 78 55 78 52\n",
      " 78 52 55 21 21 58 65 40 71 73 49 76 74 77 77 64 72 29 70 78 52 55 52 21]\n",
      "/*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*/\n",
      "예측 확률:\n",
      "[[0.00389976 0.00144602 0.00144594 0.00288362 0.00144596 0.00144596\n",
      "  0.00144599 0.00144594 0.0014462  0.00144614 0.0074316  0.00487266\n",
      "  0.00144601 0.00144601 0.00288391 0.00531168 0.00144596 0.00288376\n",
      "  0.00288487 0.00288419 0.00594753 0.00602463 0.0014462  0.01112103\n",
      "  0.00288442 0.00288473 0.00994662 0.00686725 0.00144617 0.14110349\n",
      "  0.02214772 0.01426547 0.00653846 0.29593253 0.01789299 0.01971308\n",
      "  0.00288355 0.02054268 0.02335971 0.0401635  0.01303731 0.08152095\n",
      "  0.05755131 0.01785487 0.02179698 0.00431628 0.01138676 0.01561944\n",
      "  0.0369231  0.03070083 0.00144602 0.0014462  0.00144604]\n",
      " [0.00389976 0.00144602 0.00144594 0.00288362 0.00144596 0.00144596\n",
      "  0.00144599 0.00144594 0.0014462  0.00144614 0.0074316  0.00487266\n",
      "  0.00144601 0.00144601 0.00288391 0.00531168 0.00144596 0.00288376\n",
      "  0.00288487 0.00288419 0.00594753 0.00602463 0.0014462  0.01112103\n",
      "  0.00288442 0.00288473 0.00994662 0.00686725 0.00144617 0.14110349\n",
      "  0.02214772 0.01426547 0.00653846 0.29593253 0.01789299 0.01971308\n",
      "  0.00288355 0.02054268 0.02335971 0.0401635  0.01303731 0.08152095\n",
      "  0.05755131 0.01785487 0.02179698 0.00431628 0.01138676 0.01561944\n",
      "  0.0369231  0.03070083 0.00144602 0.0014462  0.00144604]\n",
      " [0.00389976 0.00144602 0.00144594 0.00288362 0.00144596 0.00144596\n",
      "  0.00144599 0.00144594 0.0014462  0.00144614 0.0074316  0.00487266\n",
      "  0.00144601 0.00144601 0.00288391 0.00531168 0.00144596 0.00288376\n",
      "  0.00288487 0.00288419 0.00594753 0.00602463 0.0014462  0.01112103\n",
      "  0.00288442 0.00288473 0.00994662 0.00686725 0.00144617 0.14110349\n",
      "  0.02214772 0.01426547 0.00653846 0.29593253 0.01789299 0.01971308\n",
      "  0.00288355 0.02054268 0.02335971 0.0401635  0.01303731 0.08152095\n",
      "  0.05755131 0.01785487 0.02179698 0.00431628 0.01138676 0.01561944\n",
      "  0.0369231  0.03070083 0.00144602 0.0014462  0.00144604]\n",
      " [0.00389976 0.00144602 0.00144594 0.00288362 0.00144596 0.00144596\n",
      "  0.00144599 0.00144594 0.0014462  0.00144614 0.0074316  0.00487266\n",
      "  0.00144601 0.00144601 0.00288391 0.00531168 0.00144596 0.00288376\n",
      "  0.00288487 0.00288419 0.00594753 0.00602463 0.0014462  0.01112103\n",
      "  0.00288442 0.00288473 0.00994662 0.00686725 0.00144617 0.14110349\n",
      "  0.02214772 0.01426547 0.00653846 0.29593253 0.01789299 0.01971308\n",
      "  0.00288355 0.02054268 0.02335971 0.0401635  0.01303731 0.08152095\n",
      "  0.05755131 0.01785487 0.02179698 0.00431628 0.01138676 0.01561944\n",
      "  0.0369231  0.03070083 0.00144602 0.0014462  0.00144604]\n",
      " [0.00389976 0.00144602 0.00144594 0.00288362 0.00144596 0.00144596\n",
      "  0.00144599 0.00144594 0.0014462  0.00144614 0.0074316  0.00487266\n",
      "  0.00144601 0.00144601 0.00288391 0.00531168 0.00144596 0.00288376\n",
      "  0.00288487 0.00288419 0.00594753 0.00602463 0.0014462  0.01112103\n",
      "  0.00288442 0.00288473 0.00994662 0.00686725 0.00144617 0.14110349\n",
      "  0.02214772 0.01426547 0.00653846 0.29593253 0.01789299 0.01971308\n",
      "  0.00288355 0.02054268 0.02335971 0.0401635  0.01303731 0.08152095\n",
      "  0.05755131 0.01785487 0.02179698 0.00431628 0.01138676 0.01561944\n",
      "  0.0369231  0.03070083 0.00144602 0.0014462  0.00144604]\n",
      " [0.00389976 0.00144602 0.00144594 0.00288362 0.00144596 0.00144596\n",
      "  0.00144599 0.00144594 0.0014462  0.00144614 0.0074316  0.00487266\n",
      "  0.00144601 0.00144601 0.00288391 0.00531168 0.00144596 0.00288376\n",
      "  0.00288487 0.00288419 0.00594753 0.00602463 0.0014462  0.01112103\n",
      "  0.00288442 0.00288473 0.00994662 0.00686725 0.00144617 0.14110349\n",
      "  0.02214772 0.01426547 0.00653846 0.29593253 0.01789299 0.01971308\n",
      "  0.00288355 0.02054268 0.02335971 0.0401635  0.01303731 0.08152095\n",
      "  0.05755131 0.01785487 0.02179698 0.00431628 0.01138676 0.01561944\n",
      "  0.0369231  0.03070083 0.00144602 0.0014462  0.00144604]]\n",
      "합: [1. 1. 1. 1. 1. 1.]\n",
      "/*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*//*/\n",
      "zt39\n",
      "(1, 224)\n",
      "[[58 59 60 63 66 69 70 70 70 70 71 72 76 76 77 78 55 59 64 64 66 69 70 71\n",
      "  68 71 70 73 75 75 78 76 55 58 59 63 67 68 70 71 68 70 71 72 76 77 77 77\n",
      "  56 58 61 63 62 67 71 71 69 71 71 73 75 76 75 78 58 59 62 68 67 70 69 74\n",
      "  69 71 73 73 77 78 77 78 50 52 55 58 60 63 65 67 67 66 68 69 73 73 75 76\n",
      "  29 34 37 41 46 51 52 55 54 56 59 61 65 66 68 70 35 39 44 46 52 54 58 60\n",
      "  58 60 62 64 68 70 71 72 58 61 63 66 67 69 71 72 68 72 73 72 77 77 77 82\n",
      "  60 62 64 66 69 71 73 73 74 71 72 75 77 78 78 80 55 59 59 63 64 67 67 70\n",
      "  69 74 71 73 76 79 78 78 27 32 40 41 48 49 53 53 55 57 58 61 64 67 68 70\n",
      "   0  0  6 12 21 25 30 34 35 41 42 49 52 49 56 58 21 26 34 35 40 44 50 48\n",
      "  52 55 59 58 62 64 66 68]]\n",
      "ett3.shape\n",
      "(96,)\n",
      "xt39.shape\n",
      "(1, 224)\n",
      "[[ 91  93  85  90  95  93  86  91  87  87  87  86  88  87  90  87  70  73\n",
      "   69  71  76  76  77  78  74  75  76  78  79  80  78  81  65  64  68  67\n",
      "   72  71  74  73  73  70  72  74  77  77  78  78  13  19  24  29  35  37\n",
      "   41  47  44  48  51  55  58  59  59  62 102 100 102  97  99  99  97  96\n",
      "   92  91  89  89  91  91  90  88  76  78  76  77  79  80  81  81  79  81\n",
      "   80  81  81  83  82  80  70  71  72  72  76  76  77  77  74  74  71  76\n",
      "   81  79  80  80 167 163 157 151 149 145 139 136 130 127 122 120 120 120\n",
      "  115 117  36  40  44  47  50  53  58  57  57  59  61  63  67  69  71  69\n",
      "   50  56  55  57  62  64  64  67  64  67  68  65  71  75  73  75  50  52\n",
      "   52  56  62  64  65  66  65  66  69  68  73  73  73  74  43  49  50  54\n",
      "   57  58  61  64  61  65  67  66  69  70  71  74  79  75  73  77  80  81\n",
      "   76  82  80  79  81  82  85  84  84  83  79  79  79  81  82  82  83  85\n",
      "   81  81  81  83  86  87  87  85]]\n",
      "XX.shape\n",
      "(30, 30)\n",
      "xy.shape\n",
      "(900, 2)\n",
      "xy1\n",
      "[ 5.3        -4.1         5.3        -0.98965517  5.3         2.12068966\n",
      "  5.3         5.23103448  5.3         8.34137931  5.3        11.45172414\n",
      "  5.3        14.56206897  5.3        17.67241379  5.3        20.78275862\n",
      "  5.3        23.89310345  5.3        27.00344828  5.3        30.1137931\n",
      "  5.3        33.22413793  5.3        36.33448276  5.3        39.44482759]\n",
      "xy3\n",
      "[ 5.3        -4.1         5.3        -0.98965517  5.3         2.12068966\n",
      "  5.3         5.23103448  5.3         8.34137931  5.3        11.45172414\n",
      "  5.3        14.56206897  5.3        17.67241379  5.3        20.78275862\n",
      "  5.3        23.89310345  5.3        27.00344828  5.3        30.1137931\n",
      "  5.3        33.22413793  5.3        36.33448276  5.3        39.44482759]\n",
      "xy3\n",
      "[ 5.3        -4.1         5.3        -0.98965517  5.3         2.12068966\n",
      "  5.3         5.23103448  5.3         8.34137931  5.3        11.45172414\n",
      "  5.3        14.56206897  5.3        17.67241379  5.3        20.78275862\n",
      "  5.3        23.89310345  5.3        27.00344828  5.3        30.1137931\n",
      "  5.3        33.22413793  5.3        36.33448276  5.3        39.44482759]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1590 into shape (30,30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_64/1221083596.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0mxy5\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mxy99\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;31m# 지지벡터(Support Vector) 표현\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1590 into shape (30,30)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "# 데이터셋 로드하기\n",
    "# [[your code]\n",
    "data = rows\n",
    "data2 = rows2\n",
    "data9 = rows9\n",
    "# 훈련용 데이터셋 나누기\n",
    "# [[your code]\n",
    "X_train = rows[:14]\n",
    "X_test = rows[14:]\n",
    "\n",
    "y_train = data9[:14]\n",
    "y_test = data9[14:]\n",
    "\n",
    "z_train = data9[:14]\n",
    "\n",
    "print(\"y_train\")\n",
    "print(y_train)\n",
    "print('-'*90)\n",
    "print('-'*90)\n",
    "print(\"X_train\")\n",
    "print(X_train)\n",
    "# y_test2 = data2[:16]\n",
    "# y_test2 = y_test2.reshape(16,4)\n",
    "# 훈련하기\n",
    "# [[your code]\n",
    "print('-/'*90)\n",
    "print('-/'*90)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "# X2, y2 = make_classification(n_samples=1000, n_features=4,\n",
    "#                              n_informative=2, n_redundant=0,\n",
    "#                              random_state=0, shuffle=False)\n",
    "# clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "# clf.fit(X2, y2)\n",
    "# print(X2)\n",
    "# print('-/'*90)\n",
    "# print('-/'*90)\n",
    "xtt = np.array(X_train)\n",
    "xt = xtt.reshape(-1,)\n",
    "ytt = np.array(y_train) #numpy array 로 바꿈!!\n",
    "yt = ytt.reshape(-1,) # numpy array 차원 축소!!! 1차원으로 만들어주기\n",
    "ett = np.array(y_test)\n",
    "ettt = ett.reshape(-1,)\n",
    "zt = np.array(z_train)\n",
    "\n",
    "print(\"xt : X_train 에 해당\")\n",
    "print(xt)\n",
    "print('-'*90)\n",
    "print(\"yt: y_train 에 해당 \")\n",
    "print(yt)\n",
    "print('-'*90)\n",
    "print(\"ett : y_test 에 해당\")\n",
    "print(ettt)\n",
    "print('-'*90)\n",
    "\n",
    "xt = np.expand_dims(xt, axis=0) # 차원 확대\n",
    "yt = np.expand_dims(yt, axis=0) # 차원 확대 \n",
    "np.expand_dims(xt, axis=0)\n",
    "np.expand_dims(yt, axis=0)\n",
    "\n",
    "print(\"xt\")\n",
    "print(xt)\n",
    "print('-'*90)\n",
    "print(\"yt\")\n",
    "print(yt)\n",
    "print('-'*90)\n",
    "print('-*'*90)\n",
    "# clf = MultiOutputClassifier(KNeighborsClassifier()).fit(xt,yt) # 2차원 이상의 배열이 필요함...\n",
    "knn = KNeighborsClassifier(n_neighbors=1)#여기에서 n_neighbers =1 이 중요!!! 입력 데이터 형태를 보면 1로 해야함\n",
    "knn = MultiOutputClassifier(KNeighborsClassifier(n_neighbors=1)).fit(xt,yt) #2차원 필요\n",
    "print(\"knn 예측치\")\n",
    "knnmaster1 = knn.predict(xt[-2:]) #We select the training set with the [:-1] Python syntax,\n",
    "#which produces a new array that contains all but the last item from digits.data:\n",
    "print(\"knmaster1\")\n",
    "print(knnmaster1)\n",
    "print('-*'*90)\n",
    "\n",
    "\n",
    "print(\"정답률=\", knn.score(yt, xt)) ###########################\n",
    "\n",
    "\n",
    "print('-*'*90)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(xt, yt)\n",
    "print('-'*90)\n",
    "# 예측하기\n",
    "# [[your code]\n",
    "y_pred1 = model.predict(xt)\n",
    "# 정답률 출력하기\n",
    "# [[your code]\n",
    "print(y_pred1)\n",
    "print('-'*90)\n",
    "decision_tree = DecisionTreeClassifier(random_state=1)\n",
    "decision_tree.fit(xt, yt)\n",
    "y_pred2 = decision_tree.predict(xt)\n",
    "print(\"Decision Tree classifier 예측치\")\n",
    "print(y_pred2)\n",
    "print('-'*90)\n",
    "\n",
    "y_testt = np.transpose(y_test)\n",
    "print(y_test)\n",
    "print('-'*90)\n",
    "#y_test = np.expand_dims(y_test, axis=0)\n",
    "\n",
    "print('y_test')\n",
    "print(y_test)\n",
    "print('-'*90)\n",
    "print('y_pred1')\n",
    "print(y_pred1)\n",
    "print('-'*90)\n",
    "print('-'*90) \n",
    "#svm 은 y 가 1차원이어야 한다고 한다.\n",
    "yt2 = yt.reshape(-1,) # numpy array 차원 축소!!! 1차원으로 만들어주기\n",
    "xt2 = xt.reshape(-1,)\n",
    "xt3 = xt2.reshape(-1, 1)\n",
    "yt3 = yt2.reshape(-1, 1) #조진호(사람2) 데이터            \n",
    "ett2 = ett.reshape(-1,)\n",
    "ett3 = ett.reshape(-1, 1) #최주원(사람3) 데이터\n",
    "zt3 = zt.reshape(-1,)\n",
    "zt3 = zt.reshape(-1,1)\n",
    "\n",
    "print(\"zt3\")\n",
    "print(zt3)\n",
    "print('+++++'*60)\n",
    "print(\"xt2 : xt를 reshape 으로(-1,) 한 결과 \")\n",
    "print(xt2)\n",
    "print(',=,='*90)\n",
    "print(\"xt3 : xt2를 reshape 으로 (-1,1)한 결과 \")\n",
    "print(xt3)\n",
    "print('/./.'*90)\n",
    "from sklearn import svm\n",
    "\n",
    "print('-'*90)\n",
    "print('-'*90)\n",
    "print(\"ett3\")\n",
    "print(ett3)\n",
    "ett4 =ett3.reshape(-1,)\n",
    "yt33 = yt3.reshape(-1,) #차원축소\n",
    "xt33 = xt3.reshape(-1,)\n",
    "\n",
    "print('0-0-'*90)\n",
    "print(ett4.shape) \n",
    "print(yt3.shape)\n",
    "yt4 = yt3.reshape(-1,)\n",
    "ett3= ett3.reshape(-1,)\n",
    "print(yt4)\n",
    "print(\"ett4\")\n",
    "print(ett4)\n",
    "yt5 = yt4[:96]\n",
    "print(\"yt5\")\n",
    "print(yt5)\n",
    "accuracy = accuracy_score(ett4, yt5) #같은 shape 이어야 함. accuracy 랑 다른게 있다. \n",
    "\n",
    "\n",
    "print(\"정확도 계산중... \")\n",
    "print(\" 정확도는 다음과 같다 \")\n",
    "print(accuracy*100)\n",
    "# from sklearn.datasets import make_blobs\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# X,y = make_multilabel_classification(n_classes= 3,random_state = 0)\n",
    "\n",
    "# clf.predict(X[-2:])\n",
    "\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=3)\n",
    "# classifier = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "# classifier.fit(y_test,y_pred)\n",
    "# predictions = classifier.predict(y_train)\n",
    "# classifier.score(y_true,np.array(y_train))\n",
    "\n",
    "# from sklearn.linear_model import RidgeClassifierCV\n",
    "# clf = RidgeClassifierCV().fit(X_train, y_train)\n",
    "# y_score = clf.decision_function(X_train)\n",
    "# roc_auc_score(y_test, y_train, average=None)\n",
    "\n",
    "# from sklearn.datasets import make_multilabel_classification\n",
    "# from sklearn.multioutput import MultiOutputClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# X, y = make_multilabel_classification(random_state=0)\n",
    "# inner_clf = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "# clf = MultiOutputClassifier(inner_clf).fit(X, y)\n",
    "# y_score = np.transpose([y_pred[:, 1] for y_pred in clf.predict_proba(X)])\n",
    "# roc_auc_score(y, y_score, average=None)\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# clf9 = Pipeline([\n",
    "#   ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\"))),\n",
    "#   ('classification', RandomForestClassifier())\n",
    "# ])\n",
    "ett999 = ett3.reshape(-1,1)\n",
    "gbrt = GradientBoostingClassifier(learning_rate=0.01, random_state=0)\n",
    "gbrt.fit(xt3, yt3)\n",
    "print(\"결정 함수의 결과 형태: {}\".format(gbrt.decision_function(ett999).shape))#2차원 요구--> ett3\n",
    "# plot the first few entries of the decision function\n",
    "print(\"결정 함수 결과:\\n{}\".format(gbrt.decision_function(ett999)[:6, :]))\n",
    "print('/*/'*90)\n",
    "print(\"가장 큰 결정 함수의 인덱스:\\n{}\".format(\n",
    "      np.argmax(gbrt.decision_function(ett999), axis=1)))\n",
    "print(\"예측:\\n{}\".format(gbrt.predict(ett999)))\n",
    "# 가장 큰 결정 함수의 인덱스:\n",
    "# [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
    "#  0]\n",
    "# 예측:\n",
    "# [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
    "#  0]\n",
    "print('/*/'*90)\n",
    "# predict_proba 결과 중 앞부분 일부를 확인합니다\n",
    "print(\"예측 확률:\\n{}\".format(gbrt.predict_proba(ett999)[:6]))\n",
    "# 행 방향으로 확률을 더하면 1 이 됩니다\n",
    "print(\"합: {}\".format(gbrt.predict_proba(ett999)[:6].sum(axis=1)))\n",
    "# 예측 확률:\n",
    "# [[0.10664722 0.7840248  0.10932798]\n",
    "#  [0.78880668 0.10599243 0.10520089]\n",
    "#  [0.10231173 0.10822274 0.78946553]\n",
    "#  [0.10664722 0.7840248  0.10932798]\n",
    "#  [0.10825347 0.66344934 0.22829719]\n",
    "#  [0.78880668 0.10599243 0.10520089]]\n",
    "# 합: [1. 1. 1. 1. 1. 1.]\n",
    "print('/*/'*90)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xt39 = np.transpose(xt3)\n",
    "yt39 = np.transpose(yt3)\n",
    "ett39 = np.transpose(ett3)\n",
    "zt39 = np.transpose(zt3)\n",
    "print(\"zt39\")\n",
    "print(zt39.shape)\n",
    "print(zt39)\n",
    "s = [0.7*np.linalg.norm([a, b]) for a, b in zip(xt3, yt3)]\n",
    "s = [a / max(s) for a in s]  # scale\n",
    "print(\"ett3.shape\")\n",
    "print(ett3.shape)\n",
    "print(\"xt39.shape\")\n",
    "print(xt39.shape)\n",
    "print(xt39)\n",
    "\n",
    "ax= plt.scatter(xt39[:100], yt39[:100], c=s, s=30, cmap=plt.cm.Paired)\n",
    "clf = make_pipeline(StandardScaler(),LinearSVC(random_state=0, tol=1e-5))\n",
    "clf.fit(xt3,yt3) #2차원으로 fit X(왼쪽 xt3)에는 포인트가 있고 Y에는 해당 포인트가 속한 클래스가 있습니다.\n",
    "# 초평면(Hyper-Plane) 표현\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "print(\"XX.shape\")\n",
    "print(XX.shape)\n",
    "\n",
    "\n",
    "\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "print(\"xy.shape\")\n",
    "print(xy.shape)\n",
    "xy = xy.reshape(-1,1)\n",
    "\n",
    "\n",
    "xy1 = xy[:30]\n",
    "xy1 = xy1.flatten()\n",
    "xy1 = xy1[:899]\n",
    "print(\"xy1\")\n",
    "print(xy1)\n",
    "xy1 = xy1.reshape(-1,1)\n",
    "xy2 = xy1[:30]\n",
    "xy3 = xy2.flatten()\n",
    "print(\"xy3\")\n",
    "print(xy3)\n",
    "xy3 = xy3[:30]\n",
    "xy99 = xy3.reshape(30,)\n",
    "print(\"xy3\")\n",
    "print(xy3)\n",
    "xy5= xy99.reshape(-1,1)\n",
    "\n",
    "Z = clf.decision_function(xy5).reshape(30,30)\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1,0,1], alpha=0.2, linestyles=['--', '-', '--'])\n",
    "# 지지벡터(Support Vector) 표현 \n",
    "ax.scatter(clf.support_vectors_[:,0], clf.support_vectors_[:,1], s=60, facecolors='r')\n",
    "plt.show()\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "\n",
    "ax2 = fig.add_subplot(111, projection='3d')\n",
    "ax2.scatter(xt39[:100], yt39, yt39[:100], c= s , marker='o', s=15, cmap='Greens')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2814ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yt3.shape)\n",
    "yt4 = yt3.reshape(-1,)\n",
    "print(yt4)\n",
    "print(\"ett4\")\n",
    "print(ett4)\n",
    "yt5 = yt4[:96]\n",
    "print(\"yt5\")\n",
    "print(yt5)\n",
    "accuracy = accuracy_score(ett4, yt5) #같은 shape 이어야 함. accuracy 랑 다른게 있다. \n",
    "\n",
    "\n",
    "print(\"정확도 계산중... \")\n",
    "print(\" 정확도는 다음과 같다 \")\n",
    "print(accuracy*100)\n",
    "# from sklearn.datasets import make_blobs\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# X,y = make_multilabel_classification(n_classes= 3,random_state = 0)\n",
    "\n",
    "# clf.predict(X[-2:])\n",
    "\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=3)\n",
    "# classifier = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "# classifier.fit(y_test,y_pred)\n",
    "# predictions = classifier.predict(y_train)\n",
    "# classifier.score(y_true,np.array(y_train))\n",
    "\n",
    "# from sklearn.linear_model import RidgeClassifierCV\n",
    "# clf = RidgeClassifierCV().fit(X_train, y_train)\n",
    "# y_score = clf.decision_function(X_train)\n",
    "# roc_auc_score(y_test, y_train, average=None)\n",
    "\n",
    "# from sklearn.datasets import make_multilabel_classification\n",
    "# from sklearn.multioutput import MultiOutputClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# X, y = make_multilabel_classification(random_state=0)\n",
    "# inner_clf = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "# clf = MultiOutputClassifier(inner_clf).fit(X, y)\n",
    "# y_score = np.transpose([y_pred[:, 1] for y_pred in clf.predict_proba(X)])\n",
    "# roc_auc_score(y, y_score, average=None)\n",
    "s = [0.1*np.linalg.norm([a, b]) for a, b in zip(xt3, yt3)]\n",
    "s = [a / max(s) for a in s]  # scale\n",
    "\n",
    "plt.scatter(xt3[:224], xt3[:224], c=s, s=30, cmap=plt.cm.Paired)\n",
    "# 초평면(Hyper-Plane) 표현\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1,0,1], alpha=0.5, linestyles=['--', '-', '--'])\n",
    "# 지지벡터(Support Vector) 표현\n",
    "ax.scatter(clf.support_vectors_[:,0], clf.support_vectors_[:,1], s=60, facecolors='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7567665f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571b257b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0e16d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
